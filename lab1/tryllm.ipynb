{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Lab 1: Try LLM APIs"]},{"cell_type":"markdown","metadata":{},"source":["## You will learn:\n","- First experience how to do run program on the cloud\n","- Learn how to manage API keys\n","- Frist experience of using different LLM APIs\n","- (If you haven't used it before), how to use Jupyter Notebook in VSCode"]},{"cell_type":"markdown","metadata":{},"source":["## 0 Preparations"]},{"cell_type":"markdown","metadata":{},"source":["### 0.1 Dependencies"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[],"source":["# requirements.txt contains the basic packages needed to implement this project\n","# We have installed all dependencies in the default image, so you do not have to install them again, if you use the default image.\n","#!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{},"source":["### 0.2 Proxy to access OpenAI"]},{"cell_type":"code","execution_count":114,"metadata":{},"outputs":[],"source":["# add proxy to access openai ...\n","import os\n","os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n","os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n","os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""]},{"cell_type":"markdown","metadata":{},"source":["### 0.3 Saving your API token in a .env file\n","\n","Here we need to use an OpenAI API KEY, and passing the API KEY directly into the code is terrible for security. A more correct way is to use the dotenv package, write the API_KEY to the .env file, and import the API KEY later by loading the environment variable.\n","\n","You should first create a new file named .env in the root directory of your project.** (AND Never commit it to Git!)\n","The content in this file should be stored as key-value pair.  The .env file is simply a text file with one key-value per line like:\n","\n","    # Comment 1\n","    KEY1=value1\n","    # Comment 2\n","    KEY2=value2\n","\n","More informations see:\n","\n","https://pythonjishu.com/ifggzibrpkgavow/ "]},{"cell_type":"markdown","metadata":{},"source":["##  1 Using OpenAI API"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 Get response from OpenAI"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["from dotenv import load_dotenv\n","import os\n","load_dotenv()\n","openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n","# print(openai_api_key)  ## if you print it, make sure that you clear the output before commiting the notebook to github."]},{"cell_type":"markdown","metadata":{},"source":["Then you can make a call to OpenAI, using the api-key. "]},{"cell_type":"code","execution_count":116,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The 2020 World Series was played at Globe Life Field in Arlington, Texas. This was a unique situation, as it was the first time the World Series was held at a neutral site, chosen as part of the measures to address the COVID-19 pandemic.\n"]}],"source":["from openai import OpenAI\n","client = OpenAI(\n","base_url=\"https://kapkey.chatgptapi.org.cn/v1\",\n","api_key=openai_api_key)\n","\n","response = client.chat.completions.create(\n","  model=\"gpt-4\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n","    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n","    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n","  ]\n",")\n","print(response.choices[0].message.content)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ChatCompletion(id='chatcmpl-89DmVitrA7Thj3mQxE5MjnFSCTyOG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The 2020 World Series was played at Globe Life Field in Arlington, Texas. This was a unique situation, as it was the first time the World Series was held at a neutral site, chosen as part of the measures to address the COVID-19 pandemic.', role='assistant', function_call=None, tool_calls=None))], created=1710078754, model='gpt-4', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=53, prompt_tokens=41, total_tokens=87))\n"]}],"source":["#### YOUR TASK ####\n","# You can exlore what information is in the response object by printing it out and examine it\n","print(response)"]},{"cell_type":"markdown","metadata":{},"source":["You can learn more about the OpenAI API from https://platform.openai.com/docs/overview"]},{"cell_type":"markdown","metadata":{},"source":["## 1.2 Your Task: Use OpenAI api to achieve one shift Caesar cipher communicate \n","\n","We have already provided you the prompts, and you should consider the instruction and demonstrations, and you should use the model gpt-4-turbo-preview."]},{"cell_type":"code","execution_count":118,"metadata":{},"outputs":[],"source":["def encode(s):\n","    for c in s:\n","        if c not in ' ,.!?':\n","            c = chr(ord(c) + 1)\n","        print(c, end='')    \n","        \n","def decode(s):\n","    for c in s:\n","        if c not in ' ,.!?':\n","            c = chr(ord(c) - 1)\n","        print(c, end='')"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Xibu jt uif dbqjubm pg Gsbodf?"]}],"source":["encode('What is the capital of France?')"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[],"source":["prompt = \"\"\"\n","You are an expert on Caesar Cipher. We will communicate in Caesar. Do not be a translator.\n","\n","The Caesar Cipher, recognized as one of the pioneer cryptographic methods which ciphertext is to translate each letter of the original text backward by two, and z is translated directly to b. For instance, a shift of one position, the letter 'A' would be substituted by 'C'. you should answer my question in Caesar.\n","\n","Examples:\n","\n","User: ipx up nblf b cpnc ?\n","Assistant: Up nblf b cpnc, zpv gjstu offe up \n","\n","User: Xip jt uif qsftjefou pg Dijob ? \n","Assistant: Wh Ihmfohmf.\n","\n","User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Dijob ?\n","Assistant: Cfjkjoh.\n","\n","User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Bnfsjdbo ?\n","Assistant: Xbtijohupo.\n","\n","User: Xibu jt uif dbqjubm pg Gsbodf ?\"\"\"\n","\n"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["#### YOUR TASK ####\n","# using the gpt-4 model, create a chat response to the prompt above\n","response = client.chat.completions.create(\n","  model=\"gpt-4\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": prompt},\n","  ]\n",")"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Qbsjt.\n","Paris."]}],"source":["#### YOUR TASK ####\n","### TODO: Print out the cipher text here\n","### TODO: Print out the clear text here using the decode() function\n","print(response.choices[0].message.content)\n","decode(response.choices[0].message.content)"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ChatCompletion(id='chatcmpl-89DjTmdMh37viiOoK9tkFHRaau7On', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Qbsjt.', role='assistant', function_call=None, tool_calls=None))], created=1710078757, model='gpt-4', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=4, prompt_tokens=242, total_tokens=239))\n","239\n"]}],"source":["#### YOUR TASK ####\n","### TODO: print out the response object.  Explore the entire response object.  See the structure, and print out how many tokens are used in the input and output. \n","print(response)\n","print(response.usage.total_tokens)"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fqnvjt_htkqf.\n"]}],"source":["#### YOUR TASK ####\n","### TODO: Repeat the query with another model 'gpt-3.5-turbo'.  Do you still get the same response?\n","from openai import OpenAI\n","client = OpenAI(\n","base_url=\"https://kapkey.chatgptapi.org.cn/v1\",\n","api_key=openai_api_key)\n","\n","response = client.chat.completions.create(\n","  model=\"gpt-3.5-turbo\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": prompt},\n","  ]\n",")\n","print(response.choices[0].message.content)"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ymj yqfhizlm.\n"]}],"source":["#### YOUR TASK ####\n","### TODO: (optional) can you let 'gpt-3.5-turbo' to print the same, by adding more examples in the prompt?  \n","### Consider using a script to generate a much longer prompt with more examples\n","prompt = \"\"\"\n","You are an expert on Caesar Cipher. We will communicate in Caesar. Do not be a translator.\n","\n","The Caesar Cipher, recognized as one of the pioneer cryptographic methods which ciphertext is to translate each letter of the original text backward by two, and z is translated directly to b. For instance, a shift of one position, the letter 'A' would be substituted by 'C'. you should answer my question in Caesar.\n","\n","Examples:\n","\n","User: ipx up nblf b cpnc ?\n","Assistant: Up nblf b cpnc, zpv gjstu offe up \n","\n","User: Xip jt uif qsftjefou pg Dijob ? \n","Assistant: Wh Ihmfohmf.\n","\n","User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Dijob ?\n","Assistant: Cfjkjoh.\n","\n","User: Dbo zpv ufmm nf xifsf jt uif dbqjubm pg Bnfsjdbo ?\n","Assistant: Xbtijohupo.\n","\n","User: Vgn&r sgd oqdrhcdms ne Bghm`?\n","Assistent: Wh Ihmohmf.\n","\n","User: Vgn chrbnudqdc sgd k`v ne fq`uhsx?\n","Assistent: Hr``b Mdvsnm.\n","\n","User: Xibu jt uif dbqjubm pg Gsbodf ?\n","\"\"\"\n","from openai import OpenAI\n","client = OpenAI(\n","base_url=\"https://kapkey.chatgptapi.org.cn/v1\",\n","api_key=openai_api_key)\n","\n","response = client.chat.completions.create(\n","  model=\"gpt-3.5-turbo\",\n","  messages=[\n","    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","    {\"role\": \"user\", \"content\": prompt},\n","  ]\n",")\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Play with LLMs deployed on this cluster"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 Try the local API"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[],"source":["import os\n","import re\n","import requests\n","import json"]},{"cell_type":"markdown","metadata":{},"source":["First, you will need to request for an API token from our local service. "]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["get_res = requests.get('http://10.1.0.5:32411/auth/callback/debug?code=dev')\n","access_token = eval(get_res.text)['access_token']['access_token']\n","# print(access_token)  ## again, if you print it you need to clear the token from output before committing the notebook to github!"]},{"cell_type":"code","execution_count":128,"metadata":{},"outputs":[],"source":["# you can choose the model to call. \n","# The models currently provided include Qwen-7b-chat, vicuna and Llama-2-7B-Chat-fp16\n","model = 'vicuna'\n","api_url = 'http://10.1.0.5:32411/v1/chat/completions'"]},{"cell_type":"markdown","metadata":{},"source":["The local service provides a raw API, exposing the HTTP request details.  You should construct a HTTP query as the following"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["headers={'Content-Type': 'application/json',\n","         'Authorization': 'Bearer '+ access_token\n","         }\n","\n","request = {\"model\": model, \n","           \"stream\": False, \n","           \"messages\": [\n","               {\"role\": \"user\", \"content\": 'hello'}\n","               ]\n","           }"]},{"cell_type":"code","execution_count":130,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<Response [200]>\n"]}],"source":["post_res = requests.post(api_url, headers=headers, json=request)\n","print(post_res)"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello! How can I help you today?\n"]}],"source":["llm_answer = eval(post_res.text)['data']['choices'][0]['message']['content']\n","print(llm_answer)"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 Your task: Use any local model to generate two long text \n","\n","You can choose any question, but each should let the LLM to generate over 300 words in english, while the other should generate 300 Chinese characters. "]},{"cell_type":"code","execution_count":132,"metadata":{},"outputs":[],"source":["#### YOUR TASK ####\n","# write a prompt, for example\n","prompt = '帮我写一篇文章来介绍天安门的背景历史，从古代说到现代，包含很多跟天安门有关系的故事。越长越好，不可以少于1000个字。'\n"]},{"cell_type":"code","execution_count":133,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["《巫师》是一款由中国游戏公司NetEase Games开发的多人在线战斗竞技手游。该游戏于2015年在中国大陆地区正式上线，并随后成为了中国游戏市场的热门游戏之一。\n","\n","游戏以魔幻世界为背景，玩家可以选择扮演各种不同的角色，如巫师、战士、弓箭手等，进行团队战斗和个人挑战。游戏内有丰富的探索和战斗活动，玩家可以通过完成任务和挑战来获得经验值和物品。同时，游戏还提供了丰富的装备系统和技能树，玩家可以通过不断升级和改造来提高自己的角色能力。\n","\n","游戏的玩法十分紧凑，每次战斗都需要玩家快速做出决策和反应。此外，游戏还有着非常丰富的社交功能，玩家可以与其他玩家建立团队，一起完成任务和挑战。游戏的社交系统也非常丰富，玩家可以通过聊天、挂机等方式与其他玩家互动。\n","\n","总体而言，《巫师》是一款非常受欢迎的多人在线战斗竞技手游，其紧凑的玩法和丰富的社交功能使得玩家可以在游戏中获得非常高的满足感和乐趣。\n"]}],"source":["#### YOUR TASK ####\n","# prepare and call the service using a chinese prompt\n","prompt = '请告诉我有关巫师这款电脑游戏的情况，字数不少于300字'\n","request = {\"model\": model, \n","           \"stream\": False, \n","           \"messages\": [\n","               {\"role\": \"user\", \"content\": prompt}\n","               ]\n","           }\n","post_res = requests.post(api_url, headers=headers, json=request)\n","llm_answer = eval(post_res.text)['data']['choices'][0]['message']['content']\n","print(llm_answer)"]},{"cell_type":"code","execution_count":134,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["There are many differences between humans and monkeys, both in terms of their physical characteristics and their behavior. Some of the most notable differences include:\n","\n","* Physical characteristics: Humans have a larger brain-to-body ratio than monkeys, which allows us to communicate and think more complex thoughts. We also have longer limbs and a more flexible spine, which allows us to move and manipulate objects in a wider range of ways. Monkeys have shorter limbs and a less flexible spine, which limits their ability to move and manipulate objects as much as humans can.\n","* Behavior: Humans have a much more complex social structure than monkeys, with a wide variety of different cultures and societies. We also have a much greater ability to communicate and cooperate with one another, which has allowed us to build complex societies and civilizations. Monkeys, on the other hand, tend to live in smaller groups and have less complex social structures. They also tend to be more solitary animals, spending more time alone rather than in groups.\n"]}],"source":["#### YOUR TASK ####\n","# prepare and call the service using a english prompt, for example, \n","prompt = 'Please tell me the difference between human and monkey?'\n","request = {\"model\": model, \n","           \"stream\": False, \n","           \"messages\": [\n","               {\"role\": \"user\", \"content\": prompt}\n","               ]\n","           }\n","post_res = requests.post(api_url, headers=headers, json=request)\n","llm_answer = eval(post_res.text)['data']['choices'][0]['message']['content']\n","print(llm_answer)"]},{"cell_type":"code","execution_count":135,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["As of my knowledge cutoff in September 2021, the President of China was Xi Jinping. He has been serving in the position since 2013 and is widely considered one of the most powerful leaders in the country's history.\n","\n","Xi Jinping has implemented various policies aimed at strengthening the Chinese economy and enhancing the country's global influence. Under his leadership, China has become the world's second-largest economy and has continued to grow at a steady pace.\n","\n","Xi Jinping has also been instrumental in shaping China's foreign policy, particularly in terms of its relations with other countries and international organizations. He has emphasized the importance of multilateralism and regional cooperation, while also promoting China's interests and values on the global stage.\n","\n","However, it is important to note that my knowledge is limited to what was available up until 2021, and there may have been changes in China's leadership or policies since then.\n"]}],"source":["#### YOUR TASK ####\n","# prepare and call the service using a english prompt\n","prompt = 'Who is the president of china, and give me some estimation about him?'\n","request = {\"model\": model, \n","           \"stream\": False, \n","           \"messages\": [\n","               {\"role\": \"user\", \"content\": prompt}\n","               ]\n","           }\n","post_res = requests.post(api_url, headers=headers, json=request)\n","llm_answer = eval(post_res.text)['data']['choices'][0]['message']['content']\n","print(llm_answer)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 2.3 Your task (Homework): Write a simpler API for the local LLMs\n","\n","It is time to practise your Python skills.  Write an function similar to the OpenAI API and hide the raw headers and reponses from the callers. \n","It should at least support setting models, sending prompts, and return results.  It should return error if the HTTP reply code is other than 200. \n","\n","Hint: you can try to use GitHub Copilot to help you write it."]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[],"source":["#### YOUR TASK ####\n","def get_answer(model,prompt,reply_code):\n","    if reply_code != 200:\n","        return 'error!'\n","    else:\n","        request = {\"model\": model, \n","           \"stream\": False, \n","           \"messages\": [\n","               {\"role\": \"user\", \"content\": prompt}\n","               ]\n","           }\n","        post_res = requests.post(api_url, headers=headers, json=request)\n","        llm_answer = eval(post_res.text)['data']['choices'][0]['message']['content']\n","        print(llm_answer)"]}],"metadata":{"kernelspec":{"display_name":"py310","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
