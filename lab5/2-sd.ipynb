{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## 5.2 Stable Diffusion and DreamBooth\n", " Stable diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input.\n", "\n", " We use `runwayml/stable-diffusion-v1-5` in this notebook. \n", "\n", "Use the pre-downloaded model weights on `/share/lab5/sd`, or make sure you have downloaded the weights of stable-diffusion: \n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Stable Diffusion Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# You can directly use the downloaded weights from /share/lab5/sd, or pre-download them:\n", "\n", "#!export HF_ENDPOINT=https://hf-mirror.com\n", "#!huggingface-cli download --resume-download runwayml/stable-diffusion-v1-5  --local-dir your_path_of_sd"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#If you encounter an 'out of memory' error, make sure no other programs are running on this GPU (reset the previous notebook's kernel).\n", "\n", "from diffusers import AutoPipelineForText2Image\n", "import torch\n", "pipeline = AutoPipelineForText2Image.from_pretrained(\"/share/lab5/sd\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n", "output = pipeline(\"stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k\")\n", "\n", "for image in output.images:\n", "    image.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# using stable diffusion in Image2Image pipeline  (just change the AutoPipeline class)\n", "\n", "from diffusers import AutoPipelineForImage2Image\n", "import torch\n", "import requests\n", "from PIL import Image\n", "from io import BytesIO\n", "\n", "pipeline = AutoPipelineForImage2Image.from_pretrained(\n", "    \"/share/lab5/sd\",\n", "    torch_dtype=torch.float16,\n", "    use_safetensors=True,\n", ").to(\"cuda\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# the image to image pipeline requires inputting an image.\n", "\n", "image = Image.open(\"/share/lab5/data/Girl_with_a_Pearl_Earring.jpg\").convert(\"RGB\")\n", "prompt = \"a portrait of a dog wearing a pearl earring\"\n", "image.thumbnail((768, 768))\n", "\n", "image = pipeline(prompt, image, num_inference_steps=200, strength=0.75, guidance_scale=10.5).images[0]\n", "image"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### [Do it after class, as it will take a while] Stable-diffusion with Dreambooth\n", "DreamBooth is a training technique that updates the entire diffusion model by training on just a few images of a subject or style. It works by associating a special word in the prompt with the example images.\n", "\n", "- If you\u2019re training on a GPU with limited vRAM, you should try enabling the `gradient_checkpointing` and  `mixed_precision` parameters in the training command. \n", "\n", "- The script also allows to fine-tune the `text_encoder` along with the `unet`. It's been observed experimentally that fine-tuning `text_encoder` gives much better results especially on faces. \n", "Pass the `--train_text_encoder` argument to the script to enable training `text_encoder`."]}, {"cell_type": "markdown", "metadata": {}, "source": ["First, we need to finetune the diffusion model."]}, {"cell_type": "markdown", "metadata": {}, "source": ["I strongly suggest you reset your kernel here to prevent it from out of memory."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# a few directory settings\n", "\n", "MODEL_NAME=\"/share/lab5/sd\"\n", "INSTANCE_DIR=\"/share/lab5/data/dog\" \n", "CLASS_DIR='/scratch2/original_dog' \n", "MODEL_OUTPUT=\"/scratch2/dog-model\"\n", "\n", "INSTANCE_PROMPT='a photo of sks dog'\n", "CLASS_PROMPT=\"a photo of a dog\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# run the training script (this will take a long while)\n", "\n", "!python train_dreambooth.py \\\n", "  --pretrained_model_name_or_path={MODEL_NAME} \\\n", "  --instance_data_dir={INSTANCE_DIR} \\\n", "  --class_data_dir={CLASS_DIR} \\\n", "  --output_dir={MODEL_OUTPUT} \\\n", "  --with_prior_preservation --prior_loss_weight=1.0 \\\n", "  --instance_prompt=\"{INSTANCE_PROMPT}\"\\\n", "  --class_prompt=\"{CLASS_PROMPT}\" \\\n", "  --resolution=512 \\\n", "  --train_batch_size=1 \\\n", "  --gradient_accumulation_steps=1 \\\n", "  --learning_rate=5e-6 \\\n", "  --lr_scheduler=\"constant\" \\\n", "  --lr_warmup_steps=0 \\\n", "  --num_class_images=200 \\\n", "  --max_train_steps=800 \\\n", "  --gradient_checkpointing \\\n", "  --mixed_precision fp16"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once you have trained a model using the above command, you can run inference simply using the `StableDiffusionPipeline`. Make sure to include the `identifier` (e.g. `sks` in above example) in your prompt."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from diffusers import DiffusionPipeline\n", "import torch\n", "\n", "pipeline = DiffusionPipeline.from_pretrained(MODEL_OUTPUT, torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## Using the tuned prompt \"sks dog\" riding a bicycle\n", "\n", "image = pipeline(\"A photo of sks dog riding bycycle\", num_inference_steps=200, guidance_scale=7.5).images[0]\n", "image.save(\"/scratch2/dog-bike.png\")\n", "image.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# different from without the prompt sks dog\n", "\n", "image = pipeline(\"A photo of a dog riding bycycle\", num_inference_steps=200, guidance_scale=7.5).images[0]\n", "image.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image = pipeline(\"A photo of sks dog on an airplane\", num_inference_steps=200, guidance_scale=7.5).images[0]\n", "image.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Your tasks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#### Your Task ####\n", "# Use your favourite character to build a DreamBooth model, and generate the character in at least three different scenes.  \n", "# Note that if the model generates obviously wrong / non-sense images, you can leave them their, just to entertain the TAs!"]}], "metadata": {"kernelspec": {"display_name": "base", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 2}