{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## 5.3 Fuyu  \n", "A small version of the multimodal model, it can support arbitrary image resolutions, answer questions about graphs and diagrams, answer UI-based questions, and do fine-grained localization on screen images.\n", "\n", "Use the pre-downloaded model weights on `/share/lab5/fuyu`: "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# You can directly use the downloaded weights from /share/lab5/fuyu\n", "\n", "\n", "#!export HF_ENDPOINT=https://hf-mirror.com\n", "#!huggingface-cli download --resume-download adept/fuyu-8b  --local-dir your_path_of_fuyu"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from PIL import Image\n", "import torch\n", "from transformers import FuyuProcessor, FuyuForCausalLM\n", "import requests\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Fuyu():\n", "    def __init__(self, model_id='your_path_of_fuyu'):\n", "        if torch.cuda.is_available():\n", "            print(\"You are running the model on GPU.\")\n", "            self.device = torch.device(\"cuda:0\")\n", "            self.dtype = torch.float16\n", "        else:\n", "            print(\"You are running the model on CPU.\")\n", "            self.device = torch.device(\"cpu\")\n", "            self.dtype = torch.bfloat16\n", "        \n", "        print('Begin loading.')\n", "        self.model =  FuyuForCausalLM.from_pretrained(model_id, device_map=self.device, torch_dtype=self.dtype)\n", "        print('Checkpoints loaded!')\n", "        self.processor = FuyuProcessor.from_pretrained(model_id)\n", "        print('Processor loaded!')\n", "\n", "    def prompt(self, text, image=None, out_tokens=200):\n", "        #Prompt the model with a text and optional an image prompt.\n", "        # if prompt does not end in \\n, add a \\n\n", "        if text[-1] != \"\\n\":\n", "            text += \"\\n\"\n", "        # pre processing image and text\n", "        inputs = self.processor(text=text, images=[image], return_tensors=\"pt\").to(self.device)\n", "        prompt_len = inputs[\"input_ids\"].shape[-1]\n", "        print(f\"prompt length: %s\" % prompt_len)\n", "        generation_output = self.model.generate(**inputs, max_new_tokens=out_tokens)\n", "        generation_text = self.processor.batch_decode(generation_output[:,prompt_len:], skip_special_tokens=True)\n", "        return generation_text[0].lstrip()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Loading the model.  It will take a while to load the model for the first time.\n", "# If you encounter an 'out of memory' error, make sure no other programs are running on this GPU or restart the kernel.\n", "model_id = \"/share/lab5/fuyu\" \n", "fuyu = Fuyu(model_id)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## a handy utility function to print the output with a specific max characters per line\n", "def pprint(text, line_char=256):\n", "  last_char = \"\" # handle last word in each line\n", "  for i in range(0, len(text), line_char):\n", "    line = text[i:i+line_char]\n", "    line = last_char+line\n", "    last_char = \"\"\n", "    line = line.split(\" \")\n", "    last_char = line[-1]\n", "    if i <= len(text)-line_char:\n", "      # handle last word in last line\n", "      line = line[:-1]\n", "    print(\" \".join(line))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# This is how you use the model to generate text.\n", "\n", "def run_image(prompt,img_path):\n", "  image_pil = Image.open(img_path)\n", "  image_pil.show()\n", "  image = np.array(image_pil)\n", "    \n", "  if len(image.shape) == 2:\n", "      image = np.stack((image,) * 3, axis=-1)\n", "  \n", "  output = fuyu.prompt(prompt, image, out_tokens=100)\n", "  pprint(f\"OUTPUT: \\n{output}\", 50)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'How many bottles of [Magna] beer are there? Please note that several types of beer might be on the table.'\n", "img_path = '/share/lab5/data/test0.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt =' Describe what is Object 1 and object 2. Tell me what is in the circled glass.'\n", "img_path = '/share/lab5/data/test1.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## You can also directly load the image from an URL\n", "\n", "def run_image_url(prompt, img_url):\n", "  image = Image.open(requests.get(img_url, stream = True).raw)\n", "  image.show()\n", "  image = np.array(image)\n", "    \n", "  if len(image.shape) == 2:\n", "      image = np.stack((image,) * 3, axis=-1)\n", "  \n", "  output = fuyu.prompt(prompt, image, out_tokens=100)\n", "  pprint(f\"OUTPUT: \\n{output}\", 50)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["## using a URL image\n", "prompt = 'what is in the image?'\n", "url = \"https://k.sinaimg.cn/n/sinakd20240410s/106/w1024h682/20240410/cf40-2931ffbf2b8611590b5b3384c200f2d4.png/w700d1q75cms.jpg?by=cms_fixed_width\"\n", "run_image_url(prompt, url)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt= ' Please read the text in this image and return the information in the following JSON format (note xxx is placeholder, if the information is not available in the image, put \"N/A\" instead). {\"class\": xxx, \"DLN\": xxx, \"DOB\": xxx, \"Name\": xxx, \"Address\": xxx, \"EXP\": xxx, \"ISS\": xxx, \"SEX\": xxx, \"HGT\": xxx, \"WGT\": xxx, \"EYES\": xxx, \"HAIR\": xxx, \"DONOR\": xxx}'\n", "img_path = '/share/lab5/data/test2.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'What are all the scene text in the image?'\n", "img_path = '/share/lab5/data/test15.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt ='Count the number of apples in the image.'\n", "img_path = '/share/lab5/data/test3.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'Count the number of apples in the image row-by-row.'\n", "img_path = '/share/lab5/data/test3.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'Describe the landmark in the image.'\n", "img_path = '/share/lab5/data/test6.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'Describe the name of the dish.'\n", "img_path = '/share/lab5/data/test7.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'What is wrong with the foot in this figure??'\n", "img_path = '/share/lab5/data/test8.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt ='What is the spatial relation between the frisbee and the man?'\n", "img_path = '/share/lab5/data/test9.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prompt = 'Which oceans surround Africa?  both to the east and to the west.'\n", "img_path = '/share/lab5/data/test13.jpg'\n", "run_image(prompt, img_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#### Your Task ####\n", "# Try at least three examples of your image, using different prompts.  See if the model can generate the correct answer."]}], "metadata": {"kernelspec": {"display_name": "base", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 2}