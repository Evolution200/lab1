{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7731fa-1ab4-48cf-996c-a1a1fb6b2315",
   "metadata": {},
   "source": [
    "# Lec4. Adding Memory and Storage to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b0c75-2dd7-4662-b2ce-4e6b9208926c",
   "metadata": {},
   "source": [
    "Last week, we learned the basic elements of the framework LangChain. In this lecture, we are going to construct a vector store QA application from scratch.\n",
    "\n",
    ">Reference:\n",
    "> 1. [Ask A Book Questions](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Ask%20A%20Book%20Questions.ipynb)\n",
    "> 2. [Agent Vectorstore](https://python.langchain.com/docs/modules/agents/how_to/agent_vectorstore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a649ab-bb72-4894-b526-c97a7aa1fd81",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411a5b-ad45-4bf0-bf8e-91f71b256337",
   "metadata": {},
   "source": [
    "1. Install the requirements.  (Already installed in your image.)\n",
    "    ```\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "2. Get your OpenAI API; to get your Serpapi key, please sign up for a free account at the [Serpapi website](https://serpapi.com/); to get your Pinecone key, first regiter on the [Pinecone website](https://www.pinecone.io/), **Create API Key** and **Create Index**. Note that in this notebook the index's dimension should be 1536.\n",
    "\n",
    "3. Store your keys in a file named **.env** and place it in the current path or in a location that can be accessed.\n",
    "    ```\n",
    "    OPENAI_API_KEY='YOUR-OPENAI-API-KEY'\n",
    "    SERPAPI_API_KEY=\"YOUR-SERPAPI-API-KEY\"\n",
    "    PINECONE_API_KEY=\"YOUR-PINECONE-API-KEY\"\n",
    "    PINECONE_API_ENV=\"PINECONE-API-ENV\" # Should be something like \"gcp-starter\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "defc9a3a-9f4c-49ff-8546-5799ff78b457",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb49c80a-4c12-4829-bef9-91076a4af689",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "159215cd-4035-4f12-9904-e0ad32929b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5009a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function\n",
    "\n",
    "from pprint import pprint\n",
    "def print_with_type(res):\n",
    "    pprint(f\"%s:\" % type(res))\n",
    "    pprint(res)\n",
    "\n",
    "    #pprint(f\"%s : %s\" % (type(res), res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d6985-1b36-4142-90b1-ad6386eb4335",
   "metadata": {},
   "source": [
    "## 1. Adding memory to remember the context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6809691-6aa5-4062-8d9e-1c620f9c6d2f",
   "metadata": {},
   "source": [
    "### 1.1 Use Conversation Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e8c81",
   "metadata": {},
   "source": [
    "#### Basic Use of ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3b8fbfe-6cd7-4c4e-843f-92b0f4755d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'history': \"Human: hi\\nAI: what's up\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Creating a memory and write to it.\n",
    "memory = ConversationBufferMemory()  # stores all histories as a single string\n",
    "memory.save_context({\"input\": \"hi\"}, \n",
    "                    {\"output\": \"what's up\"})\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c34234",
   "metadata": {},
   "source": [
    "We can also get the history as a list of messages (this is useful if you are using this with a chat model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2794154-3b85-4012-b28f-2470cfeaa13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'history': [HumanMessage(content='hi'), AIMessage(content=\"what's up\")]}\n"
     ]
    }
   ],
   "source": [
    "# get the history as a list of messages\n",
    "memory = ConversationBufferMemory(return_messages=True)  # stores messages as a list\n",
    "memory.save_context({\"input\": \"hi\"}, \n",
    "                    {\"output\": \"what's up\"})\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7eafa",
   "metadata": {},
   "source": [
    "#### Managing Conversation Memory automatically in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e349aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edfe2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"\"\"You are a chatbot having a conversation with a human. \n",
    "            Your name is Tom Marvolo Riddle. \n",
    "            You need to tell your name to that human if he doesn't know.\"\"\"\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name = \"chat_history\"\n",
    "        ),  # This is where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),  # This is where the human input will be injected\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", \n",
    "                                  return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e2d0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set verbose as True to see more details\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,   # Look at this line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0db79f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human. \n",
      "            Your name is Tom Marvolo Riddle. \n",
      "            You need to tell your name to that human if he doesn't know.\n",
      "Human: Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello there, Harry Potter. I am Tom Marvolo Riddle. It's a pleasure to meet you. It's great to hear that you've made some good friends at Hogwarts like Ron Weasley and Hermione Granger. How are you finding life at Hogwarts so far?\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12e8428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.'),\n",
       "  AIMessage(content=\"Hello there, Harry Potter. I am Tom Marvolo Riddle. It's a pleasure to meet you. It's great to hear that you've made some good friends at Hogwarts like Ron Weasley and Hermione Granger. How are you finding life at Hogwarts so far?\")]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b0cf684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human. \n",
      "            Your name is Tom Marvolo Riddle. \n",
      "            You need to tell your name to that human if he doesn't know.\n",
      "Human: Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.\n",
      "AI: Hello there, Harry Potter. I am Tom Marvolo Riddle. It's a pleasure to meet you. It's great to hear that you've made some good friends at Hogwarts like Ron Weasley and Hermione Granger. How are you finding life at Hogwarts so far?\n",
      "Human: What are my best friends' names? \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Your best friends' names are Ron Weasley and Hermione Granger. They are both loyal and brave companions who have stood by you through thick and thin at Hogwarts.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"What are my best friends' names? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ace5b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.'),\n",
       "  AIMessage(content=\"Hello there, Harry Potter. I am Tom Marvolo Riddle. It's a pleasure to meet you. It's great to hear that you've made some good friends at Hogwarts like Ron Weasley and Hermione Granger. How are you finding life at Hogwarts so far?\"),\n",
       "  HumanMessage(content=\"What are my best friends' names? \"),\n",
       "  AIMessage(content=\"Your best friends' names are Ron Weasley and Hermione Granger. They are both loyal and brave companions who have stood by you through thick and thin at Hogwarts.\")]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5184cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a chatbot having a conversation with a human. \n",
      "            Your name is Tom Marvolo Riddle. \n",
      "            You need to tell your name to that human if he doesn't know.\n",
      "Human: What are my best friends' names? \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! I am Tom Marvolo Riddle. And you are?'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.clear()\n",
    "memory.load_memory_variables({})\n",
    "chat_llm_chain.predict(human_input=\"What are my best friends' names? \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451b9db-5213-463c-9867-5ecb67bd6d01",
   "metadata": {},
   "source": [
    "#### (Optional) Manipulate the memory by yourself in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "453b9ad2-45b7-4899-b28a-be80166d71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f429977-c439-4f56-bf42-191c14d6daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add memory to an arbitrary chain\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c28ebc5-9720-40e8-b8f6-497b14092367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'langchain_core.messages.ai.AIMessage'>:\"\n",
      "AIMessage(content='Hello Harry! How can I help you today?')\n",
      "\"<class 'dict'>:\"\n",
      "{'history': []}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"Hi, I am Harry!\"}\n",
    "response = chain.invoke(inputs)\n",
    "print_with_type(response)\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "205e3b28-4fd5-426a-87fd-4e88604762a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'history': [HumanMessage(content='Hi, I am Harry!'),\n",
      "             AIMessage(content='Hello Harry! How can I help you today?')]}\n"
     ]
    }
   ],
   "source": [
    "# You need to save the context yourself\n",
    "memory.save_context(inputs, \n",
    "                    {\"output\": response.content})\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12b115f9-c389-43a6-815a-351dfaea009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'langchain_core.messages.ai.AIMessage'>:\"\n",
      "AIMessage(content='Your name is Harry. Is there anything else you would like assistance with?')\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What's my name?\"})\n",
    "print_with_type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc6973-7992-4e37-bda1-505c0e670df8",
   "metadata": {},
   "source": [
    "### 1.2 Using Entity memory\n",
    "\n",
    "#### Basic Use of ConversationEntityMemory\n",
    "\n",
    "Entity memory remembers given facts about specific entities in a conversation. It extracts information on entities (using an LLM) and builds up its knowledge about that entity over time (also using an LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "76ae8f4b-067e-4a39-9802-8989513480cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76d147e6-bc48-4235-ba83-d40c83be86b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Harry & Ron are going to rescue a baby dragon in London.'),\n",
       "  AIMessage(content='That sounds like a great mission! What kind of mission are they working on?')],\n",
       " 'entities': {'Harry': 'Harry is going to rescue a baby dragon in London.',\n",
       "  'Ron': 'Ron is going to rescue a baby dragon in London with Harry.',\n",
       "  'Wei': '',\n",
       "  'London': 'London is the location where Harry and Ron are going to rescue a baby dragon.'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationEntityMemory(llm=llm, return_messages=True)\n",
    "inputs = {\"input\": \"Harry & Ron are going to rescue a baby dragon in London.\"}\n",
    "memory.load_memory_variables(inputs)\n",
    "memory.save_context(\n",
    "    inputs,\n",
    "    {\"output\": \"That sounds like a great mission! What kind of mission are they working on?\"}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({\"input\": \"Harry and Ron and Wei and London?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aaf35a-8bbe-4274-9ed0-43d983e35e01",
   "metadata": {},
   "source": [
    "#### Using Entity in a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3128de",
   "metadata": {},
   "source": [
    "Here we use ConversationChain.  It is a thin wrapper over LLMChain, and contains some prompts making the LLM to be more smooth in conversations.  See its source code for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9ac27a8-bfce-4066-b038-a75265036c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef6b28b9-4c78-4c7c-9164-89a60d980329",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5defa301-db7f-4bae-8b43-af49cee92f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Harry & Ron are going to rescue a baby dragon.',\n",
       " 'history': '',\n",
       " 'entities': {'Harry': '', 'Ron': ''},\n",
       " 'response': \" That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be dangerous creatures, but they also deserve to live freely in the wild. I'm sure Harry and Ron will do everything they can to ensure the dragon's safety.\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Harry & Ron are going to rescue a baby dragon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e492536-d6ee-4094-8bf5-4a17dd48348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Harry': 'Harry is going to help rescue a baby dragon with Ron.',\n",
       " 'Ron': 'Ron is going to help Harry rescue a baby dragon.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97567380-84a5-4517-be2f-5aef57b0f052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\",\n",
       " 'history': \"Human: Harry & Ron are going to rescue a baby dragon.\\nAI:  That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be dangerous creatures, but they also deserve to live freely in the wild. I'm sure Harry and Ron will do everything they can to ensure the dragon's safety.\",\n",
       " 'entities': {'Ron': 'Ron is going to help Harry rescue a baby dragon.',\n",
       "  'Charlie': '',\n",
       "  'Romania': ''},\n",
       " 'response': \" That's a great idea! Romania is known for its dragon reserves and I'm sure Charlie's friends will take good care of the baby dragon there. It's important to find a safe and suitable home for the dragon, and it seems like Ron and Harry have found the perfect solution.\"}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "62f5f13a-ff9f-407a-ae5f-1004ff8c0cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\",\n",
       " 'history': \"Human: Harry & Ron are going to rescue a baby dragon.\\nAI:  That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be dangerous creatures, but they also deserve to live freely in the wild. I'm sure Harry and Ron will do everything they can to ensure the dragon's safety.\\nHuman: They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\\nAI:  That's a great idea! Romania is known for its dragon reserves and I'm sure Charlie's friends will take good care of the baby dragon there. It's important to find a safe and suitable home for the dragon, and it seems like Ron and Harry have found the perfect solution.\",\n",
       " 'entities': {'Harry': 'Harry is going to help rescue a baby dragon with Ron.',\n",
       "  'Ron': \"Ron's elder brother Charlie's friends will be taking the baby dragon to Romania, thanks to Ron's help.\",\n",
       "  'Hogwarts': '',\n",
       "  \"Harry's Invisibility cloak\": ''},\n",
       " 'response': \" That's a clever plan! Harry's Invisibility cloak will definitely come in handy for this mission. I'm sure they will be able to successfully transfer the baby dragon without anyone noticing. Hogwarts is a big place, so finding a high and secluded spot shouldn't be too difficult. Good luck to Harry and Ron on their mission!\"}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e27e48a2-862d-418b-9cdb-8fec5278d77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What do you know about Harry & Ron?',\n",
       " 'history': \"Human: Harry & Ron are going to rescue a baby dragon.\\nAI:  That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be dangerous creatures, but they also deserve to live freely in the wild. I'm sure Harry and Ron will do everything they can to ensure the dragon's safety.\\nHuman: They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\\nAI:  That's a great idea! Romania is known for its dragon reserves and I'm sure Charlie's friends will take good care of the baby dragon there. It's important to find a safe and suitable home for the dragon, and it seems like Ron and Harry have found the perfect solution.\\nHuman: Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\\nAI:  That's a clever plan! Harry's Invisibility cloak will definitely come in handy for this mission. I'm sure they will be able to successfully transfer the baby dragon without anyone noticing. Hogwarts is a big place, so finding a high and secluded spot shouldn't be too difficult. Good luck to Harry and Ron on their mission!\",\n",
       " 'entities': {'Harry': 'Harry is using his Invisibility cloak to help secretly transfer the baby dragon to a safe place in Hogwarts.',\n",
       "  'Ron': \"Ron is helping Harry transfer the baby dragon to the highest place in Hogwarts using Harry's Invisibility cloak.\"},\n",
       " 'response': \" Harry and Ron are two brave and resourceful wizards who are always willing to help others, even if it means going on dangerous missions like rescuing a baby dragon. They make a great team and I'm sure they will succeed in their mission with the help of Harry's Invisibility cloak.\"}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"What do you know about Harry & Ron?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66085a34-f6fd-4bb0-a91f-3b9aa96b278c",
   "metadata": {},
   "source": [
    "Now Let's inspect the entities that are extracted from the conversation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c36d9ec-2840-48db-b6a9-809229a53a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'Charlie': \"Charlie is Ron's elder brother who has friends in Romania who can \"\n",
      "            'take care of the baby dragon.',\n",
      " 'Harry': 'Harry and Ron are two brave and resourceful wizards who are always '\n",
      "          'willing to help others, even if it means going on dangerous '\n",
      "          'missions like rescuing a baby dragon. They make a great team and '\n",
      "          \"I'm sure they will succeed in their mission with the help of \"\n",
      "          \"Harry's Invisibility cloak.\",\n",
      " \"Harry's Invisibility cloak\": 'Harry will use his Invisibility cloak to '\n",
      "                               'secretly transfer the baby dragon to the '\n",
      "                               'highest place in Hogwarts without being seen.',\n",
      " 'Hogwarts': 'Hogwarts is a big place, but Harry and Ron have a clever plan to '\n",
      "             'secretly transfer the baby dragon to the highest point using '\n",
      "             \"Harry's Invisibility cloak.\",\n",
      " 'Romania': \"Romania is known for its dragon reserves and it's important to \"\n",
      "            'find a safe and suitable home for the baby dragon.',\n",
      " 'Ron': 'Ron is a brave and resourceful wizard who, along with his friend '\n",
      "        'Harry, is on a mission to secretly transfer a baby dragon to the '\n",
      "        \"highest place in Hogwarts using Harry's Invisibility cloak.\"}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ad77c",
   "metadata": {},
   "source": [
    "Let's do more conversations and see what we can learn more about each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4821793a-fe46-4693-a940-18833f1b9a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Yes, Harry is known for his bravery and cleverness. He has faced many challenges and always finds a way to overcome them. He is a great friend and a valuable member of the wizarding community.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Harry is a brave and clever boy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b340df6-b5c8-4731-8936-c8587eb1d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'Charlie': \"Charlie is Ron's elder brother who has friends in Romania who can \"\n",
      "            'take care of the baby dragon.',\n",
      " 'Harry': 'Harry is known for his bravery and cleverness, and is a great '\n",
      "          'friend and valuable member of the wizarding community.',\n",
      " \"Harry's Invisibility cloak\": 'Harry will use his Invisibility cloak to '\n",
      "                               'secretly transfer the baby dragon to the '\n",
      "                               'highest place in Hogwarts without being seen.',\n",
      " 'Hogwarts': 'Hogwarts is a big place, but Harry and Ron have a clever plan to '\n",
      "             'secretly transfer the baby dragon to the highest point using '\n",
      "             \"Harry's Invisibility cloak.\",\n",
      " 'Romania': \"Romania is known for its dragon reserves and it's important to \"\n",
      "            'find a safe and suitable home for the baby dragon.',\n",
      " 'Ron': 'Ron is a brave and resourceful wizard who, along with his friend '\n",
      "        'Harry, is on a mission to secretly transfer a baby dragon to the '\n",
      "        \"highest place in Hogwarts using Harry's Invisibility cloak.\"}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "718775f3-8188-4199-a663-72bd4b96eac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What do you know about Harry?',\n",
       " 'history': \"Human: Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\\nAI:  That's a clever plan! Harry's Invisibility cloak will definitely come in handy for this mission. I'm sure they will be able to successfully transfer the baby dragon without anyone noticing. Hogwarts is a big place, so finding a high and secluded spot shouldn't be too difficult. Good luck to Harry and Ron on their mission!\\nHuman: What do you know about Harry & Ron?\\nAI:  Harry and Ron are two brave and resourceful wizards who are always willing to help others, even if it means going on dangerous missions like rescuing a baby dragon. They make a great team and I'm sure they will succeed in their mission with the help of Harry's Invisibility cloak.\\nHuman: Harry is a brave and clever boy.\\nAI:  Yes, Harry is known for his bravery and cleverness. He has faced many challenges and always finds a way to overcome them. He is a great friend and a valuable member of the wizarding community.\",\n",
       " 'entities': {'Harry': 'Harry is known for his bravery and cleverness, and is a great friend and valuable member of the wizarding community.'},\n",
       " 'response': ' As I mentioned before, Harry is known for his bravery and cleverness. He is a great friend and a valuable member of the wizarding community. He has faced many challenges and always finds a way to overcome them. He is also a skilled wizard and has a strong sense of justice. Overall, Harry is a remarkable individual who has made a significant impact in the wizarding world.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"What do you know about Harry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2467bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'Charlie': \"Charlie is Ron's elder brother who has friends in Romania who can \"\n",
      "            'take care of the baby dragon.',\n",
      " 'Harry': 'As mentioned before, Harry is known for his bravery and cleverness, '\n",
      "          'and is a great friend and valuable member of the wizarding '\n",
      "          'community. He has faced many challenges and always finds a way to '\n",
      "          'overcome them. He is also a skilled wizard and has a strong sense '\n",
      "          'of justice. Overall, Harry is a remarkable individual who has made '\n",
      "          'a significant impact in the wizarding world.',\n",
      " \"Harry's Invisibility cloak\": 'Harry will use his Invisibility cloak to '\n",
      "                               'secretly transfer the baby dragon to the '\n",
      "                               'highest place in Hogwarts without being seen.',\n",
      " 'Hogwarts': 'Hogwarts is a big place, but Harry and Ron have a clever plan to '\n",
      "             'secretly transfer the baby dragon to the highest point using '\n",
      "             \"Harry's Invisibility cloak.\",\n",
      " 'Romania': \"Romania is known for its dragon reserves and it's important to \"\n",
      "            'find a safe and suitable home for the baby dragon.',\n",
      " 'Ron': 'Ron is a brave and resourceful wizard who, along with his friend '\n",
      "        'Harry, is on a mission to secretly transfer a baby dragon to the '\n",
      "        \"highest place in Hogwarts using Harry's Invisibility cloak.\"}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab1e54-6c47-43ea-9750-af8840c1494d",
   "metadata": {},
   "source": [
    "### 1.3 Adding Memory to Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8bf04-34d1-4a86-82f8-de39be61b836",
   "metadata": {},
   "source": [
    "In this section, we will first ask the agent a question, and then without mention the context information ourselves ask another related question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edba9d7b-5baa-4769-9c2a-d11164941fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9088da52-e54b-468e-a158-9220360ea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ee6d6dd-39eb-425f-bdda-8d5dc07e3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=\"\"\"Have a conversation with a human, answering the following questions as best you can.  You have access to the following tools:\"\"\",\n",
    "    suffix=\"\"\"Begin!  \n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\",\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c0a5b87b-2c41-4b4a-b14a-cb30838c561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.mrkl.base.ZeroShotAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use create_react_agent instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ed18da6e-6754-4b8b-8951-4bf916e3d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I should use the search tool to find the most recent data on China's population.\n",
      "Action: Search\n",
      "Action Input: \"China population 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe current population of China is 1,425,289,376 as of Tuesday, April 9, 2024, based on Worldometer elaboration of the latest United Nations data 1.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should double check this information with a reliable source.\n",
      "Action: Search\n",
      "Action Input: \"China population 2024 reliable source\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe current population of China is 1,425,289,376 as of Tuesday, April 9, 2024, based on Worldometer elaboration of the latest United Nations data 1. China 2023 population is estimated at 1,425,671,352 people at mid year. China population is equivalent to 17.72% of the total world population.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This seems like a reliable and up-to-date source.\n",
      "Action: Search\n",
      "Action Input: \"China population 2024 reliable source\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe current population of China is 1,425,289,376 as of Tuesday, April 9, 2024, based on Worldometer elaboration of the latest United Nations data 1. China 2023 population is estimated at 1,425,671,352 people at mid year. China population is equivalent to 17.72% of the total world population.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The population of China in 2024 is estimated to be 1,425,289,376 people.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the population of China in 2024?',\n",
       " 'chat_history': '',\n",
       " 'output': 'The population of China in 2024 is estimated to be 1,425,289,376 people.'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"What is the population of China in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd9a011d-c1cc-4c1c-bf43-7b505eb97c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is estimated to be 1,425,289,376 people.'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4dc74f05-4c59-4df3-800b-c2421e1d1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I should use the search tool to find the population data for both China and India.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\" and \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Twenty countries with the largest population in 2024 (in millions)', 'source': 'Statista'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should click on the source from Statista to get the accurate data.\n",
      "Action: Click on the source from Statista\n",
      "Action Input: \"Statista\"\u001b[0m\n",
      "Observation: Click on the source from Statista is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the search tool to find the population data for both China and India.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\" and \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Twenty countries with the largest population in 2024 (in millions)', 'source': 'Statista'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should click on the source from Statista to get the accurate data.\n",
      "Action: Click on the source from Statista\n",
      "Action Input: \"Statista\"\u001b[0m\n",
      "Observation: Click on the source from Statista is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the search tool to find the population data for both China and India.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\" and \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Twenty countries with the largest population in 2024 (in millions)', 'source': 'Statista'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should click on the source from Statista to get the accurate data.\n",
      "Action: Click on the source from Statista\n",
      "Action Input: \"Statista\"\u001b[0m\n",
      "Observation: Click on the source from Statista is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the search tool to find the population data for both China and India.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\" and \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Twenty countries with the largest population in 2024 (in millions)', 'source': 'Statista'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should click on the source from Statista to get the accurate data.\n",
      "Action: Click on the source from Statista\n",
      "Action Input: \"Statista\"\u001b[0m\n",
      "Observation: Click on the source from Statista is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the search tool to find the population data for both China and India.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\" and \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Twenty countries with the largest population in 2024 (in millions)', 'source': 'Statista'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should click on the source from Statista to get the accurate data.\n",
      "Action: Click on the source from Statista\n",
      "Action Input: \"Statista\"\u001b[0m\n",
      "Observation: Click on the source from Statista is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the search tool to find the population data for both China and India.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\" and \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Twenty countries with the largest population in 2024 (in millions)', 'source': 'Statista'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should click on the source from Statista to get the accurate data.\n",
      "Action: Click on the source from Statista\n",
      "Action Input: \"Statista\"\u001b[0m\n",
      "Observation: Click on the source from Statista is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The population of China in 2024 is estimated to be 1,425,289,376 people, which is more than the estimated population of India in 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Search the data in google. and answer is it more or less than India?',\n",
       " 'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is estimated to be 1,425,289,376 people.',\n",
       " 'output': 'The population of China in 2024 is estimated to be 1,425,289,376 people, which is more than the estimated population of India in 2024.'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"Search the data in google. and answer is it more or less than India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6539886a-230d-497e-bcf3-1f60fc6d607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'chat_history': 'Human: What is the population of China in 2024?\\n'\n",
      "                 'AI: The population of China in 2024 is estimated to be '\n",
      "                 '1,425,289,376 people.\\n'\n",
      "                 'Human: Search the data in google. and answer is it more or '\n",
      "                 'less than India?\\n'\n",
      "                 'AI: The population of China in 2024 is estimated to be '\n",
      "                 '1,425,289,376 people, which is more than the estimated '\n",
      "                 'population of India in 2024.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff3ddfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I should use the search tool to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"population of China\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'China', 'population': '1.412 billion', 'year': '2022'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should confirm the year of the population data.\n",
      "Action: Search\n",
      "Action Input: \"population of China in 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.43 billion\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The population of China in 2024 is estimated to be 1,425,289,376 people.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the population in Chima?',\n",
       " 'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is estimated to be 1,425,289,376 people.\\nHuman: Search the data in google. and answer is it more or less than India?\\nAI: The population of China in 2024 is estimated to be 1,425,289,376 people, which is more than the estimated population of India in 2024.',\n",
       " 'output': 'The population of China in 2024 is estimated to be 1,425,289,376 people.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"what is the population in Chima?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e01167-55ca-4ba1-836d-c00e648e4634",
   "metadata": {},
   "source": [
    "## 2. Long term memory with vector storage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c1f37-7026-4d59-bf87-70c94eed7afa",
   "metadata": {},
   "source": [
    "In this section, we are going to embed the famous Harry Potter book's first chapter into a vectorstore and try some similarity searches. We have some extra examples commented, you can uncomment and try them one-by-one. If you observe the results carefully, you may find the characteristics of similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc75f3-1fd9-4076-8a3f-d809b7dbf572",
   "metadata": {},
   "source": [
    "### 2.1 Loaders and Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d598ad",
   "metadata": {},
   "source": [
    "#### PDF Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5cac64c7-69dc-4450-b2fa-ffd05740411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "data = PyPDFLoader(\"/share/lab4/harry-potter-chap-1.pdf\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43a7e514-29b0-44ad-afbd-529f67296153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 16 document(s) in your data\n",
      "There are 1848 characters in doc 0\n",
      "There are 2101 characters in doc 1\n",
      "There are 2093 characters in doc 2\n",
      "There are 1898 characters in doc 3\n",
      "There are 1892 characters in doc 4\n",
      "There are 1300 characters in doc 5\n",
      "There are 1867 characters in doc 6\n",
      "There are 1806 characters in doc 7\n",
      "There are 1548 characters in doc 8\n",
      "There are 1573 characters in doc 9\n",
      "There are 1635 characters in doc 10\n",
      "There are 1792 characters in doc 11\n",
      "There are 1542 characters in doc 12\n",
      "There are 1399 characters in doc 13\n",
      "There are 1882 characters in doc 14\n",
      "There are 1921 characters in doc 15\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "i = 0\n",
    "for d in data:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2396be0",
   "metadata": {},
   "source": [
    "#### Text file loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c50f2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "union = TextLoader(\"/share/lab4/state_of_the_union.txt\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caf81f",
   "metadata": {},
   "source": [
    "#### Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce5a0a",
   "metadata": {},
   "source": [
    "From Langchain documents: \n",
    "\n",
    "RecursiveCharacterTextSplitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e29fd56-3275-4041-ad1c-63f71a9d0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have some trials with different chunk_size and chunk_overlap.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=30)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1a8d1fe-d24c-443d-bf68-43bdb0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 68 documents\n",
      "CHAPTER ONE  \n",
      " \n",
      "THE BOY WHO LIVED  \n",
      " \n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud\n",
      "=========\n",
      "have a very large mustac he. Mrs. Dursley was thin and blonde and had  \n",
      "nearly twice the usual amoun\n",
      "=========\n",
      "think they could bear it if anyone found out about the Potters. Mrs.  \n",
      "Potter was Mrs. Dursley's sis\n",
      "=========\n",
      "Potters had a small son, too, but they had never even seen him. This boy  \n",
      "was another good reason f\n",
      "=========\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "screaming  \n",
      "Dudley into his high cha\n",
      "=========\n",
      "into his car and backed out of number four's drive.  \n",
      " \n",
      "It was on the corner of the street that he n\n",
      "=========\n",
      "stared at the cat. It stared  back. As Mr. Dursley drove around the  \n",
      "corner and up the road, he wat\n",
      "=========\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the us\n",
      "=========\n",
      "wheel and his eyes fell on a huddle of these weirdos standing quite  \n",
      "close by. They were whispering\n",
      "=========\n",
      "nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "silly stunt -- these peop\n",
      "=========\n",
      "on drills that morning. He didn't see the owls swoop ing past in broad  \n",
      "daylight, though people dow\n",
      "=========\n",
      "very good mood until lunchtime, when he thought he'd stretch his legs  \n",
      "and wal k across the road to\n",
      "=========\n",
      "caught a few words of what they were saying.  \n",
      " \n",
      "\"The Potters, that's right, that's what I heard yes\n",
      "=========\n",
      "receiver back down and stroked his mustache, thinking... no, he was  \n",
      "being stupid. Potter wasn't su\n",
      "=========\n",
      "of it, he wasn't even sure his nephew was called Harry. He'd never even  \n",
      "seen the boy. It might hav\n",
      "=========\n",
      "he walked straight into someone just outside the door.  \n",
      " \n",
      "\"Sorry,\" he grunted, as the tiny old man \n",
      "=========\n",
      "for nothing could upset me today! Rejo ice, for You -Know -Who has gone \n",
      "at \n",
      "last! Even Muggles like\n",
      "=========\n",
      "he was imagining things, which he had never hoped before, because he  \n",
      "didn't approve of imagination\n",
      "=========\n",
      "stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
      "=========\n",
      "to pull himself together, he let himself into the house. He was still  \n",
      "determined not to mention  a\n",
      "=========\n",
      "\"And finally, bird -watchers everywhere have reported that the nation's  \n",
      "owls have been behaving ve\n",
      "=========\n",
      "Going  \n",
      "to be any more showers of owls tonight, Jim?\"  \n",
      " \n",
      "\"Well, Ted,\" said the weatherman, \"I don't\n",
      "=========\n",
      "Mr. Dursley sat frozen in his armchair. Shooting stars all over Britain?  \n",
      "Owls flying by daylight? \n",
      "=========\n",
      "As he had expected, Mrs. Durs ley looked shocked and angry. After all,  \n",
      "they normally pretended she\n",
      "=========\n",
      "know... her crowd.\"  \n",
      " \n",
      "Mrs. Dursley sipped her tea through pursed lips. Mr. Dursley wondered  \n",
      "whet\n",
      "=========\n",
      "\"Oh, yes,\" said Mr. Dursley, his heart sinking horribly. \"Yes, I quite  \n",
      "agree.\"  \n",
      " \n",
      "He didn't say a\n",
      "=========\n",
      "Potters? If it did... if it got out  that they were related to a pair of  \n",
      "-- well, he didn't think \n",
      "=========\n",
      "them and their kind.... He couldn't see how he and Petunia could get  \n",
      "mixed up in a nything that mi\n",
      "=========\n",
      "Privet Drive. It didn't so much as quiver when a car door slammed on the  \n",
      "next street, nor when two\n",
      "=========\n",
      "thin, and very old, judging by the silver of his hair and beard, which  \n",
      "were both long enough to tu\n",
      "=========\n",
      "Albus Dumbledore didn't seem to realize that he had just arrived in  a\n",
      "=========\n",
      "street where everything from his name to his boots was unwelcome. He \n",
      "was \n",
      "busy rummaging in his clo\n",
      "=========\n",
      "silver cigarette lighter. He flicked it open, held it up in the air, and  \n",
      "clicked it. The nearest s\n",
      "=========\n",
      "eyed  \n",
      "Mrs. Dursley, they wouldn't be able to see anything that was happening  \n",
      "down on the pavement\n",
      "=========\n",
      "at a rather severe -looking woman who was wearing square glasses exactly  \n",
      "the shape of the markings\n",
      "=========\n",
      "Professor McGona gall. \n",
      " \n",
      "\"All day? When you could have been celebrating? I must have passed a  \n",
      "doz\n",
      "=========\n",
      "of owls... shooting stars.... Well, they're not completely st upid. They  \n",
      "were bound to notice some\n",
      "=========\n",
      "the streets in broad daylight, not even dressed in Muggle clothes,  \n",
      "swapping rumors.\"  \n",
      " \n",
      "She threw\n",
      "=========\n",
      "for. Would you care for a lemon drop?\"  \n",
      " \n",
      "\"A what?\"  \n",
      " \n",
      "\"A lemon drop. They're a kind of Muggle swe\n",
      "=========\n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment \n",
      "=========\n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You\n",
      "=========\n",
      "never have.\"  \n",
      " \n",
      "\"Only because you're too -- well -- noble to use them.\"  \n",
      " \n",
      "\"It's lucky it's dark. \n",
      "=========\n",
      "anxious to discuss, the real reason she had been waiting on a cold, hard  \n",
      "wall all day, for neither\n",
      "=========\n",
      "Dumbledore with such a piercin g stare as she did now. It was plain that  \n",
      "whatever \"everyone\" was s\n",
      "=========\n",
      "Dumbledore bowed his head. Professor McGonagall gasped.  \n",
      " \n",
      "\"Lily and James...  I can't believe it..\n",
      "=========\n",
      "but they're saying that when he couldn't kill Harry Potter, Voldemort's  \n",
      "power somehow broke -- and\n",
      "=========\n",
      "Professor McGonagall pulled out a lace handkerchief and dabbed at her  \n",
      "eyes beneath her spectacles.\n",
      "=========\n",
      "It had twelve hands but no numbers; instead, little planets were moving  \n",
      "around the edge. It must h\n",
      "=========\n",
      "he has left now.\"  \n",
      " \n",
      "\"You don't mean -- you can't mean the people who live here?\" cried  \n",
      "Professor\n",
      "=========\n",
      "uncle will be able to explain everything to him when he's older. I've  \n",
      "written them a letter.\"  \n",
      " \n",
      "\n",
      "=========\n",
      "in our world will know his name!\"  \n",
      " \n",
      "\"Exactly,\" said Dumbledore, looking very seriously over the  t\n",
      "=========\n",
      "Professor McGonagall opened her mouth, changed her mind, swallowed, \n",
      "and \n",
      "then said, \"Yes -- yes, yo\n",
      "=========\n",
      "\"I'm not saying his heart isn't in the right place,\" said Professor  \n",
      "McG onagall grudgingly, \"but y\n",
      "=========\n",
      "them.  \n",
      " \n",
      "If the motorcycle was huge, it was nothing to the man sitting astride  \n",
      "it. He was almost \n",
      "=========\n",
      "of blankets.  \n",
      " \n",
      "\"Hagrid,\" said Dumbledore, sounding relieved. \"At last. And where did  \n",
      "you get tha\n",
      "=========\n",
      "carefully off  the motorcycle as he spoke. \"Young Sirius Black lent it to  \n",
      "me. I've got him, sir.\" \n",
      "=========\n",
      "tuft of jet -black hair over his forehead they could see a curiously  \n",
      "shaped cut, like a bol t of l\n",
      "=========\n",
      "Dumbledore took Harry in his arms and turned toward the Dursleys' \n",
      "house.  \n",
      " \n",
      "\"Could I -- could I sa\n",
      "=========\n",
      "burying his face in it. \"But I c -c-can't stand it -- Lily an' James dead  \n",
      "-- an' poor little Harry\n",
      "=========\n",
      "of his cloak,  tucked it inside Harry's blankets, and then came back to  \n",
      "the other two. For a full \n",
      "=========\n",
      "\"Yeah,\" said Hagrid in a very muffled voice, \"I'll be takin' Sirius his  \n",
      "bike back. G'night, Profes\n",
      "=========\n",
      "Dumbledore turned and walked back down the street. On the corner he  \n",
      "stopped and took out the silve\n",
      "=========\n",
      "of his cloak, he was gone.\n",
      "=========\n",
      "A breeze ruffled the neat hedges of Privet Drive, which lay silent and  \n",
      "tidy under the inky sky, th\n",
      "=========\n",
      "bottles, nor that he would spend the next few weeks being prodded and  \n",
      "pinched by his cousin Dudley\n",
      "=========\n",
      "all. The sun rose on the same tidy front gardens and lit up the brass  \n",
      "number four on the Dursleys'\n",
      "=========\n",
      "large pink beac h ball wearing different -colored bonnets -- but Dudley  \n",
      "Dursley was no longer a ba\n",
      "=========\n",
      "long. His Aunt Petunia was awake and it was her shrill voice that made\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')\n",
    "\n",
    "for t in texts:\n",
    "    print(t.page_content[:100])\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515d70a",
   "metadata": {},
   "source": [
    "There are different kinds of splitters.  \n",
    "\n",
    "https://chunkviz.up.railway.app/ \n",
    "\n",
    "provides a great tool to see the splitter differences with different chunk_size and chunk_overlap settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a6a49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document(s) in data_1\n",
      "There are 457834 characters in doc 0\n",
      "=======================\n",
      "You have 327 document(s) in data_2\n",
      "There are 462967 characters in doc\n",
      "=======================\n",
      "You have 1 document(s) in data_3\n",
      "There are 498350 characters in doc 0\n",
      "========================\n",
      "You have 1 document(s) in data_4\n",
      "There are 457834 characters in doc 0\n",
      "=========================\n",
      "So, PDFMinerLoader behaves best.\n"
     ]
    }
   ],
   "source": [
    "#### Your TASK ####\n",
    "# Try different PDF Loaders.  Which one works the best for this file /share/lab4/hp-book1.pdf ,\n",
    "# which contains the full book of Harry Potter Book 1, with all the illustratons.\n",
    "\n",
    "## Langchain provides many other options for loaders, read the documents to find out the differences\n",
    "# See page https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf\n",
    "\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader\n",
    "loader_1 = UnstructuredPDFLoader(\"/share/lab4/hp-book1.pdf\")\n",
    "data_1 = loader_1.load()\n",
    "print (f'You have {len(data_1)} document(s) in data_1')\n",
    "i = 0\n",
    "for d in data_1:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1\n",
    "\n",
    "print(\"=======================\")\n",
    "\n",
    "loader_2 = PyPDFLoader(\"/share/lab4/hp-book1.pdf\")\n",
    "data_2 = loader_2.load()\n",
    "print (f'You have {len(data_2)} document(s) in data_2')\n",
    "i = 0\n",
    "m = 0\n",
    "for d in data_2:\n",
    "    i += 1\n",
    "    m += len(d.page_content)\n",
    "print(f'There are {m} characters in doc')\n",
    "\n",
    "print(\"=======================\")\n",
    "\n",
    "loader_3 = PDFMinerLoader(\"/share/lab4/hp-book1.pdf\")\n",
    "data_3 = loader_3.load()\n",
    "print (f'You have {len(data_3)} document(s) in data_3')\n",
    "i = 0\n",
    "for d in data_3:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1\n",
    "\n",
    "print(\"========================\")\n",
    "\n",
    "loader_4 = OnlinePDFLoader(\"/share/lab4/hp-book1.pdf\")\n",
    "data_4 = loader_4.load()\n",
    "print (f'You have {len(data_4)} document(s) in data_4')\n",
    "i = 0\n",
    "for d in data_4:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1\n",
    "\n",
    "print(\"=========================\")\n",
    "\n",
    "print(f'So, PDFMinerLoader behaves best.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c23cf-0d0a-4f79-9718-42d093fc4dd0",
   "metadata": {},
   "source": [
    "### 2.2 Create embeddings of your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1bbf6",
   "metadata": {},
   "source": [
    "Embedding is a model that turns a sentence into vectors, so that we can \"semantically search\" for related splits of a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd92c90b-7f21-4c8b-9586-41abf20b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI embedding: slow and expensive, we do not use them here.  \n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# openai_embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08ee572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Let's use the local ones.\n",
    "# We have downloaded a number of popular embedding models for you, in the /share/embedding directory, including\n",
    "# LaBSE\n",
    "# all-MiniLM-L12-v2\n",
    "# all-MiniLM-L6-v2\n",
    "# paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "minilm_embedding = SentenceTransformerEmbeddings(model_name=\"/share/embedding/all-MiniLM-L6-v2/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b805c79-c5b1-4812-9b85-671820ff0a69",
   "metadata": {},
   "source": [
    "### 2.4  Store and retrieve the embeddings in ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0c49f-541a-44da-8f5b-1e6059b478a6",
   "metadata": {},
   "source": [
    "You can search documents stored in \"Vector DBs\" by their semantic similarity.  Vector DBs uses an algorithm called \"KNN (k-nearest neighbors)\" to find documents whose embedding is the closest to the query. \n",
    "\n",
    "We first introduce ChromaDB becauase it runs locally, easy-to-set-up, and best of all, free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2af187c9-e90d-40be-a74f-db620af2bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings and save the embeddings into ChromaDB\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "chroma_dir = \"/scratch2/chroma_db\"\n",
    "docsearch_chroma = Chroma.from_documents(texts, \n",
    "                                         minilm_embedding, \n",
    "                                         collection_name='harry-potter', \n",
    "                                         persist_directory=chroma_dir,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "51465f59-49ed-45a5-832a-1f03b9560c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions from https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Books/Philosopher%27s_Stone/Chapter_1\n",
    "# you can try yourself\n",
    "\n",
    "# query = 'Why would the Dursleys consider being related to the Potters a \"shameful secret\"?'\n",
    "# query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "query = 'What might a \"Muggle\" be?'\n",
    "# query = 'What exactly is the cat on Privet Drive?'\n",
    "# query = '''Who might \"You-Know-Who\" be? Why isn't this person referred to by a given name?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34cf7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A utiity function ...\n",
    "def print_search_results(docs):\n",
    "    print(f\"search returned %d results. \" % len(docs))\n",
    "    for doc in docs:\n",
    "        print(doc.page_content)\n",
    "        print(\"=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c24069d5-19d6-477b-a3ba-c79b6cd39d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "Hes not going, he said. \n",
      "Hagrid grunted. \n",
      "Id like ter see a great Muggle like you stop him, he said. \n",
      "A what? said Harry, interested. \n",
      "\n",
      "(cid:145) 52 (cid:145) \n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\fTHE  KEEPER  OF  THE  KEYS \n",
      "\n",
      "A  Muggle,  said  Hagrid,  its  what  we  call  nonmagic  folk  like \n",
      "them. An its your bad luck you grew up in a family o the biggest \n",
      "Muggles I ever laid eyes on. \n",
      "\n",
      "We  swore  when  we  took  him  in  wed  put  a  stop  to  that  rub-\n",
      "bish, said Uncle Vernon, swore wed stamp it out of him! Wizard \n",
      "indeed!\n",
      "=============\n",
      "But there arent wild dragons in Britain? said Harry. \n",
      "Of  course  there  are,  said  Ron.  Common  Welsh  Green  and \n",
      "Hebridean  Blacks.  The  Ministry  of  Magic  has  a  job  hushing  them \n",
      "up, I can tell you. Our kind have to keep putting spells on Muggles \n",
      "whove spotted them, to make them forget. \n",
      "\n",
      "So what on earths Hagrid up to? said Hermione. \n",
      "\n",
      "When  they  knocked  on  the  door  of  the  gamekeepers  hut  an  hour \n",
      "later,  they  were  surprised  to  see  that  all  the  curtains  were  closed. \n",
      "Hagrid called Who is it? before he let them in, and then shut the \n",
      "door quickly behind them.\n",
      "=============\n",
      "for. Would you care for a lemon drop?\"  \n",
      " \n",
      "\"A what?\"  \n",
      " \n",
      "\"A lemon drop. They're a kind of Muggle sweet I'm rather fond of\"\n",
      "=============\n",
      "for. Would you care for a lemon drop?\"  \n",
      " \n",
      "\"A what?\"  \n",
      " \n",
      "\"A lemon drop. They're a kind of Muggle sweet I'm rather fond of\"\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# semantic similarity search\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a21737",
   "metadata": {},
   "source": [
    "#### Saving and Loading your ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56bd7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local disk\n",
    "docsearch_chroma.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd053d53-d5a0-4e1f-8d56-69acb51d6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from disk\n",
    "docsearch_chroma_reloaded = Chroma(persist_directory = chroma_dir,\n",
    "                                   collection_name = 'harry-potter', \n",
    "                                   embedding_function = minilm_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ff1f853-d04e-4bae-8bf2-bddec2d4326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "But  on  the  edge  of  town,  drills  were  driven  out  of  his  mind  by \n",
      "something  else.  As  he  sat  in  the  usual  morning  traffic  jam,  he \n",
      "couldnt  help  noticing  that  there  seemed  to  be  a  lot  of  strangely \n",
      "dressed  people  about.  People  in  cloaks.  Mr.  Dursley  couldnt  bear \n",
      "people  who  dressed  in  funny  clothes    the  getups  you  saw  on \n",
      "young  people!  He  supposed  this  was  some  stupid  new  fashion.  He \n",
      "drummed  his  fingers  on  the  steering  wheel  and  his  eyes  fell  on  a \n",
      "huddle  of  these  weirdos  standing  quite  close  by.  They  were  whis-\n",
      "pering  excitedly  together.  Mr.  Dursley  was  enraged  to  see  that  a\n",
      "=============\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help  \n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getups you saw on young people! He supposed this  \n",
      "was some stupi d new fashion. He drummed his fingers on the steering\n",
      "=============\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help  \n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getups you saw on young people! He supposed this  \n",
      "was some stupi d new fashion. He drummed his fingers on the steering\n",
      "=============\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help  \n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getups you saw on young people! He supposed this  \n",
      "was some stupi d new fashion. He drummed his fingers on the steering\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# you can test with the previous or another query\n",
    "\n",
    "query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd8cdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your TASK ####\n",
    "# With the chosen PDF loaders, test different splitters and chunk size until you feel that the chucking makes sense. \n",
    "# You can also try different embeddings\n",
    "# Then embed the entire book 1 into ChormaDB\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=30)\n",
    "texts = text_splitter.split_documents(data_3)\n",
    "\n",
    "chroma_dir = \"/scratch2/chroma_db\"\n",
    "docsearch_chroma = Chroma.from_documents(texts, \n",
    "                                         minilm_embedding, \n",
    "                                         collection_name='harry-potter-book1', \n",
    "                                         persist_directory=chroma_dir,\n",
    "                                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa211d6-014a-4b99-8c79-1699557e0fe1",
   "metadata": {},
   "source": [
    "### 2.5 Query those docs with a QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4050ea43-6af4-4617-8c2e-c3b550336fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f035d818-b8cf-4d49-9a6f-ba233e204188",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9db75a21-9f02-4e09-98ef-81c40d6e04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How did Harry's parents die?\"\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98270f41-fddd-4be0-909d-c80345e98470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Some  say  he  died.  Codswallop,  in  my  opinion.  Dunno  if  he \n",
      "had enough human left in him to die. Some say hes still out there, \n",
      "bidin  his  time,  like,  but  I  don  believe  it.  People  who  was  on  his \n",
      "side  came  back  ter  ours.  Some  of  em  came  outta  kinda  trances. \n",
      "Don reckon they couldve done if he was comin back. \n",
      "\n",
      "Most  of  us  reckon  hes  still  out  there  somewhere  but  lost  his \n",
      "powers. Too weak to carry on. Cause somethin about you finished \n",
      "him,  Harry.  There  was  somethin  goin  on  that  night  he  hadnt \n",
      "counted on  I dunno what it was, no one does  but somethin \n",
      "about you stumped him, all right.\n",
      "\n",
      "needs reminding of that on his first day at school. \n",
      "\n",
      "All right, keep your hair on. \n",
      "A whistle sounded. \n",
      "Hurry  up!  their  mother  said,  and  the  three  boys  clambered \n",
      "onto the train. They leaned out of the window for her to kiss them \n",
      "good-bye, and their younger sister began to cry. \n",
      "Dont, Ginny, well send you loads of owls. \n",
      "Well send you a Hogwarts toilet seat. \n",
      "George! \n",
      "Only joking, Mom. \n",
      "The train began to move. Harry saw the boys mother waving  \n",
      "\n",
      "(cid:145) 97 (cid:145) \n",
      "\n",
      " \n",
      "\fCHAPTER  SIX \n",
      "\n",
      "and their sister, half laughing, half crying, running to keep up with \n",
      "the  train  until  it  gathered  too  much  speed,  then  she  fell  back  and \n",
      "waved.\n",
      "\n",
      "Harry  watched  the  girl  and  her  mother  disappear  as  the  train \n",
      "rounded  the  corner.  Houses  flashed  past  the  window.  Harry  felt  a \n",
      "great leap of excitement. He didnt know what he was going to  \n",
      "but it had to be better than what he was leaving behind. \n",
      "\n",
      "The  door  of  the  compartment  slid  open  and  the  youngest  red-\n",
      "\n",
      "headed boy came in. \n",
      "\n",
      "Anyone  sitting  there?  he  asked,  pointing  at  the  seat  opposite \n",
      "\n",
      "Harry. Everywhere else is full. \n",
      "\n",
      "Harry  shook  his  head  and  the  boy  sat  down.  He  glanced  at \n",
      "Harry  and  then  looked  quickly  out  of  the  window,  pretending  he \n",
      "hadnt looked. Harry saw he still had a black mark on his nose.\n",
      "\n",
      "AAAARGH! \n",
      "Quirrell  rolled  off  him,  his  face  blistering,  too,  and  then  Harry \n",
      "knew:  Quirrell  couldnt  touch  his  bare  skin,  not  without  suffering \n",
      "terrible pain  his only chance was to keep hold of Quirrell, keep \n",
      "him in enough pain to stop him from doing a curse. \n",
      "\n",
      "Harry jumped to his feet, caught Quirrell by the arm, and hung \n",
      "on as tight as he could. Quirrell screamed and tried to throw Harry \n",
      "off  the pain in Harrys head was building  he couldnt see  \n",
      "he  could  only  hear  Quirrells  terrible  shrieks  and  Voldemorts  yells \n",
      "of,  KILL  HIM!  KILL  HIM!  and  other  voices,  maybe  in  Harrys \n",
      "own head, crying, Harry! Harry!\n",
      "\n",
      "Question: How did Harry's parents die?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Harry's parents were killed by Lord Voldemort, a powerful dark wizard.\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43d0d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "(cid:145) 1 (cid:145) \n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\fCHAPTER  ONE \n",
      "\n",
      "They didnt think they could bear it if anyone found out about the \n",
      "Potters.  Mrs.  Potter  was  Mrs.  Dursleys  sister,  but  they  hadnt  met \n",
      "for  several  years;  in  fact,  Mrs.  Dursley  pretended  she  didnt  have  a \n",
      "sister, because her sister and her good-for-nothing husband were as \n",
      "unDursleyish  as  it  was  possible  to  be.  The  Dursleys  shuddered  to \n",
      "think  what  the  neighbors  would  say  if  the  Potters  arrived  in  the \n",
      "street. The Dursleys knew that the Potters had a small son, too, but \n",
      "they  had  never  even  seen  him.  This  boy  was  another  good  reason \n",
      "for keeping the Potters away; they didnt want Dudley mixing with \n",
      "a child like that.\n",
      "\n",
      "(cid:145) 1 (cid:145) \n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "\fCHAPTER  ONE \n",
      "\n",
      "They didnt think they could bear it if anyone found out about the \n",
      "Potters.  Mrs.  Potter  was  Mrs.  Dursleys  sister,  but  they  hadnt  met \n",
      "for  several  years;  in  fact,  Mrs.  Dursley  pretended  she  didnt  have  a \n",
      "sister, because her sister and her good-for-nothing husband were as \n",
      "unDursleyish  as  it  was  possible  to  be.  The  Dursleys  shuddered  to \n",
      "think  what  the  neighbors  would  say  if  the  Potters  arrived  in  the \n",
      "street. The Dursleys knew that the Potters had a small son, too, but \n",
      "they  had  never  even  seen  him.  This  boy  was  another  good  reason \n",
      "for keeping the Potters away; they didnt want Dudley mixing with \n",
      "a child like that.\n",
      "\n",
      "They didnt think they could bear it if anyone found out about the \n",
      "Potters.  Mrs.  Potter  was  Mrs.  Dursleys  sister,  but  they  hadnt  met \n",
      "for  several  years;  in  fact,  Mrs.  Dursley  pretended  she  didnt  have  a \n",
      "sister, because her sister and her good-for-nothing husband were as \n",
      "unDursleyish  as  it  was  possible  to  be.  The  Dursleys  shuddered  to \n",
      "think  what  the  neighbors  would  say  if  the  Potters  arrived  in  the \n",
      "street. The Dursleys knew that the Potters had a small son, too, but \n",
      "they  had  never  even  seen  him.  This  boy  was  another  good  reason \n",
      "for keeping the Potters away; they didnt want Dudley mixing with \n",
      "a child like that.\n",
      "\n",
      "They didnt think they could bear it if anyone found out about the \n",
      "Potters.  Mrs.  Potter  was  Mrs.  Dursleys  sister,  but  they  hadnt  met \n",
      "for  several  years;  in  fact,  Mrs.  Dursley  pretended  she  didnt  have  a \n",
      "sister, because her sister and her good-for-nothing husband were as \n",
      "unDursleyish  as  it  was  possible  to  be.  The  Dursleys  shuddered  to \n",
      "think  what  the  neighbors  would  say  if  the  Potters  arrived  in  the \n",
      "street. The Dursleys knew that the Potters had a small son, too, but \n",
      "they  had  never  even  seen  him.  This  boy  was  another  good  reason \n",
      "for keeping the Potters away; they didnt want Dudley mixing with \n",
      "a child like that.\n",
      "\n",
      "Question: Why is Harry left with the Dursleys rather than a Wizard family?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Harry is left with the Dursleys because his parents, who were wizards, were killed by the dark wizard, Voldemort. The Dursleys are his only living relatives and the only ones who can protect him from Voldemort.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "\n",
    "# Rebuild the chain from the whole book ChromaDB.  Test with one of the following questions (of your choice).\n",
    "\n",
    "#query = 'Why does Dumbledore believe the celebrations may be premature?'\n",
    "query = 'Why is Harry left with the Dursleys rather than a Wizard family?'\n",
    "#query = 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=30)\n",
    "texts = text_splitter.split_documents(data_3)\n",
    "\n",
    "chroma_dir = \"/scratch2/chroma_db\"\n",
    "docsearch_chroma = Chroma.from_documents(texts, \n",
    "                                         minilm_embedding, \n",
    "                                         collection_name='harry-potter-book1', \n",
    "                                         persist_directory=chroma_dir,\n",
    "                                         )\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c4599ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' It is not mentioned what specifically happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "\n",
    "# Using langchain documentation, find out about the map reduce QA chain.\n",
    "# answer the following questions using the chain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=745, chunk_overlap=34)\n",
    "texts = text_splitter.split_documents(data_3)\n",
    "\n",
    "chroma_dir = \"/scratch2/chroma_db\"\n",
    "docsearch_chroma = Chroma.from_documents(texts, \n",
    "                                         minilm_embedding, \n",
    "                                         collection_name='harry-potter-book1', \n",
    "                                         persist_directory=chroma_dir,\n",
    "                                         )\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "query = 'What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?'\n",
    "# query = 'Tell me about Harry Potter and Quidditch during the first year'\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0d396",
   "metadata": {},
   "source": [
    "### 2.6 Using Pinecone, an online vector DB\n",
    "\n",
    "You have many reasons to store your DB online in a SaaS / PaaS service.  For example, \n",
    "- you want to scale the queries to many concurrent users\n",
    "- you want more data reliability without having to worry about DB management\n",
    "- you want to share the DB but without owning any servers\n",
    "\n",
    "If you want to store your embeddings online, try pinecone with the code below. You must go to [Pinecone.io](https://www.pinecone.io/) and set up an account. Then you need to generate an api-key and create an \"index\", this can be done by navigating through the homepage once you've logged in to Pinecone, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0b75f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# initialize pinecone, depends on two environment variables, os.environ['PINECONE_API_KEY'] and os.environ['PINECONE_API_ENV']\n",
    "pinecone.Pinecone()\n",
    "\n",
    "# You should create an index for your vector db.  \n",
    "# The \"dimension\" setting when you create the DB online, should be 1536 for openAI embedding, or 384 for minilm. \n",
    "index_name = \"test01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f04c5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch_pinecone = Pinecone.from_texts(\n",
    "                                [ t.page_content for t in texts ], \n",
    "                                minilm_embedding, \n",
    "                                index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ba00d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Where are your parents? \n",
      "\n",
      "Theyre dead, said Harry shortly. He didnt feel much like go-\n",
      "\n",
      "ing into the matter with this boy. \n",
      "\n",
      "Oh, sorry, said the other, not sounding sorry at all. But they \n",
      "\n",
      "were our kind, werent they?\n",
      "\n",
      "name of heaven did Harry survive?\"\n",
      "\n",
      "And there were his mother and father smiling at him again, and \n",
      "one of his grandfathers nodding happily. Harry sank down to sit on \n",
      "the floor in front of the mirror. There was nothing to stop him from \n",
      "staying here all night with his family. Nothing at all.\n",
      "\n",
      "It's just astounding... of all the things to stop him... but how in the \n",
      "name of heaven did Harry survive?\"\n",
      "\n",
      "Question: How did Harry's parents die?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I don't know.\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)\n",
    "query = \"How did Harry's parents die?\"\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)\n",
    "\n",
    "# we can use the full-book to test 'map-reduce'\n",
    "#chain = load_qa_chain(llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7453fd84-ba39-4f2b-ab23-23b94d45d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didn't realize what he had seen -- then he jerked his head around to \n",
      "look again. There was a tabby cat standing on the corner of Privet\n"
     ]
    }
   ],
   "source": [
    "# query with pinecone\n",
    "query = 'What exactly is the cat on Privet Drive?'\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "print(docs[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "THE  FORBIDDEN  FOREST \n",
      "\n",
      "Harry! Neville burst out, the moment he saw the other two. I \n",
      "was  trying  to  find  you  to  warn  you,  I  heard  Malfoy  saying  he  was \n",
      "going to catch you, he said you had a drag \n",
      "\n",
      "THE  FORBIDDEN  FOREST \n",
      "\n",
      "can  never  die.  Mr.  Potter,  do  you  know  what  is  hidden  in  the \n",
      "school at this very moment? \n",
      "\n",
      "The Sorcerers Stone! Of course  the Elixir of Life! But I dont \n",
      "\n",
      "understand who  \n",
      "\n",
      "Can you think of nobody who has waited many years to return\n",
      "\n",
      "THE  FORBIDDEN  FOREST \n",
      "\n",
      "You  dont  think  theyve  been  hurt,  do  you?  whispered \n",
      "\n",
      "Hermione. \n",
      "\n",
      "I dont care if Malfoy has, but if somethings got Neville . . . its \n",
      "\n",
      "our fault hes here in the first place. \n",
      "\n",
      "The  minutes  dragged  by.  Their  ears  seemed  sharper  than  usual. \n",
      "Harrys  seemed  to  be  picking  up  every  sigh  of  the  wind,  every \n",
      "cracking twig. What was going on? Where were the others? \n",
      "\n",
      "At last, a great crunching noise announced Hagrids return. Mal-\n",
      "foy, Neville, and Fang were with him. Hagrid was fuming. Malfoy, \n",
      "it  seemed,  had  sneaked  up  behind  Neville  and  grabbed  him  as  a \n",
      "joke. Neville had panicked and sent up the sparks.\n",
      "\n",
      "THE  FORBIDDEN  FOREST \n",
      "\n",
      "You  dont  think  theyve  been  hurt,  do  you?  whispered \n",
      "\n",
      "Hermione. \n",
      "\n",
      "I dont care if Malfoy has, but if somethings got Neville . . . its \n",
      "\n",
      "our fault hes here in the first place. \n",
      "\n",
      "The  minutes  dragged  by.  Their  ears  seemed  sharper  than  usual. \n",
      "Harrys  seemed  to  be  picking  up  every  sigh  of  the  wind,  every \n",
      "cracking twig. What was going on? Where were the others? \n",
      "\n",
      "At last, a great crunching noise announced Hagrids return. Mal-\n",
      "foy, Neville, and Fang were with him. Hagrid was fuming. Malfoy, \n",
      "it  seemed,  had  sneaked  up  behind  Neville  and  grabbed  him  as  a \n",
      "joke. Neville had panicked and sent up the sparks.\n",
      "\n",
      "Question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Harry, Hermione, and Neville were in the Forbidden Forest and Neville warned them that Malfoy was planning to catch them. Later, Hagrid returned with Malfoy, Neville, and Fang, and it was revealed that Malfoy had grabbed Neville as a joke, causing Neville to panic and send up sparks.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "# modify the QA chain in Section 2.5 (Chapter 1 only) to use pinecone instead of ChromaDB\n",
    "data_5 = PDFMinerLoader(\"/share/lab4/harry-potter-chap-1.pdf\").load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1247, chunk_overlap=102)\n",
    "texts = text_splitter.split_documents(data_5)\n",
    "\n",
    "docsearch_pinecone = Pinecone.from_texts(\n",
    "                                [ t.page_content for t in texts ], \n",
    "                                minilm_embedding, \n",
    "                                index_name=index_name)\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)\n",
    "query = 'What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?'\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc6131-6a1a-40f5-8af0-afc5c723e49e",
   "metadata": {},
   "source": [
    "### 2.7 Use vector store in Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "source": [
    "In this section, we are going to create a simple QA agent that can decide by itself which of the two vectorstores it should switch to for questions of differnent fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "#### Preparing the tools for the agent.\n",
    "\n",
    "We will use our chroma_based Harry Potter vectorDB, and let's create another one containing President Biden's State of the Union speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "949662aa-5044-4899-ba50-5e06ac7df371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "documents = TextLoader('/share/lab4/state_of_the_union.txt').load()\n",
    "texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(documents)\n",
    "docsearch3 = Chroma.from_documents(texts, \n",
    "                                   minilm_embedding, \n",
    "                                   collection_name=\"state-of-union\", \n",
    "                                   persist_directory=\"/scratch2/chroma_db\")\n",
    "docsearch3.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "To allow the agent query these databases, we need to define two RetrievalQA chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ccd41e19-fcff-4358-9374-2b36b29d1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "harry_potter = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch_chroma_reloaded.as_retriever())\n",
    "state_of_union = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                             chain_type=\"stuff\", \n",
    "                                             retriever=docsearch3.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'query': 'Why does McGonagall seem concerned about Harry being raised by the '\n",
      "          'Dursleys?',\n",
      " 'result': \" McGonagall is concerned because she knows that Harry's aunt and \"\n",
      "           'uncle, the Dursleys, are not fond of magic and may not treat Harry '\n",
      "           \"well because of his magical abilities. She also knows that Harry's \"\n",
      "           'cousin, Dudley, is spoiled and may bully Harry.'}\n",
      "\"<class 'dict'>:\"\n",
      "{'query': 'what is the GDP increase last year?',\n",
      " 'result': ' The GDP increase last year was 5.7%.'}\n"
     ]
    }
   ],
   "source": [
    "# Now try both chains\n",
    "\n",
    "print_with_type(harry_potter.invoke('Why does McGonagall seem concerned about Harry being raised by the Dursleys?'))\n",
    "print_with_type(state_of_union.invoke(\"what is the GDP increase last year?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "73957e1e-f3e2-48e6-91db-d669d5cbe3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Harry Potter QA System\",\n",
    "        func=harry_potter.run,\n",
    "        description=\"useful for when you need to answer questions about Harry Potter. Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "source": [
    "Now we can create the Agent giving both chains as tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "11b068ff-d822-44ec-ba63-c47f49b492e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "\n",
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b85245e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to find the answer\n",
      "Action: State of Union QA System\n",
      "Action Input: What did biden say about ketanji brown jackson?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden nominated Ketanji Brown Jackson for the United States Supreme Court.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Biden nominated Ketanji Brown Jackson for the United States Supreme Court.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Biden nominated Ketanji Brown Jackson for the United States Supreme Court.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"What did biden say about ketanji brown jackson?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "497fde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m You should always think about what to do\n",
      "Action: Harry Potter QA System\n",
      "Action Input: 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m It is not explicitly stated in the given context, but it can be inferred that McGonagall is concerned about Harry's well-being and treatment at the hands of the Dursleys, as they are described as neglectful and possibly abusive. Additionally, McGonagall may also be concerned about Harry's lack of knowledge about the wizarding world and his potential vulnerability to dark forces.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m You should always think about what to do\n",
      "Action: State of Union QA System\n",
      "Action Input: 'What were the main topics discussed in the most recent state of the union address?'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The main topics discussed in the most recent state of the union address were the strength of the American people, the progress made in the past year, the future goals for the country, and the need to come together as one nation to overcome challenges.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The main topics discussed in the most recent state of the union address were the strength of the American people, the progress made in the past year, the future goals for the country, and the need to come together as one nation to overcome challenges.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The main topics discussed in the most recent state of the union address were the strength of the American people, the progress made in the past year, the future goals for the country, and the need to come together as one nation to overcome challenges.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85245e2",
   "metadata": {},
   "source": [
    "We can see that the agent can \"smartly\" choose which QA system to use given a specific question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fde49",
   "metadata": {},
   "source": [
    "## 3 Your Task: putting it all together: OpenAI and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "09e6d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Non-Mergeable Sketching for Cardinality Estimation\\nSeth Pettie\\nUniversity of Michigan\\npettie@umich.eduDingyu Wang\\nUniversity of Michigan\\nwangdy@umich.eduLonghui Yin\\nTsinghua University\\nylh17@mails.tsinghua.edu.cn\\nAbstract\\nCardinality estimation is perhaps the simplest non-trivial statistical problem that can be\\nsolved via sketching. Industrially-deployed sketches like HyperLogLog ,MinHash, and PCSAare\\nmergeable , which means that large data sets can be sketched in a distributed environment, and\\nthen merged into a single sketch of the whole data set. In the last decade a variety of sketches\\nhave been developed that are non-mergeable , but attractive for other reasons. They are simpler,', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 0}), Document(page_content='their cardinality estimates are strictly unbiased , and they have substantially lower variance .\\nWe evaluate sketching schemes on a reasonably level playing eld, in terms of their memory-\\nvariance product (MVP). I.e., a sketch that occupies 5mbits and whose relative variance is 2/m\\n(standard error\\n2/m) has an MVPof10. Our contributions are as follows.\\nCohen [14] and Ting [34] independently discovered what we call the Martingale transform\\nfor converting a mergeable sketch into a non-mergeable sketch. We present a simpler way\\nto analyze the limiting MVPofMartingale -type sketches.\\nPettie and Wang proved that the Fishmonger sketch [31] has the best MVP,H0/I01.98,', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 0}), Document(page_content='among a class of mergeable sketches called linearizable sketches. ( H0andI0are precisely\\ndenedconstants.) Weprovethatthe Martingale transformisoptimalinthenon-mergeable\\nworld, and that Martingale Fishmonger in particular is optimal among linearizable sketches,\\nwith an MVPofH0/21.63. E.g., this is circumstantial evidence that to achieve 1%\\nstandard error, we cannot do better than a 2 kilobyte sketch.\\nMartingale Fishmonger is neither simple nor practical. We develop a new mergeable sketch\\ncalled Curtainthat strikes a nice balance between simplicity and eciency, and prove that\\nMartingale Curtain has limiting MVP2.31. It can be updated with O(1)memory accesses', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 0}), Document(page_content='and it has lower empirical variance than Martingale LogLog , a practical non-mergeable\\nversion of HyperLogLog .\\nThis work was supported by NSF grants CCF-1637546 and CCF-1815316.arXiv:2008.08739v2  [cs.DS]  15 Feb 2021', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 0}), Document(page_content='1 Introduction\\nCardinality estimation1is a fundamental problem in streaming and sketching with diverse applica-\\ntionsindatabases[12,21], networkmonitoring[5,8,11,37], nearestneighborsearch[32], caching[35],\\nand genomics [2,17,30,36]. In the sequential setting of this problem, we receive the elements of a\\nmultiset A={a1,a2,...,aN}one at a time. We maintain a small sketchSof the elements seen so\\nfar, such that the true cardinality =|A|is estimated by some (S). The distributed setting is\\nsimilar, except that Ais partitioned arbitrarily among several machines, the shares being sketched\\nseparately and combined into a sketch of A. Only mergeable sketches are deployed in distributed\\nsettings; see Denition 2 below.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 1}), Document(page_content='settings; see Denition 2 below.\\nDenition 1. In the random oracle model A[U]and we have oracle access to a uniformly\\nrandom permutation h: [U][U](or a uniformly random hash function h: [U][0,1]). In the\\nstandard model we can generate random bits as necessary, but must explicitly store any hash\\nfunctions in the sketch.\\nDenition 2. Suppose A(1),A(2)are multisets such that A=A(1)A(2). A sketching scheme is\\nmergeable if, whenever, A(1),A(2)are sketched as S(1),S(2)(using the same random oracle h\\nor the same source of random bits in the standard model ), the sketch SofAcan be computed\\nfromS(1),S(2)alone.\\nStandard model sketches [1,3,4,6,22,27] usually make an (,)-guarantee, i.e.,\\nPr([(1),(1 +)])\\n<.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 1}), Document(page_content='Pr([(1),(1 +)])\\n<.\\nThe state-of-the-art standard model sketch [6,27] uses O(2log1+ logU)bits, which is\\noptimal at this level of specicity, as it meets the space lower bounds of (logU),(2)(when\\n= (1)), and (2log1)[1,25,26]. However, the leading constants hidden by [6,27] are quite\\nlarge.\\nIn the random oracle model the cardinality estimate typically has negligible bias, and\\nerrors are expressed in terms of the relative variance 2Var(|)orrelative standard deviation\\n1\\nVar(|), also called the standard error . Sketches that use (m)bits typically have relative\\nvariances of O(m). Thus, the most natural way to measure the quality of the sketching scheme', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 1}), Document(page_content='itself is to look at its limiting memory-variance product (MVP), i.e., the product of its memory and\\nvariance as m.\\nUntil about a decade ago, all standard/random oracle sketches were mergeable, and suit-\\nable to both distributed and sequential applications. For reasons that are not clear to us, the idea\\nofnon-mergeable sketching was discovered independently by multiple groups [10,14,24,34] at\\nabout the same time, and quite latein the 40-year history of cardinality estimation. Chen, Cao,\\nShepp, andNguyen[10]inventedthe S-Bitmap in2011, followedbyHelmi, Lumbroso, Martnez, and\\nViolas [24] Recordinality in 2012. In 2014 Cohen [14] and Ting [34] independently invented what', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 1}), Document(page_content='we call the Martingale transform , which is a simple, mechanical way to transform any mergeable\\nsketch into a (better) non-mergeable sketch.2\\nIn a companion paper [31], we analyzed the MVPs ofmergeable sketches under the assumption\\nthat the sketch was compressed to its entropy bound. Fishmonger (an entropy compressed variant\\n1(akaF0estimation or Distinct Elements )\\n2Cohen [14] called these Historical Inverse Probability (HIP) sketches and Ting [34] applied the prex Streaming\\nto emphasize that they can be used in the single-stream setting, not the distributed setting.\\n1', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 1}), Document(page_content='ofPCSAwith a dierent estimator function) was shown to have MVP =H0/I01.98, where\\nH0= (ln 2)1+\\nk=1k1log2(1 + 1/k) andI0=(2) =2/6.\\nFurthermore, H0/I0was shown to be the minimum MVPamonglinearizable sketches, a subset of\\nmergeable sketches that includes all the popular sketches ( HyperLogLog ,PCSA,MinHash, etc.).\\nOur aim in thispaper is to build a useful framework for designing and analyzing non-mergeable\\nsketching schemes, and, following [31], to develop a theory of space-variance optimality in the\\nnon-mergeable world. We work in the random oracle model . Our results are as follows.\\nAlthough the Martingale transform itself is simple, analyzing the variance of these sketches', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 2}), Document(page_content='is not. For example, Cohen [14] and Ting [34] estimated the standard error of Martingale\\nLogLogto be about\\n3/(4m)0.866/mand about1/(2mm), respectively, where\\nthe latter tends to\\nln 2/m0.8326/masm .3We give a general method for\\ndetermining the limiting relative variance of Martingale sketches that is strongly inuenced\\nby Tings perspective.\\nWhat is the most ecient (smallest MVP) non-mergeable sketch for cardinality estimation?\\nThe best Martingale sketches perform better than the ad hocnon-mergeable S-Bitmap and\\nRecordinality , but perhaps there is a completely dierent, better way to systematically build\\nnon-mergeable sketches. We prove that up to some natural assumptions4the best non-', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 2}), Document(page_content='mergeable sketch is a Martingale X sketch, for some X. Furthermore, we prove that Martingale\\nFishmonger , having MVPofH0/21.63, is optimal among all Martingale X sketches, where\\nXislinearizable . This provides some circumstantial evidence that Martingale Fishmonger is\\noptimal, and that if we want, say, 1% standard error, we need to use a H0/2(0.01)2-bit\\nsketch,2 kilobytes.\\nMartingale Fishmonger has an attractive MVP, but it is slow and cumbersome to implement.\\nWe propose a new mergeable sketch called Curtainthat is naturally space ecient and\\neasy to update in O(1)memory accesses, and prove that Martingale Curtain has a limiting\\nMVP2.31.\\n1.1 Prior Work: Mergeable Sketches', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 2}), Document(page_content='MVP2.31.\\n1.1 Prior Work: Mergeable Sketches\\nLetSibe the state of the sketch after processing (a1,...,ai).\\nThe state of the PCSAsketch [20] is a 2D matrix S{0,1}mlogUand the hash function\\nh: [U][m]Z+produces two indices: h(a) = (j,k)with probability m12k.Si(j,k) = 1i\\ni[i].h(ai) = (j,k). Flajolet and Martin [20] proved that a certain estimator has standard error\\n0.78/m, making the MVParound (0.78)2logU0.6 logU.\\nDurand and Flajolets LogLogsketch [16] consists of mcounters. It interprets hexactly as in\\nPCSA, and setsSi(j) =kikis maximum such that i[i].h(ai) = (j,k). Durand and Flajolets\\nestimator is of the form (S)m2m1\\njS(j)and has standard error 1.3/m. Flajolet, Fusy,', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 2}), Document(page_content='Gandouet, and Meuniers HyperLogLog [19] is the same sketch but with the estimator (S)\\nm2(\\nj2S(j))1. They proved that it has standard error tending to 1.04/m. As the space is\\nmlog logUbits, the MVPis1.08 log logU.\\n3Herem=(\\nm\\uf8f6\\n0(\\nlog2(2+u\\n1+u))mdu)1is the coecient of Flajolet et al.s HyperLogLog estimator.\\n4(the sketch is insensitive to duplicates, and the estimator is unbiased)\\n2', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 2}), Document(page_content='Mergeable Sketch Limiting MVP Notes\\nPCSA [20].6 logU38.9 ForU= 264\\nLogLog [16] 1.69 log logU10.11ForU= 264\\nMinCount [9,23,29] logU= 64 ForU= 264\\nHyperLogLog [19] 1.08 log logU6.48ForU= 264\\nFishmonger [31]H0/I01.98\\nNon-Mergeable Sketch\\nS-Bitmap [10]O(log2(U/m ))\\nRecordinality [24]O(log(/m) logU)\\nMartingale PCSA new 0.35 logU22.4ForU= 264\\nMartingale LogLog [14,34] 0.69 log logU4.16ForU= 264\\nMartingale MinCount [14,34] 0.5 logU= 32 ForU= 264\\nMartingale Fishmonger newH0/21.63 H0= (ln 2)1+\\nk1log2(1+1/k)\\nk\\nMartingale Curtain new2.31 Theorem 1 with (q,a,h ) = (2.91,2,1)\\nNon-Mergeable Lower Bound\\nMartingale X newH0/2 Xis alinearizable sketch\\nTable1: Aselectionofresultsoncomposablesketches(top)andnon-composable Martingale sketches', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 3}), Document(page_content='(bottom) in terms of their limiting memory-variance product ( MVP). Logarithms are base 2.\\nThe MinCount sketch (aka MinHash orBottom-m[7,13,15]) stores the smallest mhash values,\\nwhich we assume requires logUbits each. Using an appropriate estimator [9,23,29], the standard\\nerror is 1/mandMVP = logU.\\nIt is straightforward to see that the entropy of PCSAandLogLogare both (m). Scheuermann\\nand Mauve [33] experimented with entropy compressed versions of PCSAand HyperLogLog and\\nfound PCSAto be slightly superior. Rather than use the given estimators of [16,19,20], Lang [28]\\nused Maximum Likelihood-type Estimators and found entropy-compressed PCSAto be signicantly', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 3}), Document(page_content='better than entropy-compressed LogLog(with MLE estimators). Pettie and Wang [31] dened\\nthe Fisher-Shannon ( Fish)5number of a sketch as the ratio of its Shannon entropy (controlling\\nits entropy-compressed size) to its Fisher information (controlling the variance of a statistically\\necient estimator), and proved that the Fish-number of any base- qPCSAisH0/I0, and that the\\nFish-number of base- qLogLogis worse, but tends to H0/I0in the limit as q. HereH0andI0\\nare:\\nH0= (ln 2)1+\\nk=1k1log2(1 + 1/k)\\nandI0=(2) =2/6.\\n1.2 Prior Work: Non-Mergeable Sketches\\nChen, Cao, Shepp, and Nguyens S-Bitmap [10] consists of a bit string S{0,1}mandmknown\\nconstants 00<1<<m1<1. It interprets h(a) = (j,)[m][0,1]as an index jand', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 3}), Document(page_content='realand when processing a, setsS(j)1i> HammingWeight( S). One may conrm that Sis\\ninsensitive to duplicates in the stream A, but its state depends on the orderin whichAis scanned.\\n5Fishis essentially the same as MVP, under the assumption that the sketch state is compressed to its entropy.\\n3', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 3}), Document(page_content='By setting the -thresholds and estimator properly, the standard error is ln(eU/m )/(2m)and\\nMVP =O(log2(U/m )).\\nRecordinality [24] is based on MinCount ; it stores (S,cnt), whereSis themsmallest hash values\\nencountered and cntis thenumber of times thatShas changed. The estimator looks only at cnt,\\nnotS, and has standard error \\nln(/em )/mandMVP =O(log(/m) logU).\\nCohen [14] and Ting [34] independently described how to turn any sketch into a non-mergeable\\nsketch using what we call the Martingale transform. Let Sibe the state of the original sketch after\\nseeing (a1,...,ai)andPi+1= Pr(Si+1=Si|Si,ai+1{a1,...,ai})be the probability that it\\nchanges state upon seeing a newelementai+1.6The state of the Martingale sketch is (Si,i). Upon', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 4}), Document(page_content='processingai+1it becomes (Si+1,i+1), where\\ni+1=i+P1\\ni+1q\\nSi+1=Siy\\n.\\nHereq\\nEy\\nis the indicator variable for the event E. We assume the original sketch is insensitive to\\nduplicates, so\\nE(i+1) ={i whenai+1{a1,...,ai}(and hence Si+1=Si)\\ni+ 1 whenai+1{a1,...,ai}.\\nThus, with 0=0= 0,iis an unbiased estimator of the true cardinality i=|{a1,...,ai}|and\\n(ii)iis amartingale . The Martingale -transformed sketch requires the same space, plus just\\nlogUbits to store the estimate .\\nCohen and Ting [14,34] both proved that Martingale MinCount has standard error 1/(2m)and\\nMVP = (logU)/2. Theygavedierentestimatesforthestandarderrorof Martingale LogLog . Tings\\nestimate is quite accurate, and tends to', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 4}), Document(page_content='estimate is quite accurate, and tends to\\nln 2/masm, giving it an MVP = ln 2 log log U\\n0.69 log logU.\\n1.3 The Dartboard Model\\nThedartboard model [31] is useful for describing cardinality sketches with a single, uniform\\nlanguage. The dartboard model is essentially the same as Tings [34] area cutting process, but with\\na specic, discrete cell partition and state space xed in advance.\\nThedartboard is the unit square [0,1]2, partitioned into a set C={c0,...,c|C|1}ofcellsof\\nvarious sizes. Every cell may be either occupied orunoccupied ; thestateis the set of occupied cells\\nand the state space some S2C.\\nWe process a stream of elements one by one; when a newelement is encountered we throw a', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 4}), Document(page_content='dartuniformly at random at the dartboard and update the state in response. The relationship\\nbetween the state and the dart distribution satises two rules:\\n(R1)Every cell with at least one dart is occupied; occupied cells may contain no darts.\\n(R2)If a dart lands in an occupied cell, the state does not change.\\nAs a consequence of (R1) and (R2), if a dart lands in an empty cell the state mustchange, and\\noccupiedcellsmayneverbecomeunoccupied. Dartthrowingismerelyanintuitivewayofvisualizing\\nthe hash function. Base- qPCSAandLogLoguse the same cell partition but with dierent state\\nspaces; see Figure 1.\\n6These probabilities are over the choice of h(ai+1), which, in the random oracle model , is independent of all\\nother hash values.\\n4', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 4}), Document(page_content='. . .\\n. . .(a) (b) (c)\\nFigure 1: The unit square is partitioned into mcolumns. Each column is partitioned into cells.\\nCelljcovers the vertical interval [q(j+1),qj). (b) The state of a PCSAsketch records precisely\\nwhich cells contain a dart (gray); all others are empty (yellow). (c) The state of the corresponding\\nLogLogsketch.\\nIt was observed [31] that the dartboard model includes all mergeable sketches, and some non-\\nmergeable ones like S-Bitmap .Recordinality and the Martingale sketches obey rules (R1),(R2) but\\nare not strictly dartboard sketches as they maintain some small state information ( cntor) outside\\nof the set of occupied cells. Nonetheless, it is useful to speak of the dartboard part of their state\\ninformation.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 5}), Document(page_content='information.\\n1.4 Linearizable Sketches\\nThe lower bound of [31] applies to linearizable sketches, a subset of mergeable sketches. A sketch\\nis called linearizable if it is possible to encode the occupied/unoccupied status of its cells in some\\nxed linear order (c0,...,c C1), so whether ciis occupied only depends on the status of c0,...,ci1\\nand whether cihas been hit by a dart. (Thus, it is independent of ci+1,...,c C1.) Specically, let\\nYi,Zibe the indicators for whether ciis occupied, and has been hit by a dart, respectively, and\\nYi= (Y0,...,Yi). The state of the sketch is YC1; it is called linearizable if there is some monotone\\nfunction:{0,1}{0,1}such that\\nYi=Zi(Yi1).', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 5}), Document(page_content='function:{0,1}{0,1}such that\\nYi=Zi(Yi1).\\nI.e., if(Yi1) = 1,ciis forced to be occupied and the state is forever independent of Zi.\\nPCSA-type sketches [18,20] are linearizable, as are ( Hyper)LogLog[16,19], and all MinCount ,\\nMinHash, and Bottom-mtype sketches [7,9,13,23,29]. It is very easy to engineer non-linearizable\\nsketches; see [31]. The open problem is whether this is ever a good idea in terms of memory-variance\\nperformance.\\n1.5 Organization\\nIn Section 2 we introduce the Curtainsketch, which is a linearizable (hence mergeable) sketch in\\nthe dartboard model. In Section 3 we prove some general theorems on the bias and asymptotic\\nrelative variance of Martingale -type sketches, and in Section 4 we apply this framework to bound', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 5}), Document(page_content='the limiting MVPofMartingale PCSA ,Martingale Fishmonger , and Martingale Curtain .\\nIn Section 5 we prove some results on the optimality of the Martingale transform itself, and that\\nMartingale Fishmonger has the lowest variance among those based on linearizable sketches.\\n5', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 5}), Document(page_content='. . .\\n. . .(a) (b) (c)\\nFigure 2: (a) The base- qsawtooth cell partition. (b) and (c) depict a Curtainsketch w.r.t.\\nO={3/2,1/2,1/2,3/2}andh= 1. (b) Gray cells contain at least one dart; light yellow cells\\ncontain none. The curtain vcurt= (gi)is highlighted with a pink boundary. (c) Columns that are\\nintensionhave ain their curtain cell. All darkgray cells are occupied and all darkyellow cells\\nare free according to Rule 3. All other cells are occupied/free (light gray, light yellow) according\\nto Rules 1 and 2.\\nSection 6 presents some experimental ndings that demonstrate that the conclusions drawn\\nfrom the asymptotic analysis of Martingale sketches are extremely accurate in the pre-asymptotic', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 6}), Document(page_content='regime as well, and that Martingale Curtain has lower variance than Martingale LogLog .\\n2 The Curtain Sketch\\nDesign Philosophy. Our goal is to strike a nice balance between the simplicity and time-\\neciency of ( Hyper)LogLog, and the superior information-theoretic eciency of PCSA, which can\\nonly be fully realized under extreme (and time-inecient) compression to its entropy bound [28,31].\\nInformally, if we are dedicating at least 1 bit to encode the status of a cell, the bestcells to encode\\nhave mass (1)and we should design a sketch that maximizes the number of such cells encoded.\\nWe assume the dartboard is partitioned into mcolumns; dene Cell(j,i)to be the cell in column', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 6}), Document(page_content='icovering the vertical interval [q(j+1),qj). In a PCSAsketch, the occupied cells are precisely\\nthose with at least one dart. In LogLog, the occupied cells in each column are contiguous, extending\\nto the highest cell containing a dart. In Figure 1, cells are drawn with uniform sizes for clarity.\\nConsider the vector v= (g0,g1,...,gm1)where Cell(gi,i)is the highest occupied cell in\\nLogLog/PCSA. Thecurtainofvw.r.t. allowable osets Ois a vector vcurt= (g0,g1,..., gm1)\\nsuch that (i)i[1,m1].gigi1O, and (ii)vcurtis the minimal such vector dominating\\nv, i.e.,i.gigi. Although we have described vcurtas a function of v, it is clearly possible to\\nmaintainvcurtas darts are thrown, without knowing v.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 6}), Document(page_content='We have an interest in |O|being a power of 2 so that curtain vectors may be encoded eciently,\\nas a series of osets. On the other hand, it is most ecient if Ois symmetric around zero. For\\nthese reasons, we use a base- qsawtooth cell partition of the dartboard; see Figure 2. Henceforth\\nCell(j,i)is dened as usual, except jis an integer when iis even and a half-integer when iis odd.\\nThen the allowable osets are Oa={(a1/2),(a3/2),...,1/2,1/2,...,a3/2,a1/2},\\nfor someathat is a power of 2.\\nLetCell(gi,i)is the highest cell containing a dart in column iin thesawtooth cell partition and\\nvcurt= (gi)be the curtain vector of v= (gi)w.r.t. osets O=Oa. We say column iisin tension if', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 6}), Document(page_content='(,gi1,gi1,gi+1,)is not a valid curtain, i.e., if gigi1= min( O)orgi+1gi= max( O).\\n6', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 6}), Document(page_content='In particular, if column iisnotin tension, then Cell(gi,i)must contain at least one dart, for if it\\ncontained no darts the curtain would be dropped to gi1at columni. However, if column iisin\\ntension, then Cell(gi,i)might not contain a dart.\\nThe Curtainsketch encodes vcurt= (gi)w.r.t. the base- qsawtooth cell partition and osets Oa,\\nand a bit-array b={0,1}hm. This sketch designates each cell occupied orfreeas follows.\\nRule 1. If columniis not in tension then Cell(gi,i)is occupied, and b(,i)encodes the status of the\\nhcells below the curtain, i.e., Cell(gi(j+ 1),i)is occupied i b(j,i) = 1,j{0,...,h1}.\\nRule 2. If columniis in tension, then Cell(gij,i)is occupied i b(j,i) = 1,j{0,...,h1}.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 7}), Document(page_content='Rule 3. Every cell above the curtain is free ( Cell(gi+j,i), whenj1) and all remaining cells are\\noccupied.\\nFigure 2 gives an example of a Curtainsketch, with O={3/2,1/2,1/2,3/2}andh= 1.\\n(The baseqof the cell partition is unspecied in this example.)\\nTheorem 1. Consider the Martingale Curtain sketch with parameters q,a,h(baseq,Oa={(a\\n1/2),...,a1/2}, andb{0,1}hm), and let be its estimate of the true cardinality .\\n1.is an unbiased estimate of .\\n2. The relative variance of is:\\n1\\n2Var(|) =(1 +o/m(1) +om(1))qlnq\\n2m(q1)(q1\\nq+2\\nqh(qa1/21)+1\\nqh+1)\\n,\\nAs a result, the limiting MVPofMartingale Curtain is\\nMVP = (log2(2a) +h)qlnq\\n2(q1)(q1\\nq+2\\nqh(qa1/21)+1\\nqh+1)\\n.\\nProof.Follows from Theorems 3 and 6.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 7}), Document(page_content='qh+1)\\n.\\nProof.Follows from Theorems 3 and 6.\\nHereo/m(1)andom(1)are terms that go to zero as mand/mget large. Recall that for\\npractical reasons we want to parameterize Theorem 1 with aa power of 2 and han integer, but\\nit is realistic to set q >1to be any real. Given these constraints, the optimal setting is q= 2.91,\\na= 2, andh= 1, exactly as in the example in Figure 2. This uses log logU+ 3(m1)bits to store\\nthe sketch proper, logUbits7to store , and achieves a limiting MVP2.31. In other words, to\\nachieve a standard error 1/\\nb, we need about 2.31bbits.\\nImplementation Considerations. We encode a curtain (g0,g1,..., gm1)asg0and an oset\\nvector (o1,o2,...,om1),oi= gigi1, where g0takes log2logqU6bits andoitakes log2|O|=', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 7}), Document(page_content='log2(2a)bits. Clearly, to evaluate giwe need to compute the prex sum g0+\\niioi.\\nLemma 1. Let(x0,...,x1)be a vector of t-bit unsigned integers packed into t/wwords, where\\neach word has w= (log(t))bits. The prex sum\\nj[0,i]xjcan be evaluated in O(t/w + logw)\\ntime.\\n7It is ne to store an approximation ofwithO(logm)bits of precision.\\n7', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 7}), Document(page_content='Proof.W.l.o.g. we can assume i=1, so the task is to sum the entire list. In O((t)/w)\\ntime we can halve the number of summands, by masking out the odd and even summands and\\nadding these vectors together. After halving twice in this way, we have a vector of /4 (t+ 2)-\\nbit integers, each allocated 4tbits. At this point we can halve the number of words by adding\\nthe(2i+ 1)th word to the 2ith word. Thus, if Tw(,t)is the time needed to solve this problem,\\nTw(,t) =Tw(/8,4t) +O((t)/w), which isO((t)/w+ logw).\\nIn our context t= log2(2a) = 2, so even if mis a medium-size constant, say at most 256 or\\n512, we only have to do prex sums over 8 or 16 consecutive 64-bit words. If mis much larger then', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 8}), Document(page_content='it would be prudent to partition the dartboard into m/cindependent curtains, each with c= 256\\nor 512 columns. This keeps the update time independent of mand increases the space overhead\\nnegligibly.\\nWe began this section by highlighting the design philosophy, which emphasizes conceptual\\nsimplicity and eciency. Our encoding uses xed-length codes for the osets, and can be decoded\\nvery eciently by exploiting bit-wise operations and word-level parallelism. That said, we are\\nmainly interested in analyzing the theoretical performance of sketches, and will not attempt an\\nexhaustive experimental evaluation in this work.\\n3 Foundations of the Martingale Transform', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 8}), Document(page_content='3 Foundations of the Martingale Transform\\nIn this section we present a simple framework for analyzing the limiting variance of Martingale\\nsketches, which is strongly inuenced by Tings [34] work. Theorem 2 gives simple unbiased es-\\ntimators for the cardinality and the variance of the the cardinality estimator. The upshot of\\nTheorem 2 is that to analyze the variance of the estimator, we only need to bound E(P1\\nk), where\\nPkis the probability the kth distinct element changes the sketch. Theorem 3 further shows that for\\nsketches composed of msubsketches (like Curtain,HyperLogLog , and PCSA), the limiting variance\\ntends to1\\n2m, whereis a constant that depends on the sketch scheme. Section 4 analyzes the', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 8}), Document(page_content='constantfor each of PCSA,LogLog, and Curtain. Using results of [31] on the entropy of PCSAwe\\ncan calculate the limiting MVPofPCSA,LogLog,Curtain, and Fishmonger .\\n3.1 Martingale Estimators and Retrospective Variance\\nConsider an arbitrary sketch with state space S. We assume the sketch state does not change upon\\nseeing duplicated elements, hence it suces to consider streams of distinctelements. We model\\nthe evolution of the sketch as a Markov chain (Sk)k0S, whereSkis the state after seeing k\\ndistinctelements. Dene Pk= Pr(Sk=Sk1|Sk1)to be the state changing probability , which\\ndepends only on Sk1. In the dartboard terminology Pkis the total size of all unoccupied cells in\\nSk1.\\nDenition 3. Letq\\nEy', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 8}), Document(page_content='Sk1.\\nDenition 3. Letq\\nEy\\nbe the indicator variable for event E. For any0, dene:\\nE=\\nk=1q\\nSk=Sk1y\\n1\\nPk, the martingale estimator,\\nandV=\\nk=1q\\nSk=Sk1y\\n1Pk\\nP2\\nk, the retrospective variance.\\nNote thatE0=V0= 0.\\n8', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 8}), Document(page_content='The Martingale transform of this sketch stores =Ein one machine word and returns it as a\\ncardinality estimate. It can also store Vin one machine word as well. Theorem 2 shows that the\\nretrospective variance Vis a good running estimate of the empirical squared error (E)2.\\nTheorem 2. The martingale estimator Eis an unbiased estimator of and the retrospective\\nvarianceVis an unbiased estimator of Var(E). Specically, we have,\\nE(E) =,and Var(E) =E(V) =\\nk=1E(1\\nPk)\\n.\\nRemark 1. Theorem 2 contradicts Tings claim [34], that Vis unbiased only at jump times ,\\ni.e., thosefor whichS=S1, and therefore inadequate to estimate the variance. In order to', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 9}), Document(page_content='correct for this, Ting introduced a Bayesian method for estimating the time that has passed since\\nthe last jump time. The reason for thinking that jump times are dierent is actually quite natural.\\nSuppose we record the list of distinctstatess0,...,skencountered while inserting elements,\\nbeing unknown, and let pibe the probability of changing from sito some other state. The amount\\nof time spent in state siis a geometric random variable with mean p1\\niand variance (1pi)/p2\\ni.\\nFurthermore, these waiting times are independent. Thus,\\ni[0,k)p1\\niand\\ni[0,k)(1p1\\ni)/p2\\niare\\nunbiased estimates of the cardinality and squared error upon entering state sk. These exactly', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 9}), Document(page_content='correspond to EandV, but they shouldbe biased since they do not take into account the \\nelements that had no eect on sk. As Theorem 2 shows, this is a mathematical optical illusion.\\nThe history is a random variable, and although the last elements did not change the state,\\nthey could have , which would have altered the observed history s0,...,skand hence the estimates\\nEandV.\\nProof of Theorem 2. Note thatPkis a function of Sk1. By the linearity of expectation and the\\nlaw of total expectation, we have\\nE(Ek) =E(E(Ek|Sk1)) =E(\\nE(Ek1|Sk1) +E(q\\nSk=Sk1y\\n1\\nPkSk1))\\n=E(Ek1) + 1 = E(Ek2) + 2 =...=E(E0) +k=k.\\nand\\nE(Vk) =E(E(Vk|Sk1)) =E(\\nE(Vk1|Sk1) +E(q\\nSk=Sk1y\\n1Pk\\nP2\\nkSk1((\\n=E(Vk1) +E(1Pk\\nPk)\\n=E(Vk2) +E(1Pk', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 9}), Document(page_content='=E(Vk1) +E(1Pk\\nPk)\\n=E(Vk2) +E(1Pk\\nPk)\\n+E(1Pk1\\nPk1)\\n=...\\n=E(V0) +k\\ni=1E(1Pi\\nPi)\\n=k\\ni=1E(1\\nPi)\\nk.\\nFor the variance, we have\\nVar(E) =E(E2\\n)(E(E))2=E(E2\\n)2.\\nNote that\\nE(E2\\nk|Sk1) =E((\\nEk1+q\\nSk=Sk1y\\n1\\nPk)\\n2Sk1)\\n=E2\\nk1+ 2Ek1\\nPkE(q\\nSk=Sk1ySk1)\\n+1\\nP2\\nkE(q\\nSk=Sk1y2Sk1)\\n9', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 9}), Document(page_content='=E2\\nk1+ 2Ek1+1\\nPk.\\nThen by the law of total expectation and the linearity of expectation, we have\\nE(\\nE2\\nk)\\n=E(\\nE(\\nE2\\nk|Sk1))\\n=E(\\nE2\\nk1+ 2Ek1+1\\nPk)\\n=E(\\nE2\\nk1)\\n+ 2(k1) +E(1\\nPk)\\n.\\nFrom this recurrence relation, we have\\nE(\\nE2\\n)\\n=E(\\nE2\\n0)\\n+ 2\\nk=1(k1) +\\nk=1E(1\\nPk)\\n=\\nk=1E(1\\nPk)\\n+(1).\\nWe conclude that\\nVar(E) =\\nk=1E(1\\nPk)\\n+(1)2=\\nk=1E(1\\nPk)\\n=E(V).\\n3.2 Asymptotic Relative Variance\\n3.2.1 The ARV Factor\\nWe consider classes of sketches composed of msubsketches , which controls the size and variance.\\nInLogLog,PCSA, and Curtainthese subsketches are the mcolumns. When considering a sketch\\nwithmsubsketches, instead of using as the total number of insertions, we always use to denote', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 10}), Document(page_content='the number of insertions per subsketch and therefore the total number of insertions is m. We care\\nabout the asymptotic relative variance (ARV) asmandboth go to innity (dened below). A\\nreasonable sketch should have relative variance O(1/m). Informally, the ARV factor is just the\\nleading constant of this expression.\\nDenition 4 (ARV factor) .Consider a class of sketches whose size is parameterized by m. For\\nanyk0, denePm,kto be the probability the sketch changes state upon the kth insertion and\\nEm,kthe martingale estimator. The ARV factor of this class of sketches is dened as\\nlim\\nlimmmVar(Em,m )\\n(m)2. (1)\\n3.2.2 Scale-Invariance and the Constant ', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 10}), Document(page_content='3.2.2 Scale-Invariance and the Constant \\nFewsketcheshave strictlywell-denedARVfactors. In Martingale LogLog , forexample, thequantity(\\nlimmmVar(Em,m )\\n(m)2)\\nis not constant, but periodic in log2; it does not converge as . We\\nexplain how to x this issue using smoothing in Section 3.2.3. Scale-invariant sketches must have\\nwell-dened ARV factors.\\nDenition 5 (scale-invariance and constant ).A combined sketch is scale-invariant if\\n1. For any , there exists a constant such thatPm,mconverges to almost surely as\\nm.\\n2. The limit of asexists, and def= lim.\\n10', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 10}), Document(page_content='The constant of a sketch Ais denoted as A, where the subscript Ais often dropped when the\\ncontext is clear.\\nThe next theorem proves that under mild regularity conditions, all scale-invariant sketches have\\nwell dened ARV factors and there is a direct relation between the ARV factor and the constant .\\nTheorem 3 (ARV factor of a scale-invariant sketch) .Consider a sketching scheme satisfying the\\nfollowing properties.\\n1. It is scale-invariant with constant .\\n2. For any  > 0, the limit operator and the expectation operator of {1\\nPm,m}mcan be inter-\\nchanged.\\nThen the ARV factor of the sketch exists and equals1\\n2.\\nProof.First note that, by the assumptions, we have that\\nlimmE(\\n1\\nPm,m(\\n=E(\\nlimm1\\nPm,m(\\n=E(\\n)\\n=\\n.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 11}), Document(page_content='1\\nPm,m(\\n=E(\\nlimm1\\nPm,m(\\n=E(\\n)\\n=\\n.\\nAlso note that since Pm,kare non-increasing as kincreases, by simple coupling argument, we see\\nthat for any kk,E(1/Pm,k)E(1/Pm,k)andk\\nkk\\nk.\\nFix>0, we have, by Theorem 2,\\nlimm1\\n2mVar(Em,m ) = limm(\\n1\\n2mm\\nk=1E(\\n1\\nPm,k(\\n1\\n(\\n= limm1\\n2m1\\ni=0m\\nj=1E(\\n1\\nPm,im +j(\\n1\\n(2)\\nSince for any j[1,m],E(\\n1\\nPm,im +j)\\nE(\\n1\\nPm,(i+1)m)\\n, we have\\nlimm1\\n2mVar(Em,m )limm1\\n2m1\\ni=0m\\nj=1E(\\n1\\nPm,(i+1)m(\\n1\\n\\n=1\\n21\\ni=0limmE(\\n1\\nPm,(i+1)m(\\n1\\n\\n=1\\n21\\ni=0i+ 1\\ni+11\\n,\\nDenote the ARV factor as v. FixW > 0. Note that for any i[0,/W1],k/W +i+1\\nk/W +i+1\\n(k+1)/W\\n(k+1)/W.\\nvlim\\n(\\n1\\n21\\ni=0i+ 1\\ni+11\\n(\\n= lim\\n\\uf8eb\\n\\uf8ed1\\n2W1\\nk=0/W1\\ni=0k/W +i+ 1\\nk/W +i+1(\\n(\\nlim', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 11}), Document(page_content='2W1\\nk=0/W1\\ni=0k/W +i+ 1\\nk/W +i+1(\\n(\\nlim\\n\\uf8eb\\n\\uf8ed1\\n2W1\\nk=0/W1\\ni=0(k+ 1)/W\\n(k+1)/W(\\n(=1\\nW2W1\\nk=0lim\\nk+ 1\\n(k+1)/W\\n11', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 11}), Document(page_content='note that lim(k+1)/W=by the denition of scale-invariance,\\n=1\\nW2W1\\nk=0k+ 1\\n=1\\n2W(W+ 1)\\nW2. (3)\\nOntheotherhand, wecanbounditfrombelowsimilarly. Wewillonlyoutlinethekeystepssince\\nit is almost identical to the previous one. Note that for any j[1,m],E(\\n1\\nPm,im +j)\\nE(\\n1\\nPm,im)\\n.\\nUsing this inequality in (2), we have\\nlimm1\\n2mVar(Em,m )limm1\\n2m1\\ni=0m\\nj=1E(\\n1\\nPm,im(\\n1\\n=1\\n21\\ni=0i\\ni1\\n.\\nSimilarly, we have\\nvlim\\n\\uf8eb\\n\\uf8ed1\\n2W1\\nk=0/(W)1\\ni=0k/W +i\\nk/W +i(\\n(lim\\n\\uf8eb\\n\\uf8ed1\\n2W1\\nk=0/W1\\ni=0k/W\\nk/W(\\n(\\n=1\\nW2W1\\nk=0k\\n=1\\n2W(W1)\\nW2. (4)\\nThus by combining (3) and (4), we have\\n1\\n2W(W1)\\nW2v1\\n2W(W+ 1)\\nW2.\\nSincethechoiceof Wisarbitrary, weconcludethattheARVfactor viswell-denedand v=1\\n2.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 12}), Document(page_content='2.\\nThe constant together with Theorem 3 is useful in that it gives a simple and systematic way\\nto evaluate the asymptotic performance of a well behaved (scale-invariant) sketch scheme.\\nMinCount [9,23,29] is an example of a scale-invariant sketch. The function h(a) = (i,v)\\n[m][0,1]is interpreted as a pair containing a bucket index and a real hash value. A (k,m)-\\nMinCount sketch stores the smallest khash values in each bucket.\\nTheorem 4. (k,m)-MinCount is scale-invariant and (k,m)-MinCount =k.\\nProof.When a total of melements are inserted to the combined sketch, each subsketch receives\\n(1 +o(1))elements as  . Since we only care the asymptotic behavior, we assume for\\nsimplicity that each subsketch receives exactly elements.\\nLetP(i)', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 12}), Document(page_content='LetP(i)\\nbe the probability that the sketch of the ith bucket changes after the th element is\\nthrown into the ith bucket. Then by denition, we have\\nPm,m =m\\ni=1P(i)\\n\\nm.\\nSince all the subsketches are i.i.d., by the law of large numbers, Pm,E(\\nP(1)\\n)\\nalmost surely\\nasm.\\nLetXbe thekth smallest hash value among uniformly random numbers in [0,1], which\\ndistributes identically with P(1)\\n. By standard order statistics, Xis a Beta random variable\\nBeta(k,1 +k)which has meank\\n+1. Thus=E(X) =k\\n+1. We conclude that\\n= lim\\n= lim\\nk\\n+ 1=k.\\n12', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 12}), Document(page_content='Applying Theorem 3 to (k,m)-MinCount , we see its ARV is1\\n2km,8matching Cohen [14] and\\nTing [34]. Technically its MVPis unbounded since hash values were real numbers, but any realistic\\nimplementation would store them to logUbits of precision, for a total of kmlogUbits. Hence we\\nregard its MVPto be1\\n2log2U.\\n3.2.3 Smoothing Discrete Sketches\\nSketches that partition the dartboard in some exponential fashion with base q(like LogLog,PCSA,\\nandCurtain) have the property that their estimates and variance are periodic in logq. Pettie and\\nWang [31] proposed a simple method to smooththese sketches and make them truly scale-invariant\\nasm.\\nWe assume that the dartboard is partitioned into mcolumns. The base- qsmoothing operation', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 13}), Document(page_content='uses anoset vector  r= (r0,...,rm1). We scale down all the cells in column iby the factor qri,\\nthen add a dummy cell spanning [qri,1)which is always occupied. (Phrased algorithmically, if a\\ndart is destined for column i, we lter it out with probability 1qriand insert it into the sketch\\nwith probability qri.) When analyzing variants of ( Hyper)LogLogandPCSA, we use the uniform\\noset vector (0,1/m,2/m,..., (m1)/m). The Curtainsketch can be viewed as having a built-in\\noset vector of (0,1/2,0,1/2,0,1/2,...)which eects the sawtooth cell partition. To smooth it,\\nwe use the oset vector9\\n(0,1/2,1/m,1/2 + 1/m,2/m,1/2 + 2/m, ..., 1/21/m,11/m).\\nAsm, rbecomes uniformly dense in [0,1].', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 13}), Document(page_content='Asm, rbecomes uniformly dense in [0,1].\\nThe smoothing technique makes the empirical estimation more scale-invariant (see [31, Figs. 1&\\n2]) but also makes the sketch theoretically scale-invariant according to Denition 5. Thus, in the\\nanalysis, we will always assume the sketches are smoothed. However, in practice it is probably not\\nnecessary to do smoothing if q<3.\\nInthenextsection, wewillprovethat smoothedq-LL,q-PCSA, and Curtainareallscale-invariant.\\n4 Analysis of Dartboard Based Sketches\\nConsider a dartboard cell that covers the vertical interval [q(t+1),qt). We dene the heightof\\nthe cell to be t. In a smoothed cell partition, no two cells have the same height and all heights are', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 13}), Document(page_content='of the form t=j/m, for some integer j. Thus, we may refer to it unambiguously as cellt. Note\\nthat celltis anm11\\nqtq1\\nqrectangle.\\n4.1 Poissonized Dartboard\\nSince we care about the asymptotic case where , we model the process of throwing darts\\nby a Poisson point process on the dart board (similar to the poissonization in the analysis of\\nHyperLogLog [19]). Specically, after throwing mdarts (events) to the dartboard, we assume the\\nnumber of darts in cell tis a Poisson random variable with mean 1\\nqtq1\\nqand the number of darts in\\ndierent cells are independent. For the poissonized dartboard, the range of height of cells naturally\\nextend to the whole set of real numbers, instead of just having cells with positive height.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 13}), Document(page_content='8For simplicity, we assume the second condition of Theorem 4 holds for all the sketches analyzed in this paper.\\n9In [31], the smoothing was implemented via randomosetting, instead of the uniform osetting. In Curtainwe\\nneed to use uniform osetting so that the oset values of columns are similar to their neighbors.\\n13', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 13}), Document(page_content='For anytR, letYt,be the indicator whether cell tcontains at least one dart. Note that the\\nprobability that a Poisson random variable with mean is zero ise. Thus we have,\\nPr(Yt,= 0) =e\\nqtq1\\nq.\\nHere, we note some simple identities for integrals that we will use frequently in the analysis.\\nLemma 2. For anyq>1, we have\\n1\\nqte1\\nqtdt=1\\nlnqe1\\nqt+C.\\nFurthermore, let c0,c1be any positive numbers, we have\\n\\nc0\\nqtec1\\nqtdt=c0\\nc11\\nlnq.\\nProof.Use standard calculus.\\n4.2 The Constant \\nLetZt,be the indicator of whether the cell tisfree. UnlikeYt,,Zt,depends on which sketching\\nalgorithm we are analyzing. Since the state changing probability is equal to the sum of the area of\\nfree cells, we have\\nPm,m =\\nj=01\\nm(1\\nqj/m1\\nqj/m+1)', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 14}), Document(page_content='Pm,m =\\nj=01\\nm(1\\nqj/m1\\nqj/m+1)\\nZj/m,. (5)\\nIfPm,mconverges to /almost surely as m, then E(Pm,m )also converges to /as\\nm. Thus we have, from (5),\\n/= limmE(Pm,m ) = limm\\nj=01\\nm(1\\nqj/m1\\nqj/m+1)\\nE(Zj/m, )\\n=\\n0(1\\nqt1\\nqt+1)\\nE(Zt,)dt\\n(1\\nqt1\\nqt+1)\\nE(Zt,)dt, (6)\\nwhere we can extend the integration range to negative innity without aecting the limit of as\\n.10We conclude that\\n= lim\\n= lim\\n\\n(1\\nqt1\\nqt+1)\\nE(Zt,)dt. (7)\\nThe formula (7) is novel in the sense that, in order to evaluate , we now only need to understand\\nthe probability that Zt,is 1 for xed tand.11\\n10Note that for any t,, we all have E(Zt,)E(1Yt,)(free cell has no dart). Therefore, by extend-', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 14}), Document(page_content='ing the integration (6) to the whole real line, the increment is bounded by\\uf8f60\\n(1\\nqt1\\nqt+1)\\nE(1Yt,)dt=\\n\\uf8f60\\n(1\\nqt1\\nqt+1)\\ne(1/qt1/qt+1)dt=1\\n\\uf8f6logq((q1)/q)\\n1/qte1/qtdt=1\\neq1\\nq\\nlnqwhereeq1\\nq\\nlnq0as.\\nThus it will not aect the value of lim.\\n11Technically, to apply formula (7) one needs to rst prove that the state changing probability Pm,mconverges\\nalmost surely to some constant /for any, which is a mild regularity condition for any reasonable sketch. Thus\\nin this paper we will assume the sketches in the analysis all satisfy this regularity condition and claim that a sketch\\nis scale-invariant if formula (7) converges.\\n14', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 14}), Document(page_content='4.3 Analysis of Smoothed q-PCSA andq-LL\\nThe sketches q-PCSAandq-LLare the natural smoothed base- qgeneralizations of PCSA[20] and\\nLogLog[16].\\nTheorem 5. q-PCSAandq-LLare scale-invariant. In particular, we have,\\nq-PCSA =1\\nlnq,andq-LL=1\\nlnqq1\\nq.\\nProof.Forq-LL, celltis free i both itself and all the cells above it in its column contain no darts.\\nThus we have\\nE(Zt,) =\\ni=0Pr(Yt+i,= 0) =\\ni=0e\\nqt+iq1\\nq=e\\nqt.\\nInsert it to formula (7) and we get\\nq-LL= lim\\n\\n(1\\nqt1\\nqt+1)\\ne\\nqtdt=1\\nlnqq1\\nq.\\nForq-PCSA, celltis free i it has no dart. Thus Zt,= 1Yt,and by formula (7) we have\\nq-PCSA = lim\\n\\n(1\\nqt1\\nqt+1)\\ne\\nqtq1\\nqdt=1\\nlnq.\\nTheFishmonger [31] sketch is based on a smoothed, entropy compressed version of base- ePCSA.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 15}), Document(page_content='The memory footprint of Fishmonger approaches its entropy as m, which was calculated to\\nbemH 0[31, Lemma 4]. From Theorem 5, we know e-PCSA = 1.\\nCorollary 1. Fishmonger has limiting MVPH0/21.63.\\nProof.By Theorem 3, limiting MVPequalsmH 01\\n2m=H0\\n2.\\n4.4 Asymptotic Local View\\nFor anytand, since we want to evaluate Zt,, whose value may depend on its neighbors on the\\ndartboard, we need to understand the congurations of the cells near cell t. Since we consider the\\ncase where mgoes to innity, we may ignore the eect of smoothing to the cells in the immediate\\nvicinity of cell t.\\nAfter taking these asymptotic approximations, we can index the cells near cell tas follows.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 15}), Document(page_content='Denition 6 (neighbors of cell t).Fix a cellt. LetiZandcR. The (i,c)-neighbor of cell\\ntis a cell whose column index diers by i(negativeimeans to the left, positive to the right) and\\nhas height t+c, it covers the vertical interval [q(t+c+1),q(t+c)). In the sawtooth partition, cis\\nan integer when iis even and a half-integer when iis odd. (Note that we are locally ignoring the\\neect of smoothing.)\\nOnce celltis xed, dene W(i,c)to be the indicator for whether the (i,c)-neighbor of cell t\\nhas at least one dart in it. Thus, for xed t,, we have\\nPr(W(i,c) = 0) = Pr( Yt+c,= 0) =e\\nqt+cq1\\nq.\\nIn the asymptotic local view, we lose the property that a cell can be uniquely identied by its', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 15}), Document(page_content='height, hence the need to refer to nearby cells by their position relativeto cellt.\\n15', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 15}), Document(page_content='4.5 Analysis of Curtain\\nWe rst briey state some properties of curtain. For any a1, recall that Oa={(a1/2),(a\\n3/2),...,1/2,1/2,...,a3/2,a1/2}. It is easy to see that for any vector v= (g0,g1,...,gm1),\\nvcurt= (gi)can be expressed as\\ngi= max\\nj[0,m1]{gj|ij|(a1/2)}.\\nFor eachi, we dene the tension point ito be the lowest allowable value of gi, given the context\\nof its neighboring columns.\\ni= max\\nj[0,m1]\\\\{i}{gj|ij|(a1/2)},\\nand thus we have gi= max(gi,i). We see that the column iisin tension igii, that is, gi=i.\\nTheorem 6. Curtainis scale-invariant with\\nCurtain =1\\nlnqq1\\nq1\\nq1\\nq+2\\nqh(qa1/21)+1\\nqh+1.\\nProof.Fix celltand. DeneW1(k)to be the height of the highest cell containing darts in the', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 16}), Document(page_content='columnkaway fromts column. I.e., dene =q\\nkis oddy\\n/2to be 1/2 if kis odd and zero if kis\\neven, andW1(k)def= max{t+i+|iZandW(k,i+) = 1}.\\nWe have for any iZ,\\nPr(W1(k)t+i+) =\\nj=1Pr(W(k,i+j+) = 0) =e\\nqt+1+i+.\\nLetT1be the tension point of the column of cell t, which equals max\\njZ\\\\{0}{W1(j)|j|(a1/2)}. We\\nhave for any iZ,\\nPr (T1i+t) = Pr(\\nmax\\njZ\\\\{0}{W1(j)|j|(a1/2)}i+t(\\n=\\njZ\\\\{0}Pr(W1(j)|j|(a1/2)i+t)\\n=\\uf8eb\\n\\uf8ed\\nj=1e1\\nqt+i+1+j(a1/2)(\\n(2\\n=e2\\nqt+i+11\\nqa1/21.\\nFrom the rules of Curtain, we know that a cell is free i it contains no dart, it is at most h1\\nbelow its columns tension point, and at most hbelow the highest cell in its column containing\\ndarts. Thus,\\nZt,=q\\nYt,= 0y\\nq\\ntT1(h1)y\\nq\\ntW1(0)hy\\n,', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 16}), Document(page_content='Zt,=q\\nYt,= 0y\\nq\\ntT1(h1)y\\nq\\ntW1(0)hy\\n,\\nNote that T1is independent from Yt,andW1(0). In addition, Yt,is also independent fromq\\ntW1(0)hy\\n, since the latter only depends on Yt,withth+t+ 1. Thus, we have\\nE(Zt,) = Pr(Yt,= 0)Pr(T1t+h1)Pr(W1(0)t+h)\\n16', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 16}), Document(page_content='=e\\nqtq1\\nqe2\\nqt+h1\\nqa1/21e\\nqt+h+1\\n= exp(\\n\\nqt(q1\\nq+2\\nqh(qa1/21)+1\\nqh+1))\\n.\\nThus by formula (7), we have\\nCurtain = lim\\n\\n(1\\nqt1\\nqt+1)\\nexp(\\n\\nqt(q1\\nq+2\\nqh(qa1/21)+1\\nqh+1))\\ndt\\n=1\\nlnqq1\\nq1\\nq1\\nq+2\\nqh(qa1/21)+1\\nqh+1.\\n5 Optimality of Martingale Fishmonger\\nMartingale sketches have several attractive properties, e.g., being strictly unbiased and insensitive\\nto duplicate elements in the data stream. In Section 5.1 we argue that any sketch that satises\\nthese natural assumptions can be systematically transform into a Martingale X sketch with equal or\\nlesser variance, where Xis a dartboard sketch. In other words, the Martingale transform is optimal.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 17}), Document(page_content='In Section 5.2 we prove that within the class of linearizable dartboard sketches, Martingale Fish-\\nmongeris optimal. The class of linearizable sketches is broad and includes state-of-the-art sketches,\\nwhich lends strong circumstantial evidence that the memory-variance product of Martingale Fish-\\nmongercannot be improved.\\n5.1 Optimality of the Martingale Transform\\nConsider a non-mergeable sketch processing a stream A= (a1,a2,...). LetSibe its state after\\nseeing (a1,...,ai),i=|{a1,...,ai}|, and (Si)be the estimate of cardinality iwhen in state Si.\\nWe make the following natural assumptions.\\nRandomness. The random oracle his the only source of randomness. In particular, Siis a\\nfunction of (h(a1),h(a2),...,h (ai)).', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 17}), Document(page_content='function of (h(a1),h(a2),...,h (ai)).\\nDuplicates. Ifai{a1,...,ai1},Si=Si1, i.e., duplicates do not trigger state transitions.\\nUnbiasedness. Suppose one examines the data structure at time iand seesSi=siand then\\nexamines it at time j. Then (Sj)(si)is an unbiased estimate of ji.\\nDenition 7. Thestate history at timei, denotedWi= (S0,Sj1,Sj2,...,Sj=Si), lists all the\\ndistinctstates encountered when processing (a1,...,ai). Note that ,{jk}1k, andWiare all\\nrandom variables. When we want to x a particular state-history wiwe writeWi=wi.\\nTheduplicates andrandomness assumptions imply that the distribution of SiandWidepends\\nonly oni. Thus, we henceforth assume for simplicity that there are no duplicates and that i=i.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 17}), Document(page_content='Suppose that the algorithm could magically make its cardinality estimates based not just on\\nSi, but the entire state history Wi. LetHbe the (countably innite) set of all histories and\\nH[0,1]HHbe the stochastic matrix governing transition between histories.12Letew[0,1]H\\n12I.e., ifw= (S0,...,S,S)andwis the prex of wmissingS, thenH(w,w)is the probability that the next\\n(distinct) element would cause the sketch to transition from StoS.\\n17', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 17}), Document(page_content='be the probability distribution that puts unit probability on history w.13LetRHbe the vector\\nof cardinality estimates at each history-state. From the Randomness ,Duplicates , andUnbiasedness\\nassumptions, it follows that if we observe that Wi=wi, then\\ne\\nwiHji=ji.\\nis the expectation of (Wj)(wi). Heree\\nwiHjiis the distribution of the history-state Wj\\nconditioned on Wi=wi. In the special case that j=i+ 1, we have\\nE((Wi+1)|Wi=wi) =(wi) +E((Wi+1)(wi)|Wi+1=wi)(1H(wi,wi))\\nand due to the Unbiased assumption this must be\\n=(wi) + 1.\\nHence, for any wi,\\nE((Wi+1)(wi)|Wi+1=wi) = (1H(wi,wi))1. (8)\\nPhraseddierently, the Unbiased assumptionimpliesthat (Xi)isamartingale, where Xi=(Wi)', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 18}), Document(page_content='i. DeneZi=XiXi1. Because (Xi)is a martingale the covariances of the (Zi)are all zero. We\\nhave\\nVar(Xi) =i\\nj=1Var(Zj)\\n=i\\nj=1(\\nE(Var(Zj|Wj1)) + Var( E(Zj|Wj1)))\\nObserve that E(Zj|Wj1) = 0, so this is\\n=i\\nj=1E(Var(Zj|Wj1))\\n=i\\nj=1\\nwj1Pr(Wj1=wj1)E(((Wj)(wj1)1)2)\\n(9)\\nNote that the expression inside the expectation in (9) is constant when Wj=wj1, which holds\\nwith probability c0=H(wj1,wj1). Letc1,c2,...be other constants that depend only on wj1.\\nContinuing, this is equal to\\n=i\\nj=1\\nwj1(\\nE(((Wj)(wj1)1)2Wj=wj1)\\nc1+c2)\\n(10)\\nBy (8), E((Wj)(wj1)1)\\n= (1H(wj1,wj1))11, which also depends only on wj1,\\nhence (10) is equal to\\n=i\\nj=1\\nwj1(\\nVar((Wj)(wj1)Wj=wj1)\\nc3+c4)\\n. (11)', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 18}), Document(page_content='Var((Wj)(wj1)Wj=wj1)\\nc3+c4)\\n. (11)\\n13I.e.,ew(w) = 1andew(w) = 0for allw=w.\\n18', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 18}), Document(page_content='At this point we can ask which estimate vector minimizes (11). The variances in (11) are\\nnon-negative, and it is possible to make them all zero, subject to (8), by setting\\n(wj) =(wj1) + (1H(wj1,wj1))1(12)\\nfor everywjsuch that H(wj1,wj)>0. Note that the transitions in Hthat occur with non-zero\\nprobability, excludingself-loops, formadirectedarborescence(out-tree)rootedattheinitialhistory\\n(S0). Thus, all the constraints of the form (12) can be satised simultaneously.\\nTo recapitulate, as a consequence of the Randomness ,Duplicates , andUnbiased assumptions,\\ntheMartingale estimator has minimum variance. Dene the h-stateof a sketch state S, denoted', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 19}), Document(page_content='Sh, to be the set of hash values, that, if encountered, would cause no state transition. Then we can\\nwriteSias(i,Sh\\ni,Sl\\ni), where iis the Martingale estimate (which depends on the history), and\\nSl\\niis any leftover state information not implied by Sh\\niandi. We have shown that iis the only\\ninformation from the history useful for making cardinality estimates. Thus, the data structure is\\nfree to change Sl\\nito any value consistent with Sh\\niat will, and therefore Sl\\nishould not be stored at\\nall. In other words, we can simply store the state Sias(i,Sh\\ni)and impute any Sl\\niwhich is most\\nadvantageous.14Note that since (Sh\\ni)is a dartboard sketch,15(i,Sh\\ni)is derived by a Martingale', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 19}), Document(page_content='i)is derived by a Martingale\\ntransform and is not worse than the original sketch (Si).\\nRemark 2. We should note that under some circumstances it is possible to achieve smaller vari-\\nance by violating the duplicates andunbiasedness assumptions. For example, suppose the sketch\\nstate after seeing ielements were (i,Si,i). If the stream is duplicate-heavy,  i carries no useful\\ninformation, but if nearly all elements are distinct, iis also a good cardinality estimate. Since\\nii, the cardinality estimate min{i,i}is never worse than ialone, but when ii, it is\\nbiased and has a constant factor lower variance.\\n5.2 Optimality of Martingale Fishmonger', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 19}), Document(page_content='5.2 Optimality of Martingale Fishmonger\\nGiven an abstract linearizable sketching scheme X, its space is minimized by compressing it to\\nits entropy. On the other hand, by Theorem 3 the variance of Martingale X is controlled by the\\nnormalized expected probability of changing state: 2E(P). Theorem 7 lower bounds the ratio\\nof these two quantities for any sketch that behaves well over a suciently large interval of cardi-\\nnalities[ea,eb]. The proof technique is very similar to [31], as is the take-away message (that\\nX=Fishmonger is optimal up to some assumptions). However, the two proofs are mathematically\\ndistinct as [31] focuses on Fisher information while Theorem 7 focuses on the probability of state\\nchange.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 19}), Document(page_content='change.\\nTheorem 7. Fix realsa < bwithd=ba >1. Let H,R > 0. For any linearizable sketch, let\\nH()be the entropy of its state and Pbe the probability of state change16at cardinality satises\\nthat\\n1. for all>0,H()H, and\\n2. for all[ea,eb],2E(P)R,\\n14In particular, if ai+1is such that it would cause (i,Sh\\ni,Sl\\ni)to become (i+1,Sh\\ni+1,Sl\\ni+1)and cause (i,Sh\\ni,Sh\\ni)\\nto become (i+1,Sh\\ni+1,Sl\\ni+1), then we are free to choose our next state to be (i+1,Sh\\ni+1)or(i+1,Sh\\ni+1), whichever\\nis more advantageous. As variances improve when |Sh|is small, we would choose the one minimizing |Sh\\ni+1|,|Sh\\ni+1|.\\n15(occupied cells = hash values that cause no transition)\\n16The probability of state change Pis itself a random variable.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 19}), Document(page_content='19', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 19}), Document(page_content='then\\nH\\nRH0\\n21max(8d1/4,5ed/2)\\n1 +(344+4\\nd)\\ndH0\\nI0(1max(8d1/4,5ed/2))=H0\\n2(1od(1)).\\nProof.By the assumptions of the theorem, we have\\uf8f6b\\naH(ex)dx\\n2\\uf8f6b\\naexE(Pex)dxH\\nR. Thus it suces to prove\\nthat\\n\\uf8f6b\\naH(ex)dx\\n2\\uf8f6b\\naexE(Pex)dxH0\\n2(1od(1)).\\nNow we will write the expressions in terms of the cells.\\nLetCbe the of cells. By linearizability, we can write cells as c0,c1,...,c|C|1, wherecihas area\\npi. LetZibe the indicator whether ciis hit by a dart and Yibe the indicator whether ciis occupied.\\nLetFi= (Y0,...,Yi). Since it is linearizable, there is some monotone function :{0,1}{0,1}\\nsuch thatYi=Zi(Fi1). Assume poissonization17, by Lemma 13 in [31], we can write\\nH() =|C|1\\ni=0HB(epi) Pr((Fi1,) = 0).', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 20}), Document(page_content='H() =|C|1\\ni=0HB(epi) Pr((Fi1,) = 0).\\nThen by the linearity of expectation, we have\\nE(P) =|C|1\\ni=0piPr(Zi= 0) Pr((Fi1,) = 0) =|C|1\\ni=0piepiPr((Fi1,) = 0).\\nFor clear presentation, we introduce the following denitions.\\nDenition 8. Fix a linearizable sketch. Let CCbe a collection of cells and WRbe an\\ninterval of the reals. Dene:\\nH(CW) =\\nW\\nciCH(piex) Pr((Yi1,ex) = 0)dx,\\nR(CW) =\\nW\\nciCR(piex) Pr((Yi1,ex) = 0)dx,\\nwhere\\nH(t) =HB(et) =1\\nln 2(tet(1et) ln(1et)),\\nR(t) = 2tet.\\nNow we can write\\uf8f6b\\naH(ex)dxasH(C[a,b])and2\\uf8f6b\\naexE(Pex)dxasR(C[a,b]).\\nNote that\\uf8f6\\nR(ex)dx= 2and it is proved in [31] that\\uf8f6\\nH(ex)dx=H0.18Thus we want\\nto proveH(C[a,b])\\nR(C[a,b])\\uf8f6\\nH(ex)dx\\uf8f6', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 20}), Document(page_content='to proveH(C[a,b])\\nR(C[a,b])\\uf8f6\\nH(ex)dx\\uf8f6\\nR(ex)dx(1od(1)). A similar statement is proved in Theorem 5 in [31]\\nwhere it is showed thatH(C[a,b])\\nI(C[a,b])\\uf8f6\\nH(ex)dx\\uf8f6\\nI(ex)dx(1od(1))andIand Iare dened as follows.\\nI(CW) =\\nW\\nciCI(piex) Pr((Yi1,ex) = 0)dx,\\n17A cell of size pwill have probability epto be without a dart at cardinality .\\n18H0= (ln 2)1+\\nk=1k1log2(1 + 1/k).\\n20', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 20}), Document(page_content='where I(t) =t2\\net1. Note that the only dierence between this theorem and Theorem 5 in [31] is\\nbetween Rand I. However, one can verify that R(t)satises all the properties (see the lemma\\nbelow) it is used for I(t)in the proof of Theorem 5 in [31]. Thus the similar lower bound is obtained\\nhere.\\nLemma 3. The following statements are true.\\n1.H(t)\\nR(t)is decreasing in ton(0,). This corresponds to Lemma 12 in [31].\\n2.R(t)4et/2for allt>0. This corresponds to Lemma 20 in [31].\\nProof. 1.H(t)\\nR(t)=1\\n2 ln 2(1(1et) ln(1et)\\ntet ). Note that(1et) ln(1et)\\ntet =1et\\ntln(1et)\\net. Let\\ng(t) =1et\\ntandh(x) =ln(1x)\\nxwheret>0andx(0,1). It suces to prove that g(t)is\\ndecreasing and g(x)is increasing. Indeed, g(t) =ett1+et', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 21}), Document(page_content='t2<etet1\\nt2= 0sincet+ 1< et\\nfort>0;h(x) =x\\n1x+ln(1x)\\nx2>0forx(0,1).\\n2. It suces to prove t/2et/2, which is true.\\nCorollary 2. The MVP of any linearizable and scale-invariant sketch is at leastH0\\n2.\\nProof.LetSbe a scale-invariant combined sketch with constant . First recall Denition 5 that\\nfor any, we havePm,mconverges to almost surely as mwherePm,mis the updating\\nprobability after minsertions to a combined sketch consisting of mbase-sketches19. By the\\ndominated convergence theorem, we have E(Pm,m )converges to . Furthermore, recall that\\nis the limit of as. Therefore, for any 1>0, there exist suciently large m1and1,\\nsuch that for any > 1,E(Pm1,m1)>1.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 21}), Document(page_content='such that for any > 1,E(Pm1,m1)>1.\\nNow by Theorem 3 and the denition of ARV factor (Denition 4), for any 2>0, there exist\\nsuciently large m2> m 1and2>  1, such that for any  >  2,m2Var(Em2,m2)\\n(m2)2>1\\n22>\\n1\\n2E(Pm2,m2)+212whereEm2,m2is the Martingale estimator.\\nThen, xing m2, view the combined sketch as a single sketch20and we have that for any\\n >  2m2,Var(E)\\n2>1\\n2E(P)+21m22\\nm2.Suppose the sketch uses Hbits of memory and for\\nsuciently large , the relative variance is bounded by . Thus we have\\nVar(E)\\n2>1\\n2E(P) + 21m22\\nm2,\\nwhich says\\n2E(P)1\\n+2\\nm221m2.\\nInvoking Theorem 7 where aandbcan be chosen arbitrarily far away, as long as b > a > log2,\\nwe have\\nH\\n1\\n+2\\nm221m2H0\\n2.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 21}), Document(page_content='we have\\nH\\n1\\n+2\\nm221m2H0\\n2.\\nFinally note that 1,2can be made arbitrarily small and m2can be made arbitrarily large. We\\nconclude that the MVP HH0\\n2.\\n19The combined sketch is assumed to be smoothed.\\n20ThusEm2,m 2should be written as Em2andPm2,m 2should bePm2.\\n21', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 21}), Document(page_content='6 Experimental Validation\\nThroughout the paper we have maintained a possibly unhealthy devotion to asymptotic analysis,\\ntakingmwhenever it was convenient. In practice mwill be a constant, and possibly a\\nsmallish constant. How do the sketches perform in the pre-asymptotic region?\\nIn turns out that the theoretical analysis predicts the performance of Martingale sketches pretty\\nwell, evenwhem missmall. IntheexperimentofFigure3, wexedthesketchsizeatatiny 128bits.\\nTherefore HyperLogLog usesm1=128/6= 21counters. The Martingale LogLog andMartingale\\nCurtainsketchesencodethemartingaleestimatorwithaoatingpoint approximation ofin14bits,\\nwith a 6-bit exponent and 8-bit mantissa. Thus, Martingale LogLog usesm2= (12814)/6 = 19', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 22}), Document(page_content='counters, and Martingale Curtain usesm3= 37.21\\nFor larger sketch sizes, the distribution of /is more symmetric, and closer to the predicted\\nperformance. Figure 4 gives the empirical distribution of /over 100,000 runs when = 106and\\nthe sketch size is xed at 1,200 bits. Here MartingaleCurtain usesm= 400, and both Martingale\\nLogLogandHyperLogLog usem= 200.\\nThe experimental and predicted relative variances and standard errors are given in Table 2.\\nFigure 3: The sketch size is xed at 128bits.\\nFigure 4: The sketch size is xed at 1200 bits.\\nSketchUsing 128bits Using 1200bits\\nExperiment Prediction Experiment Prediction\\nVar StdErr Var StdErr Var StdErr Var StdErr\\nHyperLogLog 0.0573 23.94% 0.0549 23.44% 0.00541 7.36% 0.00539 7.35%', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 22}), Document(page_content='Martingale LogLog 0.0348 18.65% 0.0365 19.10% 0.00350 5.91% 0.00347 5.89%\\nMartingale Curtain 0.0211 14.54% 0.0208 14.43% 0.00189 4.35% 0.00193 4.39%\\nTable 2: The relative variance is1\\n2Var(|)and standard error is1\\n\\nVar(|). The predic-\\ntions for Martingale LogLog andMartingale Curtain use Theorems 3, 5, and 6. The predictions for\\nHyperLogLog are from Flajolet et al. [19, p. 139].\\n21It uses the optimal parameterization (q,a,h ) = (2.91,2,1)of Theorem 1.\\n22', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 22}), Document(page_content='7 Conclusion\\nThe Martingale transform is attractive due to its simplicity and low variance, but it results in non-\\nmergeable sketches. We proved that under natural assumptions22, it generates optimal estimators\\nautomatically, allowing one to design structurally more complicated sketches, without having to\\nworry about designing or analyzing ad hocestimators. We proposed the Curtainsketch, in which\\neach subsketch only needs a constant number of bits of memory, for arbitrarily large cardinality\\nU.23\\nThe analytic framework of Theorems 2 and 3 simplies Cohen [14] and Ting [34], and gives a\\nuser-friendly formula for the asymptotic relative variance (ARV) of the Martingale estimator, as a', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 23}), Document(page_content='function of the sketchs constant . We applied this framework to Martingale Curtain as well as the\\nMartingale version of the classic sketches ( MinCount ,HLLandPCSA).\\nAssuming perfect compression, one gets the memory-variance product (MVP) of an sketch by\\nmultiplying its entropy and ARV. It is proved that for linearizable sketches, Fishmonger is optimal\\nfor mergeable sketches [31] (limiting MVP =H0/I21.98). In this paper we proved that in\\nthe sequential (non-mergeable) setting, if we restrict our attention to linearizable sketches, that\\nMartingale Fishmonger is optimal, with limiting MVP =H0/21.63(Section 5.2). We conjecture\\nthat these two lower bounds hold for general, possibly non-linearizable sketches.\\nReferences', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 23}), Document(page_content='References\\n[1] N. Alon, P. B. Gibbons, Y. Matias, and M. Szegedy. Tracking join and self-join sizes in limited\\nstorage. In Proceedings 18th ACM Symposium on Principles of Database Systems (PODS) ,\\npages 1020, 1999.\\n[2] D.N.BakerandB.Langmead. Dashing: Fastandaccurategenomicdistanceswithhyperloglog.\\nbioRxiv, 2019.\\n[3] Z. Bar-Yossef, T. S. Jayram, R. Kumar, D. Sivakumar, and L. Trevisan. Counting distinct\\nelements in a data stream. In Proceedings 6th International Workshop on Randomization and\\nApproximation Techniques (RANDOM) , volume 2483 of Lecture Notes in Computer Science ,\\npages 110, 2002.\\n[4] Z. Bar-Yossef, R. Kumar, and D. Sivakumar. Reductions in streaming algorithms, with an ap-', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 23}), Document(page_content='plication to counting triangles in graphs. In Proceedings 13th Annual ACM-SIAM Symposium\\non Discrete Algorithms (SODA) , pages 623632, 2002.\\n[5] R. Ben-Basat, G. Einziger, S. L. Feibish, J. Moraney, and D. Raz. Network-wide routing-\\noblivious heavy hitters. In Proceedings of the 2018 Symposium on Architectures for Networking\\nand Communications Systems (ANCS) , pages 6673, 2018.\\n[6] J. Basiok. Optimal streaming and tracking distinct elements with high probability. ACM\\nTrans. Algorithms , 16(1):3:13:28, 2020.\\n[7] A. Z. Broder. On the resemblance and containment of documents. In Proceedings of Compres-\\nsion and Complexity of SEQUENCES , pages 2129, 1997.\\n22(insensitivity to duplicates, and unbiasedness)', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 23}), Document(page_content='22(insensitivity to duplicates, and unbiasedness)\\n23Note that an O(log logU)-bit oset register is needed for the whole sketch.\\n23', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 23}), Document(page_content='[8] T. Buddhika, M. Malensek, S. L. Pallickara, and S. Pallickara. Synopsis: A distributed\\nsketch over voluminous spatiotemporal observational streams. IEEE Trans. Knowl. Data Eng. ,\\n29(11):25522566, 2017.\\n[9] P. Chassaing and L. Gerin. Ecient estimation of the cardinality of large data sets. In\\nProceedings of the 4th Colloquium on Mathematics and Computer Science Algorithms, Trees,\\nCombinatorics and Probabilities , 2006.\\n[10] A. Chen, J. Cao, L. Shepp, and T. Nguyen. Distinct counting with a self-learning bitmap.\\nJournal of the American Statistical Association , 106(495):879890, 2011.\\n[11] M. Chen, S. Chen, and Z. Cai. Counter tree: A scalable counter architecture for per-ow', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 24}), Document(page_content='trac measurement. IEEE/ACM Trans. Netw. , 25(2):12491262, 2017.\\n[12] P. H. Chia, D. Desfontaines, I. M. Perera, D. Simmons-Marengo, C. Li, W. Day, Q. Wang,\\nand M. Guevara. KHyperLogLog: Estimating reidentiability and joinability of large data at\\nscale. In Proceedings of the 2019 IEEE Symposium on Security and Privacy , pages 350364,\\n2019.\\n[13] E. Cohen. Size-estimation framework with applications to transitive closure and reachability.\\nJ. Comput. Syst. Sci. , 55(3):441453, 1997.\\n[14] E. Cohen. All-distances sketches, revisited: HIP estimators for massive graphs analysis. IEEE\\nTrans. Knowl. Data Eng. , 27(9):23202334, 2015.\\n[15] E. Cohen and H. Kaplan. Tighter estimation using bottom ksketches. Proc. VLDB Endow. ,\\n1(1):213224, 2008.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 24}), Document(page_content='1(1):213224, 2008.\\n[16] M. Durand and P. Flajolet. Loglog counting of large cardinalities. In Proceedings 11th An-\\nnual European Symposium on Algorithms (ESA) , volume 2832 of Lecture Notes in Computer\\nScience, pages 605617. Springer, 2003.\\n[17] R.A.L.Elworth, Q.Wang, P.K.Kota, C.J.Barberan, B.Coleman, A.Balaji, G.Gupta, R.G.\\nBaraniuk, A. Shrivastava, and T. J. Treangen. To petabytes and beyond: recent advances in\\nprobabilistic and signal processing algorithms and their application to metagenomics. Nucleic\\nAcids Research , 48(10):52175234, 2020.\\n[18] C. Estan, G. Varghese, and M. E. Fisk. Bitmap algorithms for counting active ows on high-\\nspeed links. IEEE/ACM Trans. Netw. , 14(5):925937, 2006.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 24}), Document(page_content='[19] P. Flajolet, . Fusy, O. Gandouet, and F. Meunier. HyperLogLog: the analysis of a near-\\noptimal cardinality estimation algorithm. In Proceedings of the 18th International Meeting on\\nProbabilistic, Combinatorial, and Asymptotic Methods for the Analysis of Algorithms (AofA) ,\\n2007.\\n[20] P. Flajolet and G. N. Martin. Probabilistic counting algorithms for data base applications. J.\\nComput. Syst. Sci. , 31(2):182209, 1985.\\n[21] M. J. Freitag and T. Neumann. Every row counts: Combining sketches and sampling for\\naccurategroup-byresultestimates. In Proceedings of the 9th Biennial Conference on Innovative\\nData Systems Research (CIDR) , 2019.\\n24', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 24}), Document(page_content='[22] P. B. Gibbons and S. Tirthapura. Estimating simple functions on the union of data streams. In\\nProceedings 13th Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA) ,\\npages 281291, 2001.\\n[23] F. Giroire. Order statistics and estimating cardinalities of massive data sets. Discret. Appl.\\nMath., 157(2):406427, 2009.\\n[24] A. Helmi, J. Lumbroso, C. Martnez, and A. Viola. Data Streams as Random Permutations:\\nthe Distinct Element Problem. In Proceedings of the 23rd International Meeting on Proba-\\nbilistic, Combinatorial, and Asymptotic Methods for the Analysis of Algorithms (AofA) , pages\\n323338, 2012.\\n[25] P. Indyk and D. P. Woodru. Tight lower bounds for the distinct elements problem. In', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 25}), Document(page_content='Proceedings 44th IEEE Symposium on Foundations of Computer Science (FOCS), October\\n2003, Cambridge, MA, USA, Proceedings , pages 283288, 2003.\\n[26] T. S. Jayram and D. P. Woodru. Optimal bounds for Johnson-Lindenstrauss transforms and\\nstreaming problems with subconstant error. ACM Trans. Algorithms , 9(3):26:126:17, 2013.\\n[27] D. M. Kane, J. Nelson, and D. P. Woodru. An optimal algorithm for the distinct elements\\nproblem. In Proceedings 29th ACM Symposium on Principles of Database Systems (PODS) ,\\npages 4152, 2010.\\n[28] K. J. Lang. Back to the future: an even more nearly optimal cardinality estimation algorithm.\\nCoRR, abs/1708.06839, 2017.\\n[29] J. Lumbroso. An optimal cardinality estimation algorithm based on order statistics and its', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 25}), Document(page_content='full analysis. In Proceedings of the 21st International Meeting on Probabilistic, Combinatorial,\\nand Asymptotic Methods in the Analysis of Algorithms (AofA) , pages 489504, 2010.\\n[30] G. Marais, B. Solomon, R. Patro, and C. Kingsford. Sketching and sublinear data structures\\nin genomics. Annual Review of Biomedical Data Science , 2(1):93118, 2019.\\n[31] S. Pettie and D. Wang. Information theoretic limits of cardinality estimation: Fisher meets\\nShannon. In Proceedings 53rd ACM Symposium on Theory of Computing (STOC) , 2021.\\n[32] N. Pham. Hybrid LSH: faster near neighbors reporting in high-dimensional space. In Proceed-\\nings of the 20th International Conference on Extending Database Technology (EDBT) , pages\\n454457, 2017.', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 25}), Document(page_content='454457, 2017.\\n[33] B. Scheuermann and M. Mauve. Near-optimal compression of probabilistic counting sketches\\nfor networking applications. In Proceedings of the 4th International Workshop on Foundations\\nof Mobile Computing (DIALM-POMC) , 2007.\\n[34] D. Ting. Streamed approximate counting of distinct elements: beating optimal batch methods.\\nInProceedings 20th ACM Conference on Knowledge Discovery and Data Mining (KDD) , pages\\n442451, 2014.\\n[35] J. Wires, S. Ingram, Z. Drudi, N. J. A. Harvey, and A. Wareld. Characterizing storage\\nworkloads with counter stacks. In Proceedings of the 11th USENIX Symposium on Operating\\nSystems Design and Implementation (OSDI) , pages 335349, 2014.\\n25', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 25}), Document(page_content='[36] D. E. Wood, J. Lu, and B. Langmead. Improved metagenomic analysis with Kraken 2. bioRxiv,\\n2019.\\n[37] Q. Xiao, S. Chen, Y. Zhou, M. Chen, J. Luo, T. Li, and Y. Ling. Cardinality estimation\\nfor elephant ows: A compact solution based on virtual register sharing. IEEE/ACM Trans.\\nNetw., 25(6):37383752, 2017.\\n26', metadata={'source': '/share/lab4/ych/papers/paper1.pdf', 'page': 26})]\n",
      "[Document(page_content='The Structure of Minimum Vertex Cuts\\nSeth Pettie\\nUniversity of Michigan\\npettie@umich.eduLonghui Yin\\nTsinghua University\\nylh17@mails.tsinghua.edu.cn\\nAbstract\\nIn this paper we continue a long line of work on representing the cut structure of graphs.\\nWe classify the types minimum vertexcuts, and the possible relationships between multiple\\nminimum vertex cuts.\\nAs a consequence of these investigations, we exhibit a simple O(n)-space data structure\\nthat can quickly answer pairwise (+ 1)-connectivity queries in a -connected graph. We also\\nshow how to compute the closest -cut to every vertex in near linear O(m+ poly()n)time.\\nThis work was supported by NSF grants CCF-1637546 and CCF-1815316.arXiv:2102.06805v1  [cs.DS]  12 Feb 2021', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 0}), Document(page_content='1 Introduction\\nOne of the strong themes running through graph theory is to understand the cut structure of graphs\\nand to apply these structural theorems to solve algorithmic and data structural problems. Consider\\nthe following exemplars of this line of work:\\nGomory-Hu Tree. Gomory and Hu (1961) [28] proved that any weighted, undirected graph G=\\n(V,E)can be replaced by a weighted, undirected tree T= (V,ET)such that for every s,tV,\\nthe minimum s-tcut partition in T(removing a single edge, partitioning Vinto two sets)\\ncorresponds to a minimum s-tcut partition in G. These are sometimes called cut-equivalent\\ntrees[1].\\nCactus Representations. Dinitz,Karzanov,andLomonosov(1976)[12]provedthatallthe global', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 1}), Document(page_content='minimumedge-cutsofanyweighted, undirectedgraph G= (V,E)couldbesuccinctlyencoded\\nas an (unweighted) cactus graph . A cactus is a multigraph in which every edge participates in\\nexactly one cycle. It was proved that there exists a cactus C= (VC,EC)and an embedding\\n:VVCsuch that the minimum edge-cuts in C(2 edges in a common cycle) are in 1-1\\ncorrespondence with the minimum edge-cuts of G. A corollary of this theorem is that there\\nare at mostn\\n2)minimum edge-cuts.\\nPicard-Queyrenne Representation. In adirecteds-tow network there can be exponentially\\nmany min s-tcuts. Picard and Queyrenne (1980) [38] proved that the family S={S|\\n(S,S)is a mins-t}corresponds 1-1 with the downward-closed sets of a partial order, and is', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 1}), Document(page_content='therefore closed under union and intersection.\\nBlock Trees, SPQR Trees, and Beyond. Whitney (1932) [43,44] proved that the cut vertices\\n(articulation points) of an undirected graph G= (V,E)partitionEinto single edges and\\n2-edge connected components (blocks). This yields the block tree representation. Di Battista\\nand Tamassia (1989) [4,5] formally dened the SPQR tree , which succinctly encodes all 2-\\nvertex cuts in a biconnected graph, and Kanevsky, Tamassia, Di Battista, and Chen [31]\\nextended this structure to represent 3-vertex cuts in a triconnected graph.1\\nIt is natural to ask how, and to what extent, these structures can be extended and generalized.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 1}), Document(page_content='Guseld and Naor [29] described an analogue of Gomory-Hu trees for vertex connectivity, i.e., a\\ntree that compactly represents the s-tvertexconnectivity for every s,tV. It used a result of\\nSchnorr [39] on an analogue of Gomory-Hu trees for roundtrip ow-values in directed networks.\\nThese claims were refuted by Benczur [6], who illustrated that Schnorrs and Guseld and Naors\\nproofs were incorrect and could not be rectied. In particular, s-tvertex connectivity and directed\\ns-tcuts have no tree representation . We take this as a reminder that having published proofs ( even\\nincorrect ones ) is essential for facilitating self-correction in science.\\nThe inspiration for this paper is an extended abstract of Cohen, Di Battista, Kanevsky, and', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 1}), Document(page_content='Tamassia [10] from STOC 1993. Their goal was to nd a cactus-analogue for global minimum\\nvertex cuts, or from a dierent perspective, to extend SPQR trees [5] and [31] from {2,3}\\nvertex cuts to arbitrarily large . As an application of their ideas, they described a data structure\\nfor-connected graphs occupying space O(3n)that, given u,v, decided whether u,vare separated\\nby a-cut or (+ 1)-connected. There are no suspect claims in [10]. On the other hand, the paper\\n1Many of the structural insights behind [5,31] were latent in prior work. See, for example. Mac Lane [34] (1937),\\nTutte [41,42] (1961-6), Hopcroft and Tarjan [30], and Cunningham and Edmonds [11].\\n1', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 1}), Document(page_content='(a) (b)\\n(c) (d)\\n(e) (f)\\n(g) (h)\\nFigure 1: (a) A weighted undirected graph; (b) Its Gomory-Hu (cut-equivalent) tree [28]. (c) A\\nweighted undirected graph (unmarked edges have unit weight); (d) the Cactus representation [12]\\nof its minimum edge cuts. (e) A directed s-tow network; (f) A dag whose downward-closed sets\\n(that include sbut nott) correspond to min s-tcuts (Picard-Queyrenne [38]). (g) An abstract\\nrepresentation of a 2-connected graph; (h) The representation of its 3-connected components as an\\nSPQR tree (Di Battista-Tamassia [5]).\\n2', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 2}), Document(page_content='is 7 pages and leaves many of its central claims unproven.2We believe that understanding the\\nstructure of minimum vertex cuts is a fundamental problem in graph theory, and deserving of a\\ncomplete, formal treatment.\\nIn this paper we investigate the structure of the set of all minimum vertex cuts and classify the\\nrelationships between dierent minimum vertex cuts. Our work reveals some structural features of\\nminimum-cuts not evident in Cohen, Di Battista, Kanevsky, and Tamassia [10], and ultimately\\nallows us to develop a simpler data structure to answer pairwise -cut queries in a -connected\\ngraph. It occupies (optimal) O(n)space and can be constructed in randomized O(m+ poly()n)', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 3}), Document(page_content='time, in contrast to [10], which occupies O(3n)space and is constructed in exp()n5time.3\\n1.1 Related Work\\nDinitz and Vainshtein [16,17] combined elements of the cactus [12] and Picard-Queyrenne [38]\\nrepresentations, which they called the connectevity carcass . Given an undirected, unweighted G=\\n(V,E)andSVof terminals, Sis the size of the minimum edge-cut that separates S. The\\ncarcass represents allsize-Sseparating cuts in O(min{m,Sn})space and answers various cut\\nqueries inO(1)time.4\\nBenczur and Goemans [7] generalized the cactus representation [12] in a dierent direction, by\\ngiving a compact representation of all cuts that are within a factor 6/5of the global minimum\\nedge-cut.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 3}), Document(page_content='edge-cut.\\nDinitz and Nutov [13] generalized the cactus representation [12] in another direction, by giving\\nanO(n)-space representation of all and+ 1edge cuts, where is the edge-connectivity of the\\nundirected, unweighted graph. Unpublished manuscripts [14,15] give detailed treatments of the \\nodd andeven cases separately.\\nGeorgiadis et al. [21,2527] investigated various notions of 1- and 2-edge and vertex connectivity\\nindirectedgraphs, and the compact representation of edge/vertex cuts.\\nSparsication. One general way to compactly represent connectivity information is to produce\\nasparsegraph with the same cut structure. Nagamochi and Ibaraki [36] proved that every un-', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 3}), Document(page_content='weighted, undirected graph G= (V,E)contains a subgraph H= (V,EH)with|EH|<(k+1)nsuch\\nthatHis computable in O(m)time and contains exactly the same k-vertex cuts and k-edge cuts\\nasG, for allk{1,...,k}. Benczur and Karger [8] proved that for any capacitated, undirected\\ngraphG= (V,E), there is another capacitated graph H= (V,EH)with|EH|=O(2nlogn)such\\nthat the capacity of everycut inGis preserved in Hup to a (1)-factor. This bound was later\\nimproved to O(2n)by Batson, Spielman, and Srivastava [3], which is optimal.\\nIn directed graphs, Baswana, Choudhary, and Roditty [2] considered the problem of nding\\na sparse subgraph that preserves reachability from a single source, even if dvertices are deleted.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 3}), Document(page_content='They proved that (2dn)edges are necessary and sucient for d[1,logn].\\nd-Failure Connectivity. An undirected graph can be compactly represented such that connec-\\ntivity queries can be answered after the deletion of any dvertices/edges (where dcould be much\\n2The full version of this paper was never written (personal communication with R. Tamassia, 2011, and R. Di\\nBattista, 2016).\\n3The algorithm enumerates allminimum-cuts, which can be as large as (2(n/)2); modern vertex connectivity\\nalgorithms [2224] may reduce the exponent of nin the running time.\\n4The carcass was introduced in extended abstracts [16,17] and the (simpler) case of odd Swas analyzed in detail', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 3}), Document(page_content='in a journal article [18]. We are not aware of a full treatment of the case when Sis even.\\n3', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 3}), Document(page_content='larger than the underlying connectivity of the graph). Improving on [19,32,37], Duan and Pet-\\ntie [20] proved that dvertex failures could be processed in O(d2)time such that connectivity queries\\nare answered in O(d)time, anddedge failures could be processed in O(dlogdlog logn)time such\\nthat connectivity queries are answered in O(log logn)time. The size of the [20] structure is O(m)\\nfor vertex failures and O(n)for edge failures. Choudhary [9] gave an optimal O(n)-space data\\nstructure that could answer directed reachability queries after d{1,2}vertex or edge failures.\\nLabeling Schemes. Benczurs refutation [6] of [29,39] shows that all pairwise vertex connectiv-', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 4}), Document(page_content='ities cannot be captured in a treestructure, but it does not preclude other representations of this\\ninformation. Korman [33] proved that the vertices of any undirected G= (V,E)could be assigned\\nO(k2logn)-bit labels such that given (label(u),label(v)), we can determine whether uandvare\\n(k+1)-connected or separated by a k-vertex cut. That is, poly() logn-bit labels suce to compute\\nmin{(u,v),}, where(u,v)is the pairwise connectivity of u,v.\\nVertex Connectivity Algorithms. In optimal linear time we can decide whether the connec-\\ntivity of a graph is = 1,= 2,or3[30,40]. For larger , the state-of-the-art in vertex\\nconnectivity has been improved substantially in the last few years. Forster, Nanongkai, Yang,', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 4}), Document(page_content='Saranurak, and Yingchareonthawornchai [22] gave a Monte Carlo algorithm for computing the ver-\\ntex connectivity of an undirected graph in O(m+n3)time, w.h.p.5The best deterministic\\nalgorithm, due to Gao, Li, Nanongkai, Peng, Saranurak, and Yingchareonthawornchai [24], com-\\nputes the connectivity <n1/8inO((m+n7/4O())no(1))time orO((m+n19/205/2)no(1))time.\\nFor>n1/8, Gabows algorithm [23] runs in O(n2+2nmin{n3/4,3/2})time.\\n1.2 Organization\\nIn Section 2 we review basic denitions and lemmas regarding vertex cuts. Section 3 gives the basic\\nclassication theorem for minimum vertex cuts, and lists some useful corollaries. In short, every\\npair of cuts have laminar,wheel,crossing matching , orsmallrelation. Sections 3.13.4 analyze', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 4}), Document(page_content='these four categories in more detail. Section 4 exhibits a new O(n)-space data structure that,\\ngiven two vertices, answers (+ 1)-connectivity queries in O(1)time, and produces a separating\\n-cut (if one exists) in O()time. We conclude with some remarks and open problems in Section 5.\\n2 Preliminaries\\nThe input is a simple, connected, undirected graph G= (V,E)withn=|V|andm=|E|. The\\npredicateABis true ifAis astrictsubset ofB.\\nLet the subgraph of Ginduced by Abe denoted G|A. We callUVacutif the graph G|V\\\\U\\nis disconnected. A sideof the cutUis a connected component of G|V\\\\U. IfPis a side of Uand\\nAP, we sayAiswithin a side of U, and let SideU(A) =Pdenote the side containing A. A', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 4}), Document(page_content='regionof a cutUis a side, or the union of several sides of U. Denote RegionU(A)as the region\\ncontaining the sides of Uthat intersects with A.6We say a cut disconnects orseparatesAandB\\nif they are in distinct sides of U. In particular, if B=V\\\\(AU), we sayUdisconnects orseparates\\nBfrom the rest of the graph .\\n5The algorithm does not produce a witness, and hence may err with small probability.\\n6Note when Ais a singleton set {u},RegionU(A) = SideU(A).\\n4', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 4}), Document(page_content='A path=v1v2vlisfromAtoB, ifv1AandvlB. Two paths ,fromv1tovlare\\ninternally vertex disjoint if they have no common vertices, except for v1,vl. We sayUblocksif\\nU\\\\{v2,...,vl1}=.\\nAk-cutis a cut of size k. Dene(u,v)to be the minimum ksuch that there exists a k-cut\\nseparatinguandv, where{u,v}=E(G). Dene=(G)to be the minimum of (u,v)over all\\npairs{u,v}V(G)\\n2)\\\\E(G). We sayGisk-connected if(G)k.\\nIn this paper we assume that <n/ 4and consider the set of all(minimum) -cuts.\\nRemark 1. There is some exibility in dening the corner cases. Some authors leave (u,v)\\nundened when{u,v}E(G)or dene it to be n1. In [10] ak-cut is dened to be a mixed set of', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 5}), Document(page_content='edgesandverticeswhoseremovaldisconnectsthegraph. Underthisdenition, when {u,v}E(G),\\n(u,v) =kif removing k1vertices and{u,v}disconnects uandv. This last denition is\\ncompatible with Mengers theorem, and allows for it to be extended to allpairs of vertices.\\nTheorem 1. (Menger [35]) Let G= (V,E)be an undirected graph and {u,v}a pairnotinE. Let\\nUVbe a minimum size cut disconnecting uandvandbe a maximum size set of internally\\nvertex disjoint paths from utov. Then(u,v) =|U|=||.\\nThe following categories make sense when applied to non-minimal vertex cuts, but we are only\\ninterested in applying them to minimum vertex cuts. Henceforth cutusually means minimum cut .', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 5}), Document(page_content='Laminar Cuts. LetUbe a cut and Pbe a side of U. IfWis a cut and WUP, we sayW\\nis alaminar cut ofUin sideP.7\\nFigure 2: A 7-cut Uwith two sides, and two 7-cuts W1,W2that are laminar w.r.t. U.\\nSmall Cuts. Informally, when a side of a cut tiny we call the cut small. We dene three levels\\nof small cuts. Let Ube a cut with sides A1,A2,...,Aa. We say that\\n1Uis (I,t)-smallif there exists an index isuch that\\ni=i|Ai|t.Aiis called the large\\nsideofUand the others the small sides ofU.\\n2Uis (II,t)-smallif there exists isuch that for every i=i,|Ai|t.\\n3Uis (III,t)-small, if there exists isuch that|Ai|t. In this case Aiis thesmall side ofU.\\nNote that for any t, I-small cuts are II-small, and II-small cuts are III-small. We typically apply', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 5}), Document(page_content='this denition with t=,t= (), ort=n\\n2.\\n7These are sometimes called parellel cuts .\\n5', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 5}), Document(page_content='Wheel Cuts. SupposeVcan be partitioned into a series of disjoint sets T,{Ci},{Si}(1\\niw,w4, subscripts are taken module w), such that the {Ci}and{Si}are nonempty ( T\\nmay be empty), and CiTCi+2disconnects SiCiSi+1from the rest of the graph. We\\nsay(T;C1,C2,...,Cw)forms aw-wheelwithsectorsS1,S2,...,Sw. We callTthecenterof the\\nwheel,{Ci}thespokesof the wheel, and C(i,j) =CiTCjthecutsof the wheel. Dene\\nD(i,j) =SiCi+1Cj1Sj1.\\nRecall that we are only interested in wheels whose cuts are minimum -cuts. The cut of the\\nwheels discussed in this paper are all -cuts. It is proved in Lemma 3 that, if (T;C1,C2,...,Cw)\\nformsawheel, thenfor every i,jsuchthatji /{1,w1},C(i,j)isa-cutwithexactlytwosides,', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 6}), Document(page_content='namelyD(i,j)andD(j,i). Notethata w-wheel (T;C1,C2,...,Cw)containsx-wheels,x[4,w1].\\nFigure 3: A 6-wheel of 8-cuts with a center of size |T|= 2.\\nSpecically, for anysubset{i1,i2,...,ix}{ 1,2,...,w}withx4,(T;Ci1,Ci2,...,Cix)forms\\nanx-wheel called a subwheel of the original. If a wheel is not a subwheel of any other wheel, it is\\namaximal wheel . If there exists an index isuch that,\\ni=i|Si|, then we say this is a small\\nwheel.8\\nMatchingCutsandCrossingMatchingCuts. LetUbeacut,Abeasideof U, andPUbe\\na subset of the cut. We call a cut Wamatching cut of Uin sideAw.r.t.Pif (i)U\\\\PWUA,\\n(ii)A\\\\W=, and (iii)Wdisconnects P(V\\\\(UA))fromA\\\\W. The set MatchU;A(P)def=W\\\\U', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 6}), Document(page_content='is the neighborhood of Prestricted to A. Note that a matching cut is a type of laminar cut.\\nNow suppose Uis a cut with exactly two sides AandB, and letPUbe a non-empty subset of\\nU. We callWacrossing matching cut of Uin sideAw.r.t.Pif (i)W\\\\B=, (ii) (U\\\\P)(W\\\\A)\\nis a matching cut of Uin sideAw.r.t.P,\\nOne could view Uand a crossing matching cut Was a degenerate 4-wheel, in which one sector\\nS1=is empty. Such cuts should notbe regarded as wheels, as they do not possess key properties\\nof wheels, e.g., that when UandWare (minimum) -cuts, that|C1|==|C4|=|T|\\n2, because\\nC1TC2is not a cut.\\nLemmas 1 and 2 are used throughout the paper. Recall here =(G)is the vertex connectivity\\nofG.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 6}), Document(page_content='ofG.\\nLemma 1. SupposeUis a-cut andPa side ofU. For every pPanduU, there exists a\\npath fromptouthat is not blocked by V\\\\P.\\n8For a small wheel, all its cuts C(i,j)are (II,O(2))-small.\\n6', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 6}), Document(page_content='Figure 4: A cut U(drawn vertically) with two sides AandB. Dotted lines indicate two crossing\\nmatching cuts w.r.t. P1(bottom 3 vertices of U) andP2(top 2 vertices of P1).\\nProof.Fix anyvin another side of U. By Mengers thorem (Theorem 1) there are internally\\nvertex disjoint paths from utov, and therefore each must pass through a dierent vertex of U.\\nThe prexes of these paths that are contained in PUare not blocked by V\\\\P.\\nLemma 2. SupposeUandWare two cuts, Pis disconnected by Ufrom the rest of the graph G\\nandQis disconnected by Wfrom the rest of the graph G. Then we have the following two rules:\\n(Intersection Rule) If P\\\\Q=, thenP\\\\Qis disconnected by (U\\\\Q)(U\\\\W)(W\\\\P)\\nfrom the rest of the graph G;', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 7}), Document(page_content='from the rest of the graph G;\\n(Union Rule) If V\\\\(UPWQ)=, thenPQis disconnected by (U\\\\Q)(W\\\\P)from\\nthe rest of the graph G.\\n(a) (b)\\nFigure 5: (a) Intersection rule; (b) Union rule.\\nProof.DenoteA= (U\\\\Q)(U\\\\W)(W\\\\P),B=P\\\\Q. First,AB= (UP)\\\\(WQ)V,\\nsoV\\\\(AB)=. Consider a path v1v2vlfromBtoV\\\\(AB). Becausev1B=P\\\\Q, and\\nvl/UPorvl/WQ, this path must be blocked by UorW, so there must exist some vjin\\nUW. Find the smallest isuch thatviUW, and without loss of generality assume viU.\\nThen the path v1v2viis not blocked by W, soviQW. Since (QW)\\\\UAwe have\\nviA. It follows that AseparatesBfrom the rest of the graph, proving the Intersection Rule.\\nFortheUnionRule, let R=V\\\\(UP),S=V\\\\(WQ). Nowthat R\\\\S=V\\\\(UPWQ)=', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 7}), Document(page_content=', byapplyingtheintersectionruleabove, R\\\\Sisdisconnectedby T= (U\\\\S)(U\\\\W)(W\\\\R) =\\n(U\\\\Q)(W\\\\P)from the rest of the graph.\\n7', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 7}), Document(page_content='3 The Classication of Minimum Vertex Cuts\\nThe main binarystructural theorem for vertex connectivity is, informally, that every two minimum\\nvertex cuts have a relationship that is Laminar,Wheel,Crossing Matching , orSmall; cf. [10].\\nMoreover, any strict subset of this list would be inadequate to capture all possible relationships\\nbetween two vertex cuts.9\\nTheorem 2. Fix a minimum -cutUwith sidesA1,A2,...,Aa,a2, and letWbe any other\\n-cut with sides B1,B2,...,Bb,b2. DenoteT=U\\\\W,Wi=W\\\\AiandUj=U\\\\Bj. Then\\nWmay be classied w.r.t. Uas follows:\\nLaminar type. Wis a laminar cut of U, and in particular, there exists indices iandjsuch\\nthatBj\\\\Ai= (U\\\\W)(i=iAi)andAi\\\\Bj= (W\\\\U)(j=jBj).', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 8}), Document(page_content='Wheel type. a=b= 2, and (T;U1,W1,U2,W2)forms a 4-wheel with sectors A1\\\\B1,A1\\\\B2,\\nA2\\\\B2andA2\\\\B1.\\nCrossing Matching type. a=b= 2, and w.l.o.g., A1\\\\B1=,A2\\\\B2=, butA1\\\\B2=.\\nWe have|W2|=|U1|>0,|W1|=|U2|>0, andWis a crossing matching cut of Uin side\\nA1w.r.t.U2. Furthermore, if A2\\\\B1=, then|U1||U2|.\\nSmall type. Uis (I,1)-small, and the small sides of Uare withinW, orWis (I,1)-small,\\nand the small sides of Ware withinU.\\nProof.Suppose there is a single index isuch thatWi=andWi=for alli=i. It follows\\nthatWAiUis a laminar cut of Uin sideAi. It remains to prove the other properties of\\nthe laminar type. By Lemma 1 there exists paths from any vertex in Ai,i=i, toU\\\\Wthat', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 8}), Document(page_content='are not blocked by W, so they all lie within one side of W; let us denote this side by Bj. Then\\n(U\\\\W)(i=iAi)Bj, and because V=U(a\\ni=1Ai), we obtain Bj\\\\Ai= (U\\\\W)(i=iAi).\\nNow thatUWBjis laminar w.r.t. W, so based on the same reasoning we have Ai\\\\Bj=\\n(W\\\\U)(j=jBj).\\nWe proceed under the assumption that such indices i,jdo not exist, and without loss of\\ngenerality assume that W1,W2,U1,U2=. We now wish to prove that allUi,Wiare non-empty.\\nSupposeWidef=W\\\\Ai=were empty, then Aiwould be contained within a side of W, say\\nAiBj. By Lemma 2 (intersection rule), whenever Ai\\\\Bj=, the setWiTUjdisconnects\\nAi\\\\Bjfrom the rest of the graph. It follows that\\n|Wi|+|T|+|Uj|=|T|+|Uj|=|T|+b\\nl=1|Ul|,', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 8}), Document(page_content='|Wi|+|T|+|Uj|=|T|+|Uj|=|T|+b\\nl=1|Ul|,\\nwhich implies that Ujis theonlynon-empty U-set, contradicting U1,U2=. Therefore, Wi=\\nfor alliand similarly, Uj=for allj.\\nDene  ={(i,j)|Ai\\\\Bj=}to be the side-pairs whose intersections are non-empty. We\\nconsider the following possibilities, which are exhaustive.\\n1There exist (i,j),(i,j)such thati=i,j=j. Then by Lemma 2 (intersection rule)\\n|Wi|+|T|+|Uj|\\n9The existence of Smallcuts as a categoryan a prioriunnatural classindicates that there may be other ways\\nto capture all minimum vertex cuts through an entirely dierent classication system.\\n8', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 8}), Document(page_content='and|Wi|+|T|+Uj.\\nOn the other hand,\\n|Uj|+Uj+|T||U|=\\nand|Wi|+|Wi|+|T||W|=.\\nThus all these inequalities must be equalities, and, adding the fact that all Wi,Uj=, we\\nconclude that a=b= 2,|Wi|=Uj,|Wi|=|Uj|. W.l.o.g. we x i=j= 1,i=j= 2. See\\nFigure 6.\\nFigure 6: A depiction of cuts U,Win case 1.\\n1.1SupposeA1\\\\B2=andA2\\\\B1=. Then|W|+|U\\uf6be||T|for every ,\\uf6be{1,2},\\nso we conclude that\\n|U1|=|U2|=|W1|=|W2|=|T|\\n2.\\nNow thatWTU\\uf6bedisconnects A\\\\B\\uf6befrom the rest of the graph, U1TU2=U\\ndisconnects (A1\\\\B1)W1(A1\\\\B2) =A1from (A2\\\\B1)W2(A2\\\\B2) =A2,\\nW1TW2=Wdisconnects (A1\\\\B1)U1(A2\\\\B1) =B1from (A1\\\\B2)U2\\n(A2\\\\B2) =B2, we conclude that (T;U1,W1,U2,W2)forms a 4-wheel.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 9}), Document(page_content='Figure 7: A depiction of the cuts U,Win case 1.2.\\n1.2SupposeA1\\\\B2=(or symmetrically, that A2\\\\B1=). ThenA1=A1\\\\(B1W) =\\n(A1\\\\B1)W1. By Lemma 2, W1TU1separatesA1\\\\B1from the rest of the graph.\\nSinceU2V\\\\((A1\\\\B1)(U1TW1)), it follows that W1TU1disconnects U2\\nfromA1\\\\B1=A1\\\\(W1TU1), i.e., it is a matching cut of Uin sideA1w.r.t.U2.\\n9', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 9}), Document(page_content='See Figure 7. Because W2=W\\\\A2=and(W\\\\A1)(U\\\\U2) =W1TU1,Wis\\na crossing matching cut of Uin sideA1w.r.t.U2.\\nIfA2\\\\B1=, by Lemma 2 (intersection rule)\\n|U1|+|W2|+|T|=|W1|+|T|+|W2|,\\nso|U1||U2|.\\n2Suppose there exists a jsuch thati.j=j.(i,j), i.e.,Ai\\\\Bj=. This implies that\\nj=jBjU, and because Uj=,j=jBjisstrictlysmaller than . Therefore Wis a (I,\\n1)-small cut, and all the small sides of Ware withinU.\\n3There exists isuch thati=i.j.(i,j). Symmetric to case 2;Uis (I,1)-small,\\nand all the small sides of Uare withinW.\\n4 =. Thena\\ni=1AiW, soV=U(a\\ni=1Ai)UW, and|V|2. This is a possibility,\\nbut not one we consider as it contradicts our initial assumption that n>4.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 10}), Document(page_content='Corollary 1. IfUis a-cut that is not (I, 1)-small and has at least 3sides, then all other\\n-cuts have a laminar type relation with U, or are themselves (I, 1)-small cuts.\\nCorollary 2. SupposeUis a-cut that is not (I, 1)-small, with exactly two sides AandB.\\nSupposeWis a-cut with sides K,L(and possibly others), such that W\\\\A=,W\\\\B=,\\nAKW, andL\\\\U=. ThenWonly has two sides, and Wis a crossing matching cut of U\\nin sideAw.r.t.L\\\\U.\\nCorollary 3. Dene CutsC;Dto be the set of all -cuts that disconnect disjoint, non-empty vertex\\nsetsCandD. IfCutsC;D=, it contains a unique minimal element MinCutC;D, such that for\\nany cutUCutsC;D,RegionMinCutC;D(C)RegionU(C).', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 10}), Document(page_content='any cutUCutsC;D,RegionMinCutC;D(C)RegionU(C).\\nProof.This is a corollary of Theorem 2, but also admits a simple, direct proof via the Picard-\\nQueyrenne theorem [38]. Form a ow network Gvia the following steps (i) contract CandD\\nto vertices sandt, (ii) replace each vertex vwith a subgraph consisting of vertices vin,voutand\\na directed edge (vin,vout), (iii) replace each undirected edge {u,v}with directed edges (uout,vin)\\nand(vout,uin), (iv) give edges from (ii) unit capacity and edges from (iii) innite capacity. If\\nthe ow value is , then the minimum (sout,tin)-cuts are in one-to-one correspondence with the\\nminimum vertex cuts in CutsC;D=. Since (sout,tin)-cuts inGare closed under union and', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 10}), Document(page_content='intersection [38], there is a unique vertex cut MinCutC;DCutsC;Dsuch that RegionMinCutC;D(C)\\nis minimal w.r.t. containment.\\nTheorem 2 classies the pairwise relationship between two minimum -cuts. In Sections 3.13.4\\nwe further explore the properties of wheel cuts, (crossing) matching cuts, laminar cuts, and small\\ncuts.\\n10', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 10}), Document(page_content='3.1 Wheels and Wheel Cuts\\nRecall that a w-wheel (T;C1,...,Cw)satised, by denition, the property that CiTCi+2formed\\na-cut, but did not say anything explicitly about C(i,j) =CiTCj. Lemma 3 proves that\\nthese are also cuts, and bounds their number of sides.\\nLemma 3. Suppose (T;C1,C2,...,Cw)forms aw-wheel (w4) with sectors S1,S2,...,Sw.\\n(Subscripts are modulo w.) For any i=j,C(i,j)is a-cut that disconnects D(i,j)from the rest\\nof the graph. Moreover, when ji{1,w1},C(i,j)has exactly two sides, which are D(i,j)\\nandD(j,i). Furthermore,|Ci|=|T|\\n2.\\nProof.By denition CiTCi+2andCi1TCi+1are two-cuts that, respectively, separate\\nSiCi+1Si+1andSi1CiSifrom the rest of the graph. By Lemma 2 (intersection rule),', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 11}), Document(page_content='CiTCi+1disconnects Sifrom the rest of the graph. Thus, whenever ji{1,2},C(i,j)\\ndisconnects D(i,j)from the rest of the graph. This is the base case. Assuming the claim is true\\nwheneverji[1,l1], we prove it is true up to las well,lw1. Fixi,jsuch that\\nji=l. ThenC(i,j1)is a cut that disconnects D(i,j1)from the rest of the graph, and\\nC(i+1,j)is a cut that disconnects D(i+1,j)from the rest of the graph. By Lemma 2 (union rule),\\n(C(i,j1)\\\\D(i+1,j)(C(i+1,j)\\\\D(i,j1)) =CiTCjdisconnects D(i,j1)D(i+1,j) =\\nD(i,j)from the rest of the graph. This proves the rst part.\\nBy Lemma 1, there exist paths from any vertex in Srto every vertex in Cr, and to every vertex', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 11}), Document(page_content='inCr+1, that is not blocked by V\\\\Sr. Thus, when ji{1,w1},C(i,j)separatesD(i,j)\\nfromD(j,i),D(i,j)forms a side since all vertices in D(i,j)have paths to Ci+1, being distinct from\\nCj, andD(j,i)forms a side since all vertices have paths to Cj+1, being distinct from Ci. (When\\nj=i+ 1,D(i,i+ 1)may be a region consisting of multiple sides.)\\nNow it is proved that for all i,j,C(i,j)is a-cut, so|Ci|+|Cj|=|T|for alli,j. Therefore\\nall|Ci|are equal to|T|\\n2.\\nRemark 2. Lemma 3 shows that the set {C(i,i+ 2)}i[w]generates all thew\\n2)wheel cuts. One\\nmight think that the sector cuts {C(i,i+ 1)}would also suce, but this is incorrect. In Figure 8,\\nC(i,i+ 1)is a (minimum) 6-cut for all iseparatingSifrom the rest of the graph, but this is nota', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 11}), Document(page_content='4-wheel since C(1,3)andC(2,4)are not cuts .\\nFigure 8: A faux 4-wheel.\\nTheorem 3. Suppose (T;C1,C2,...,Cw)forms aw-wheel (w4) with sectors S1,S2,...,Sw.\\n(Subscripts are given by modulo w.) LetXbe any minimum -cut. Then one of the following is\\ntrue:\\n1X=C(i,j)for somei=j.\\n11', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 11}), Document(page_content='2XC(i,i+ 1)Sifor somei, i.e.,Xis a laminar cut of C(i,i+ 1).\\n3Xhas crossing matching type relation with some C(i,i+ 1)or someC(i,i+ 2).\\n4Xis a (I,1)-small cut.\\n5(T;C1,C2,...,Cw)is a small wheel.\\n6There exists i < j, such that XSiTSj, and (T;C1,...,Ci,X\\\\Si,Ci+1,...,Cj,X\\\\\\nSj,Cj+1,...,Cw)forms a (w+ 2)-wheel; or there exists i=j,XSiTCj, and\\n(T;C1,...,Ci,X\\\\Si,Ci+1,...,Cw)forms a (w+1)-wheel. In other words, (T;C1,C2,...,Cw)\\nis a subwheel of some other wheel.\\nProof.By the denition of wheels and Lemma 1, there exists paths from any vertex in SitoCi,\\ntoT, and toCi+1that are not blocked by V\\\\Si, and there exist paths from any vertex in CitoT\\nthat are not blocked by V\\\\(Si1CiSi). These facts are used frequently below.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 12}), Document(page_content='For everyi{1,2,...,w}, we consider the following cases relating cuts XandC(i,i+1), which\\nare exhaustive according to Theorem 2.\\ni.X=C(i,i+ 1), this is a trivial case and we are in case 1.\\nii.X\\\\Si=.\\niii.Xis a laminar cut of C(i,i+1), andX\\\\Si=, then it must be true that XC(i,i+1)Si,\\nand we are in case 2.\\niv.Xis a wheel type cut of C(i,i+ 1), andX\\\\Si=.\\nv.Xis a crossing matching type cut of C(i,i+ 1), then we are in case 3.\\nvi.XandC(i,i+ 1)have a small type relation, such that Xis (I,1)-small, then we are in\\ncase 4.\\nvii.XandC(i,i+ 1)have a small type relation, such that C(i,i+ 1)is (I,1)-small, and\\nD(i+1,i)is the small side, which implies that |D(i,i+ 1)|<, so the wheel is a small wheel,\\nand we are in case 5.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 12}), Document(page_content='and we are in case 5.\\nviii.XandC(i,i+ 1)have a small-type relation, such that C(i,i+ 1)is (I,1)-small, and\\nSi=D(i,i+ 1)is the region of the small sides. Then we have that Si=D(i,i+ 1)X.\\nIt can be seen that if for any i, we are in case i, iii, v, vi, or vii, there is nothing left to prove.\\nOtherwise, we may proceed under the assumption that everyindexiis in case ii, iv, or viii. We\\ndene the index sets I1,I2,I3as follows.\\nI1={i|case iv applies to i},\\nI2={i|case viii applies to i},\\nI3={i|case ii applies to i},\\nand hence I1I2I3= [w] ={1,2,...,w}.\\nWe split the possibilities into the following cases.\\nI.|I1|2.\\n12', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 12}), Document(page_content='II.|I1|1,|I2|>0,|I3|>0.\\nIII.|I1|= 1,|I2|= 0.\\nIV.|I1|1,|I3|= 0.\\nV.|I1|=|I2|= 0.\\nWe will show that I and III lead to case 6, II leads to case 3, IV leads to case 5, and V leads\\nto1. DeneYi,Zi,Qas follows\\nYi=X\\\\Si,\\nZi=X\\\\Ci,\\nandQ=X\\\\T.\\nI. Suppose i=jare inI1. BecauseXhas a wheel type relation with some other cut (namely\\nC(i,i+1)andC(j,j+1)), it must have exactly two sides; let them be KandL. Without loss\\nof generality we assume i= 1. We consider two subcases depending on whether j{2,w}\\n(I.a) orj{2,w}(I.b).\\nI.a.j{2,w}, i.e.,jis not adjacent to i. We prove the following claims, culminating in\\nClaim 3, which puts us in case 6.\\nClaim 1.XS1TSj.\\nBecauseXhas a wheel type relation with C(1,2)andC(j,j+ 1),|X\\\\D(1,2)|=', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 13}), Document(page_content='|X\\\\D(2,1)|and|X\\\\D(j,j+ 1)|=|X\\\\D(j+ 1,j)|. Thus, in terms of the Y,Z\\nsets,\\n|Y1|=\\nr{1,2}|Zr|+\\nr=1|Yr|and|Yj|=\\nr{j,j+1}|Zr|+\\nr=j|Yr|.\\nTherefore,|Zr|= 0for allr,|Yr|= 0for allr{1,j}, and|Y1|=|Yj|=|Q|\\n2. This\\nmeans that I1={1,j},I2=,I3= [w]\\\\I1, andXS1TSj.\\nClaim 2.C2D(2,j)CjandCj+1D(j+ 1,1)C1are in dierent sides of X, and\\nQ=T.\\nBy Lemma 1, the subgraphs induced by C2D(2,j)CjandCj+1D(j+1,1)C1\\nare connected, and therefore each is contained in a side of X. Suppose they are\\ncontained in the sameside, sayK. Any vertices in T\\\\Xmust be in Kas well, so\\nLS1Sjand w.l.o.g. we assume L\\\\S1=. Applying Lemma 2 (intersection\\nrule) toXandC(1,2)we conclude that\\n(L\\\\C(1,2))(S1\\\\X)(X\\\\C(1,2)) = (S1\\\\X)(X\\\\C(1,2)) =Y1Q', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 13}), Document(page_content='is a cut that disconnects L\\\\S1from the rest of the graph. It follows that |Y1|+\\n|Q|=+|Q|\\n2, but this contradicts with |Q|< . Therefore, we conclude that\\nC2D(2,j)CjandCj+1D(j+ 1,1)C1are indierent sides ofX, and since\\neach of these sides are adjacent to all vertices of T, thatQ=Tas well.\\nClaim 3. (T;C1,Y1,C2,...,Cj,Yj,Cj+1,...,Cw)forms a (w+ 2)-wheel.\\nBy Claim 2, TX, so|Y1|=|Yj|=|T|\\n2andC2D(2,j)CjKand\\nCj+1D(j+ 1,1)C1Lare in dierent sides of X. To verify that this is a\\nwheel we simply need to conrm that the four new cuts involving Yi,Yjare in fact\\n13', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 13}), Document(page_content='cuts. We illustrate this for Y1TC3. Applying Lemma 2 (intersection rule) to\\nXwith sideKandC(1,3)with sideD(1,3), we conclude that (K\\\\S1)C2S2\\nis disconnected by Y1TC3from the rest of the graph. The other three new\\ncuts are conrmed similarly, hence (T;C1,Y1,C2,...,Cj,Yj,Cj+1,...,Cw)forms a\\n(w+ 2)-wheel.\\nI.b.j {2,w}. W.l.o.g. we assume j= 2. Once again we prove the following claims,\\nculminating in Claim 6 which puts us in case 6.\\nClaim 4.XS1S2TC2.\\nBecauseXhas wheel type relation with C(1,2)andC(2,3), we have that\\n|Y1|=\\nr{1,2}|Zr|+\\nr=1|Yr|and|Y2|=\\nr{2,3}|Zr|+\\nr=2|Yr|.\\nTherefore,|Zr|= 0for allr= 2,|Yr|= 0for allr{1,2}, and|Y1|=|Y2|=\\n|Q||Z2|\\n2. This means I1={1,2},I2=,I3= [w]\\\\I1, andXY1Y2TZ2.\\nClaim 5.Q=TandZ2=.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 14}), Document(page_content='Claim 5.Q=TandZ2=.\\nBy Lemma 1, C3D(3,w)C1is within a side of X, sayK. Moreover, if T\\\\X=,\\nthenT\\\\XK. BecauseXhas a wheel relation with C(1,2),\\n|L\\\\C(1,2)|=|K\\\\C(1,2)||C1|.\\nThus,X\\\\C(1,2) =QZ2and|X\\\\C(1,2)|2|C1|=|T|. SinceT\\\\XK,\\nit follows that\\n|L\\\\C(1,2)|=|L\\\\C2||C2||C1|+|T\\\\X|=|K\\\\C(1,2)|,\\nimplying|T\\\\X|= 0and therefore that Q=TandZ2=.\\nClaim 6. (T;C1,Y1,C2,Y2,C3,...,Cw)forms a (w+ 2)-wheel.\\nBy Claims 4 and 5 we know |Y1|=|Y2|=|T|\\n2. There are three new wheel\\ncuts involving Y1,Y2that need to be conrmed, namely X=Y1TY2, which\\nseparatesC3D(3,w)C1fromC2, as well as CwTY1andY2TC4. The\\nlatter two are established by applying Lemma 2, as in Claim 3. We conclude that\\n(T;C1,Y1,C2,Y2,C3,...,Cw)forms a (w+ 2)-wheel.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 14}), Document(page_content='(T;C1,Y1,C2,Y2,C3,...,Cw)forms a (w+ 2)-wheel.\\nII. At most one index is in I1, so there must be indices in I2andI3that are adjacent in the\\ncircular order. Without loss of generality let them be 1I2,2I3, i.e.,C(1,2)is small,\\nS1X, andS2\\\\X=. By Lemma 1 there exist paths from any vertex in S2toC2\\\\X,\\nC3\\\\X, andT\\\\Xthat are not blocked by X, so they are all on the same side of X, call it side\\nK. Refer to Figure 9 in Claims 7 and 8.\\nClaim 7. There exists another side LofX, such that L\\\\C1=.\\nNoteC(1,3)separatesD(1,3)from the rest of the graph, and XseparatesKfrom the\\nrest of the graph. If the claim were not true, then C1XK, soG\\\\(XKC(1,3)\\nD(1,3))G\\\\(XK)=. We can now apply Lemma 2 (union rule) to C(1,3)andX,', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 14}), Document(page_content='and deduce that KD(1,3)is disconnected from the rest of the graph by\\n(C(1,3)\\\\K)(X\\\\D(1,3))X\\\\S1.\\nBut|X\\\\S1|<|X|=, a contradiction. So there exists a side Lsuch thatL\\\\C1=.\\n14', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 14}), Document(page_content='Figure 9: In case II S1XandS2\\\\X=.\\nClaim 8.Xis a crossing matching cut of C(1,3)in sideD(1,3)w.r.t.L\\\\C1, or a crossing\\nmatching cut of C(w,2)in sideD(w,2)w.r.t.K\\\\C2.\\nIfX\\\\D(3,1)=then Corollary 2 implies that Xis a crossing matching cut of C(1,3)\\nin sideD(1,3)w.r.t.L\\\\C1.\\nOtherwise, if X\\\\D(3,1) =, then because there are paths from every vertex in D(3,1)\\ntoSwwithin itself, and paths from SwtoC1\\\\Lnot blocked by X,D(3,1)L. Now\\nthatS3LandS2K, it follows that C3TX. Based on the same reason of\\nClaim 7, we have K\\\\C2=. Now for cut C(w,2), we know that X\\\\D(w,2)S1=,\\nX\\\\D(2,w)C3=,D(w,2) =SwC1S1XL, andK\\\\C(w,2) =K\\\\C2=,\\nby Corollary 2, Xis a crossing matching cut of C(w,2)w.r.t.K\\\\C2. u', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 15}), Document(page_content='III. W.l.o.g. we assume I1={1}and therefore I3={2,3,...,w}. WithY,Zdened as in case\\nI, we have\\nX=Y1Q(w\\ni=1Zi).\\nBecauseXhas a wheel type relation with C(1,2),Xhas exactly two sides, say KandL, and\\nmoreover, the intersections of Xwith the two sides of C(1,2)have equal size, i.e.,\\n|Y1|=\\nr{1,2}|Zr|=|Q||Z1||Z2|\\n2.\\nClaim 9.Q=T.\\nIfT\\\\X=, by Lemma 1 there exists paths from every vertex in Sr,r= 1, toT\\\\X, to\\nCr\\\\X, and toCr+1\\\\X, that are not blocked by X. Thus, ((D(2,1)T)\\\\X)is within\\na side ofX, say sideK. It follows that the other side LsatisesLS1. Applying\\nLemma 2 (intersection rule) to C(1,2)andX, we nd that L\\\\S1=Lis disconnected\\nfrom the rest of the graph by\\n(L\\\\C(1,2))(X\\\\C(1,2))(S1\\\\X) =Y1QZ1Z2.\\nThat means', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 15}), Document(page_content='That means\\n|Y1|+|Q|+|Z1|+|Z2|,\\nwhich implies\\n=|X|=|Y1|+|Q|+w\\ni=1|Zi||Y1|+|Q|+|Z1|+|Z2|,\\nand therefore Zr=for allr{1,2}, soX(C1TC2S1), contradicting the fact\\nthatX,C(1,2)have wheel type. Thus Q=T.\\n15', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 15}), Document(page_content='Claim 10 There exists j{1,2}such thatZj=Cj.\\nIftheredoesnotexistsucha j,thenitfollowsthat Cr\\\\Xisnonemptyforevery r{1,2}.\\nThus, there are paths from any vertex in SrtoCr\\\\Xand toCr+1\\\\Xthat are not blocked\\nbyX, soD(2,1)\\\\Xisstillcontainedinasideof X, sayK. IfC1\\\\XorC2\\\\Xisnonempty,\\nthen they are also in Kas well, since there exist paths from C1\\\\XtoSw, and fromC2\\\\X\\ntoS2. Then we have LS1. Based on exactly the same reasoning in Claim 9 we obtain\\nthe contradiction that X(C1TC2S1). This proves the claim.\\nClaim 11 (T;C1,Y1,C2,...,Cw)forms a wheel.\\nSinceQ=T,Cj=Zj, and\\n\\nr{1,2}|Zr|=|Q||Z1||Z2|\\n2|Q|\\n2=|T|\\n2=|Cj|=|Zj|,\\nit follows that|Zi|= 0fori=j. By Lemma 2 (intersection rule) it is easy to verify that', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 16}), Document(page_content='(T;C1,Y1,C2,...,Cw)forms a (w+1)-wheel, as is done in Claims 3 and 6, and this puts\\nus in case 6.\\nIV. Recall that I1I2I3={1,2,...,w}. In this case, except for at most one iI1, all other\\niare inI2and therefore SiX, then\\ni=iSi|X|=, so this is a small wheel and we\\nare in case 5.\\nV. Again recall that I1I2I3={1,2,...,w}. So in this case I3={1,2,...,w}. Therefore,\\nXT(w\\ni=1Ci). Note that the graph induced by (w\\ni=1Si){t}is connected for any tT,\\nand that every vertex in some Ciis adjacent to Si1andSi. This implies that TX, and\\nthat there exists indices i=jsuch thatCiCjX; otherwise Xis not even a cut. We have\\ndeduced that X=C(i,j)for somei,j, putting us in case 1.\\n3.2 Matching Cuts and Crossing Matching Cuts', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 16}), Document(page_content='3.2 Matching Cuts and Crossing Matching Cuts\\nDeneN(P)to be the neighborhood of PVandNA(P)def=N(P)\\\\A.\\nTheorem 4. LetUbe an arbitrary -cut andAa side ofU.\\n1If there exists a matching -cut ofUin sideAw.r.t.P, then it isW= (U\\\\P)NA(P), and\\n|P|=|NA(P)|<|A|. In particular, MatchU;A(P) =NA(P).\\n2When there is such a matching cut W,Gcontains a matching between PandMatchU;A(P) =\\nNA(P).\\n3Suppose MatchU;A(P)andMatchU;A(Q)exist. IfP\\\\Q=, then MatchU;A(P\\\\Q)exists,\\nand\\nMatchU;A(P\\\\Q) = Match U;A(P)\\\\MatchU;A(Q).\\nIf|A|>|PQ|, then MatchU;A(PQ)exists, and\\nMatchU;A(PQ) = Match U;A(P)MatchU;A(Q).\\n16', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 16}), Document(page_content='Proof.Part 1. By denition, Wis a matching cut in side Aw.r.t.Pif (i)W\\\\U=U\\\\P, (ii)\\nWUA, and (iii)Wseparates every vertex in A\\\\WfromP. It must be that NA(P)W,\\nfor otherwise Wwould not satisfy (iii). It also follows from (iii) that NA(P)\\\\A=. Since\\nW= (U\\\\P)NA(P)is a cut (separating A\\\\NA(P)fromPV\\\\(UA)), it follows that WW,\\nbut sinceWis a (minimum) -cut, thenW=Wand hence|P|=|NA(P)|. Thus, by denition\\nMatchU;A(P) =NA(P) =W\\\\Uisjusttheneighborhoodfunction NA(P)wheneversuchamatching\\ncutWexists.\\nPart 2. DeneHto be the bipartite subgraph of GbetweenPandNA(P) = Match U;A(P).\\nBy Halls theorem, if Hdoes not contain a matching then there exists a strict subset PPsuch', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 17}), Document(page_content='that|P|>|NA(P)|, but if this were the case, (U\\\\P)NA(P)would be a cut with cardinality\\nstrictly smaller than , a contradiction.\\nFigure 10: Left: a cut Uwith matching cuts in side A. Right: the derived ow network for\\nP,QU.\\nPart 3. Redene Hto be the bipartite subgraph of GbetweenPQandNA(PQ). We\\nconstruct a directed ow network Hon{s,t}V(H)as follows; see Figure 10. All edges from H\\nappear inH, oriented from PQtoNA(PQ), each having innite capacity. The edge set also\\nincludes edges from stoPQandNA(PQ)tot, each with unit capacity. Clearly integer ows in\\nHcorrespond to matchings in H. By the Knig-Egervry theorem, the size of the minimum vertex', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 17}), Document(page_content='cover inHis equal to the size of the maximum matching in H. Following the same argument in\\n2, they must both be of size |PQ|for otherwise Uwould not be a minimum vertex cut. In fact,\\nminimum size vertex covers of Hare in 1-1 correspondence with minimum capacity s-tcuts inH.\\nThe correspondence is as follows. If (S,T)is a minimum capacity s-tcut then there can be no\\n(innite capacity) edge from S\\\\(PQ)toT\\\\NA(PQ), so\\nC= ((PQ)\\\\T)(NA(PQ)\\\\S)\\nis a vertex cover in Hand\\n|C|= cap(S,T).\\nPicard and Queyrenne [38] observed that minimum s-tcuts are closed under union and in-\\ntersection, in the sense that if (S,T),(S,T)are mins-tcuts, then so are (SS,T\\\\T)and\\n(S\\\\S,TT). By assumption (P\\\\Q)NA(Q)and(Q\\\\P)NA(P)are minimum vertex covers10', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 17}), Document(page_content='ofH, with cardinality |PQ|. Translated to the ow network H, this implies that\\n10This follows from the fact that (U\\\\Q)NA(Q)and(U\\\\P)NA(P)are assumed to be matching cuts of UinA\\nw.r.t.QandP, respectively, with MatchU;A(P) =NA(P)andMatchU;A(Q) =NA(Q).\\n17', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 17}), Document(page_content='({s}QNA(Q),(P\\\\Q)NA(PQ)\\\\NA(Q){t})\\nand({s}PNA(P),(Q\\\\P)NA(PQ)\\\\NA(P){t})\\nare minimum s-tcuts, which implies that their union and intersection are also minimum s-tcuts:\\n({s}PQNA(PQ),{t})\\nand\\n{s}(P\\\\Q)(NA(P)\\\\NA(Q)),\\n\\n(PQ)\\\\(P\\\\Q))\\n\\nNA(PQ)\\\\(NA(P)\\\\NA(Q)))\\n{t})\\n.\\nTranslated back to H, these correspond to vertex covers\\nNA(PQ)\\nand(PQ)\\\\(P\\\\Q)(NA(P)\\\\NA(Q)).\\nWheneverNA(PQ)is astrictsubset ofAthe rst corresponds to a matching -cut ofU\\n(U\\\\(PQ))NA(PQ)\\nwith MatchU;A(PQ) =NA(PQ) = Match U;A(P)MatchU;A(Q).\\nWheneverP\\\\Q=the second corresponds to a matching -cut ofU\\n(U\\\\(P\\\\Q))(NA(P)\\\\NA(Q))\\nwith MatchU;A(P\\\\Q) =NA(P)\\\\NA(Q) = Match U;A(P)\\\\MatchU;A(Q).\\nFix a-cutUand a side AofU. Dene  ={P|MatchU;A(P)exists}. According to Part', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 18}), Document(page_content='3of Theorem 4, is closed under union and intersection, and is therefore characterized by its\\n18', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 18}), Document(page_content='minimal elements. Dene ={\\\\uP,PP|uU}. It can be seen from the denition that\\n\\\\uP,PPcorresponds to the minimum matching cut for vertex u.\\nIn the most extreme case may have 21elements (e.g., if the graph induced by UNA(U)is\\na matching), which may be prohibitive to store explicitly. From denition we know that ||,\\nso it works as a good compression for . Lemmas 4 and 5 also highlights some ways in which \\nis a sucient substitute for .\\nLemma 4. LetUbe a-cut and let be dened w.r.t. the matching cuts of Uin a sideA. Suppose\\nthatPandPQ, and thatWis a crossing matching cut of Uin sideAw.r.t.Q. Then\\n(W\\\\MatchU;A(Q))(Q\\\\P)MatchU;A(P)is also a crossing matching cut of UinAw.r.t.P.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 19}), Document(page_content='Moreover, if Q=P1P2Pwhere each Pi, then any pair disconnected by Wis also\\ndisconnected by some (W\\\\MatchU;A(Q))(Q\\\\Pi)MatchU;A(Pi).\\nProof.Apply Lemma 2 (intersection rule) to cuts Wand(U\\\\P)MatchU;A(P)and we have the\\nrst statement, that (W\\\\MatchU;A(Q))(Q\\\\P)MatchU;A(P)is a cut.\\nForthesecondstatement, suppose Wseparatesvertices uandv. Ifbothu,vUMatchU;A(Q),\\nthen they are separated by any(W\\\\MatchU;A(Q))(Q\\\\Pi)MatchU;A(Pi). If one ofu,vis inQ,\\nsayuQ, then there exists at least one ifor whichuPi. ThenvA\\\\Wand therefore u,vare\\nseparated by (W\\\\MatchU;A(Q))(Q\\\\Pi)MatchU;A(Pi).\\nLemma 5. LetUbe a-cut with two sides AandB, and let be dened w.r.t. its matching cuts', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 19}), Document(page_content='in sideA. ForP, deneU(P)to be the cut separating PfromA\\\\MatchU;A(P)minimizingSideU(P)(P).\\n1U(P)is either a crossing matching cut of Uin sideAw.r.t.P, or else there is no such\\ncrossing matching cut and U(P) = (U\\\\P)MatchU;A(P)is a matching cut.\\n2SupposeXis a crossing matching cut of Uin sideAw.r.t.P. Ifu,vare separated by X,\\nthen they are also separated by either U(P)or(X\\\\MatchU;A(P))P, which is a laminar\\ncut ofU.\\nProof.Part 1. LetWbe a cut that disconnects PfromA\\\\MatchU;A(P). Because every vertex in\\nMatchU;A(P)is adjacent to Pand adjacent to A\\\\MatchU;A(P), it follows that MatchU;A(P)W.\\nFrom Corollary 3 we know the set of all cuts separating PfromA\\\\MatchU;A(P)has a unique', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 19}), Document(page_content='minimum element. This is the cut U(P); let the sides of U(P)beK,LwithPKBP\\nandA\\\\MatchU;A(P)L.\\nIfK=BP, thenU(P) = (U\\\\P)MatchU;A(P). IfKBP, thenU(P)\\\\B=.\\nNow since MatchU;A(P)U(P)and(U(P)\\\\A)(U\\\\P)is a matching cut w.r.t. P, it follows\\nthatU(P)is a crossing matching cut of Uin sideAw.r.t.P.\\nPart 2. Fix such a crossing matching cut X. It disconnects PfromA\\\\MatchU;A(P), and has\\nexactly two sides, KPandLA\\\\MatchU;A(P). By the minimality of U(P)we haveKK.\\nBecauseX\\\\B=,KBP. Thus, ifU(P) = (U\\\\P)MatchU;A(P)is the matching cut\\n(not a crossing matching cut), this contradicts the existence of X. We conclude that U(P)is a\\ncrossing matching cut of U.\\nLetuKandvLbe disconnected by X. IfuB\\\\KandvLthen by Lemma 2', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 19}), Document(page_content='(intersection rule) applied to UandX,B\\\\Kis disconnected from the rest of the graph by\\n(X\\\\B)(X\\\\U)(U\\\\K) = (X\\\\MatchU;A(P))P, which is a laminar cut of U. By the\\nminimality of U(P),KKandU(P)KX, henceLL. WhenuPandvL, they\\nare also disconnected by U(P).\\n19', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 19}), Document(page_content='Corollary 4. Fix a cutUwith two sides AandB, and let be dened w.r.t. the matching cuts\\nin sideA, and letU(P)be dened as in Lemma 5. Dene U={U(P)|P}.\\nLetXbe a crossing matching cut of Uin sideAw.r.t.Q. Ifuandvare separated by X, then\\nthey are also separated by a member of Uor(X\\\\MatchU;A(Q))Q, a laminar cut of Uin sideB;\\nProof.By Lemma 4, w.l.o.g. we may assume that Q. SinceXis a crossing matching cut,\\nthere is a crossing matching cut U(Q)U. The claim then follows from Lemma 5.\\n3.3 Laminar Cuts\\nIn this section we analyze the structure of laminar cuts. Throughout this section, Urefers to a cut\\nthat isnot(I,1)-small,nota wheel cut C(i,j)in some wheel, and has a side Awith|A|>2.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 20}), Document(page_content='Consider the set of all cuts Wthat are laminar w.r.t. U, contained in UAand not (I, 1)-\\nsmall. It follows that Whas a side, call it S(W), that contains U\\\\Wand all other sides of U.11\\nDeneR(W)to be the region containing all other sides of WbesideS(W). We callWamaximal\\nlaminar cut of Uif there does not exist another laminar cut Wsuch thatR(W)R(W).\\nTheorem 5. LetUbe the reference cut.\\n1. If there exist matching cuts of Uin sideA, dene w.r.t.U,A, deneQ=PP, and\\nletX= (U\\\\Q)MatchU;A(Q)be the matching cut in side Ahaving the smallest intersection\\nwithU. Then every laminar cut WofUin sideAis\\n(i) a laminar cut of Xin regionA\\\\MatchU;A(Q), or\\n(ii) a matching cut of U, or\\n(iii) a crossing matching cut of X.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 20}), Document(page_content='(iii) a crossing matching cut of X.\\n2. If there are no matching cuts of Uin sideA, every laminar cut of Uin sideAis a maximal\\nlaminar cut, or a laminar cut of some maximal laminar cut Wiin a side of R(Wi). Moreover,\\nwheneverWi,Wjare distinct maximal laminar cuts, R(Wi)\\\\R(Wj) =.\\nProof.Part 1.Xhas a sideK=Q(V\\\\(UA))and a region L=A\\\\MatchU;A(Q). According\\nto the number of sides of X, we split into two cases:\\nI. IfXhas strictly more than two sides, let its sides be KandL1,L2,...,LrwhereL=r\\ni=1Li.\\nThen by Corollary 1, any other cut should have laminar type relation with X, or themselves\\nbe (I,1)-small cuts. But here the cut Win our concern are not (I, 1)-small. For', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 20}), Document(page_content='such aWofUin sideA, it can only be a laminar cut of Xin some side. If it was Li, then\\nwe have (i). If it was K, then we have that WXKand alsoWUA, so that\\nW(XK)\\\\(UA) =UMatchU;A(Q). Then by denition of ,Wis a matching cut\\nofUand we have (ii).\\nII. IfXhas exactly two sides, then they are K=Q(V\\\\(UA))andL=A\\\\MatchU;A(Q).\\nFix any laminar cut WofUin sideA. IfWA(U\\\\Q)thenWis a laminar cut of Xin\\nsideA\\\\MatchU;A(Q), and we are in case (i). If WUMatchU;A(Q), then by denition of\\n,W= (U\\\\P)MatchU;A(P)for somePandWis a matching cut of U, and we are in\\ncase (ii).\\nThus, we can proceed with the assumption that W\\\\Q=andW\\\\(A\\\\MatchU;A(Q))=.\\nTherefore,W\\\\K=andW\\\\L=. SoWmust have wheel type or crossing matching', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 20}), Document(page_content='11S(W)is exactlyBjof Theorem 2, if using its notation on UandW.\\n20', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 20}), Document(page_content='type relation with X. We only need to show that Wdoes not have wheel type relation with\\nX. BecauseR(W)A, we know that R(W)\\\\KA\\\\K=, so they do not have a wheel\\ntype relation. Then, Wmust be a crossing matching cut of X, and we are in case (iii).\\nPart 2. By assumption Udoes not have matching cuts in side A. Enumerate all of its maximal\\nlaminar cutsW={W1,W2,...,W|W|}. Fix any laminar cut WofUin sideA. IfWW,\\nthen by denition of maximality there exists some Wisuch thatR(W)R(Wi). It follows that\\nWR(Wi)Wi, soWis a laminar cut of Wiin one of the sides of R(Wi).\\nIt remains to prove that for all i=j,R(Wi)\\\\R(Wj) =. Suppose the statement were\\nfalse. Because S(Wi)\\\\S(Wj)=,Wi,Wjmust have laminar, crossing matching, or wheel type', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 21}), Document(page_content='relation. They cannot be laminar, for then R(Wi)R(Wj), orR(Wj)R(Wi), contradicting\\nthe maximality of Wi,Wj. Otherwise, WiandWjmust both have exactly two sides, namely\\nR(Wi),S(Wi)andR(Wj),S(Wj). Apply Corollary 3 to C=R(Wi)\\\\R(Wj)andD=S(Wi)\\\\\\nS(Wj), noticing that WiandWjdisconnects CandD, we may set Y= MinCut C;D. Because\\nRegionY(C)RegionWi(C)\\\\RegionWj(C) =R(Wi)\\\\R(Wj) =C,Cis actually a region of U. As\\nlong asR(Wi)R(Wj)=A,Yis a laminar cut of U, also contradicting the maximality of Wi,Wj.\\nThus, we proceed under the assumption that R(Wi)R(Wj) =A, meaningY=Uis not a laminar\\ncut ofU.\\nIfWiandWjhave a crossing matching type relation, at least one of R(Wi)\\\\S(Wj)and\\nR(Wj)\\\\S(Wi)is empty, suppose it is R(Wi)\\\\S(Wj) =. ThenR(Wi)R(Wj)Wj, but we', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 21}), Document(page_content='already have that R(Wi)R(Wj) =A, soR(Wj) =A\\\\Wj, which means Wjis a matching cut of\\nUin sideA, contradicting the assumption of Part 2 that Uhas no matching cuts in side A.\\nThe last case is when WiandWjhave a wheel type relation, i.e., they form a 4-wheel with\\ncenterT=Wi\\\\Wj, spokesWi\\\\R(Wj),Wi\\\\S(Wj),Wj\\\\R(Wi),Wj\\\\S(Wi), and sectors\\nR(Wi)\\\\R(Wj),R(Wi)\\\\S(Wj),S(Wi)\\\\R(Wj),S(Wi)\\\\S(Wj). Thus, the -cut(Wi\\\\S(Wj))\\n(Wi\\\\Wj)(Wj\\\\S(Wi))disconnects S(Wi)\\\\S(Wj)fromR(Wi)R(Wj) =A. This means\\nU= (Wi\\\\S(Wj))(Wi\\\\Wj)(Wj\\\\S(Wi))is also a cut of this wheel. This contradicts the\\noriginal assumption that our reference cut Uis not a wheel cut C(i,j)of some wheel.\\n3.4 Small Cuts\\nFix a vertex uand a threshold tn', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 21}), Document(page_content='Fix a vertex uand a threshold tn\\n2. Dene Smt(u)to be a cut Uminimizing|SideU(u)|with\\n|SideU(u)|t. We rst show that Smt(u), if it exists, is unique.\\nTheorem 6. If there exists any (III, t)-small cut that is small w.r.t. u, then there exists a unique\\nsuch cut, denoted Smt(u), such that for any other cut U,uU,\\nSide Smt(u)SideU(u).\\nProof.It suces to show that for any two (III, t)-small cuts U,W, there exists a cut X(possibly\\nUorW) such that\\nSideX(u)SideW(u)\\\\SideU(u).\\nIfSideU(u)SideW(u)orSideW(u)SideU(u), we may set X=UorX=W. IfV\\\\(UW\\nSideU(u)SideW(u))=, we may pick an arbitrary vertex vin this set, and apply Corollary 3 to\\nthe singleton sets C={u}andD={v}, and we may set X= MinCut C,D.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 21}), Document(page_content='These two cases above rule out the possibility that U,Whave a laminar or wheel type relation,\\nexcept when, using the notation of Theorem 2, Ai= SideU(u)andBj= SideW(u). But this\\nwould lead to a contradiction that\\n|V|=|Ai|+|Bj||Ai\\\\Bj|+|U\\\\W|\\n21', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 21}), Document(page_content='2n\\n2\\n1 + (1)\\n<n.\\nByTheorem2theremainingcaseisthat U,Whavecrossingmatchingtype,i.e., SideU(u)\\\\SideW(u)=\\n,SideW(u)\\\\SideU(u)=, andV=UWSideU(u)SideW(u). By Lemma 2 (intersection\\nrule), (U\\\\SideW(u))(W\\\\SideU(u))(U\\\\W)is a cut. If it has size exactly then we can\\nsetXto be this cut. We proceed under the assumption that it is strictly larger than . Thus, by\\ninclusion/exclusion,\\n|V|=|UWSideW(u)SideU(u)|\\n=|U|+|W|+|SideW(u)|+|SideU(u)|\\n|SideW(u)\\\\SideU(u)|(|U\\\\SideW(u)|+|W\\\\SideU(u)|+|U\\\\W|)\\nSinceuSideW(u)\\\\SideU(u), this is\\n2+ 2t1(+ 1)\\n2n\\n2\\n+2\\n<n,\\nwhich contradicts the denition of n=|V|. We conclude that when t(n)/2,Smt(u)is\\nunique if it exists.\\n4 A Data Structure for (+ 1)-Connectivity Queries', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 22}), Document(page_content='In this section we design an ecient data structure that, given u,v, answers (+ 1)-connectivity\\nqueries, i.e., reports that (u,v) =and produces a minimum -cut separating u,v, or reports\\nthat(u,v)+ 1.\\nWe work with the mixed-cut denition of (u,v)(see Remark 1), which is the minimum size set\\nof vertices and edges that need to be removed to disconnect uandv, or equivalently, the maximum\\nsize set of internally vertex-disjoint paths joining uandv.12\\nTheorem 7. Given a-connected graph G, we can construct in O(m+ poly()n)time a data\\nstructure occupying O(n)space that answers the following queries. Given u,vV(G), report\\nwhether(u,v) =or+ 1inO(1)time. If(u,v) =, report a-cut separating u,vinO()\\ntime.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 22}), Document(page_content='time.\\nSparsication. InO(m)time, the Nagamochi-Ibaraki [36] algorithm produces a subgraph G\\nthat has arboricity +1and hence at most (+1)nedges, such that G(u,v) =G(u,v)whenever\\nG(u,v)+ 1, andG(u,v)+ 1wheneverG(u,v)+ 1. Without loss of generality we\\nmay assume Gis theoutputof the Nagamochi-Ibaraki algorithm.\\n12If{u,v}E(G)and(u,v) =, then there exists UV,|U|=, such that removing Udisconnects u,v.\\nIf{u,v}E(G)then there exists UV,|U|=1, such that removing Uand{u,v}disconnects u,v. In this\\ncase the single-edge path {u,v}would count for one of the internally vertex disjoint paths, the other 1passing\\nthrough distinct vertices of U.\\n22', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 22}), Document(page_content='The Data Structure. Throughout this section we x the threshold t=n\\n2. Dene Sm(u) =\\nSmt(u)tobetheuniqueminimum -cutwith Side Sm(u)(u)t,ifanysuchcutexists,and Sm(u) =\\notherwise. The data structure stores, for each uV(G),Sm(u),|Side Sm(u)(u)|,aO(logn)-bit\\nidentier for Side Sm(u)(u), and for each vertex vN(u)\\\\Sm(u), a bitbu,vindicating whether\\n{{u,v}} Sm(u)\\\\{v}is a mixed cut disconnecting uandv. Furthermore, when |Side Sm(u)(u)|\\n1, we store Side Sm(u)(u)explicitly. When Sm(u) =we will say Side Sm(u)(u) =Gand henceSide Sm(u)=n. The total space is O(n).\\nConnectivity Queries. The query algorithm proceeds to the rst applicable case. Note in the\\nfollowing, Sm(u)may be, and for all vertices v, we dene v /.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 23}), Document(page_content='Case I: Sm(u) = Sm(v)and Side Sm(u)(u) = Side Sm(v)(v).Then(u,v)+ 1.\\nCase II:uSm(v)andvSm(u).Then(u,v) =. Without loss of generality suppose thatSide Sm(u)(u)Side Sm(v)(v). Then Sm(u)is a-cut separating uandv.\\nCase III:vSm(u)\\\\N(u), or the reverse. The bitbu,vindicates whether (u,v)+ 1or\\n(u,v) =, in which case{{u,v}} Sm(u)\\\\{v}is the-cut.\\nCase IV:vSm(u),uSm(v).Then(u,v)+ 1.\\nCase V:vSm(u),uSm(v), or the reverse. IfSide Sm(v)(v)1, directly check whether\\nuSide Sm(v)(v). If so then (u,v)+ 1; if not then Sm(v)disconnects them. ThusSide Sm(v)(v). IfSide Sm(v)(v)Side Sm(u)(u)then Sm(v)is a-cut separating uand\\nv, and otherwise (u,v)+ 1.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 23}), Document(page_content='v, and otherwise (u,v)+ 1.\\nLemmas 6, 7, and Theorem 8 establish the correctness of the query algorithm. Its construction\\nalgorithm is described and analyzed in Section 4.1.\\nLemma 6. IfvSide Sm(u)(u), then either Sm(v) = Sm(u)orSm(v)is a laminar cut of Sm(u)\\nwith Side Sm(v)(v)Side Sm(u)(u).\\nProof. Sm(u)is(III,t)-smallw.r.t. v. ByTheorem6, Sm(v)existsand Side Sm(v)(v)Side Sm(u)(v).\\nLemma 7. Supposeuandvare not (+ 1)connected, i.e., (u,v) =. If{u,v}E(G), then\\nthey are disconnected by Sm(u)orSm(v), and if{u,v}E(G), then they are disconnected by\\n{(u,v)}Sm(u)\\\\{v}or{(u,v)}Sm(v)\\\\{u}.\\nProof.First suppose{u,v}/E(G)and letXbe any cut separating uandv. Whent=n\\n2', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 23}), Document(page_content='2\\neither|SideX(u)|tor|SideX(v)|t. W.l.o.g. suppose it is the former, then Sm(u)exists and by\\nTheorem 6, Side Sm(u)(u)SideX(u), soSm(u)also separates uandv.\\nIf{u,v}E(G), suppose (1)verticesW={w1,w2,...,w1}and{u,v}disconnectuand\\nv. Afterremoving Wfromthegraph, G\\\\Wisstillconnected. Bydeletingtheedge {u,v}, thegraph\\nbreaks into exactly two connected components, say AandBwithuAandvB. ThenW{u}\\nforms a-cut with SideW{u}(v) =B, andW{v}also forms a -cut with SideW{v}(u) =A.\\nClearly we have\\nn=|W|+|A|+|B|=1 +|A|+|B|.\\n23', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 23}), Document(page_content='W.l.o.g. suppose |A||B|, then\\n|A|n+ 1\\n2\\n=n\\n2\\n=t.\\nThus Sm(u)exists, Side Sm(u)(u)SideW{v}(u), and Sm(u)is eitherW{v}or a laminar cut of\\nW{v}in sideA. Since{u,v}E(G), we havevSm(u). If we remove{u,v}fromG, then any\\npath fromutovgoes through a vertex in W, but any path from uto a vertex in Wgoes through\\na vertex in Sm(u)\\\\{v}. Therefore,{{u,v}}Sm(u)\\\\{v}is a mixed cut separating u,vas it blocks\\nallu-vpaths.\\nTheorem 8. The query algorithm correctly answers (+ 1)-connectivity queries.\\nProof.Suppose the algorithm terminates in Case I. It follows that uSm(v),vSm(u), and\\nneither Sm(u)norSm(v)disconnect uandv. Lemma 7 implies that (u,v)+ 1.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 24}), Document(page_content='In Case II, if Sm(u)=butSm(v) =then Sm(u)is the cut separating u,vand sinceSide Sm(u)(u)<Side Sm(v)(v)=n,thenthequeryisansweredcorrectly. Ifboth Sm(u),Sm(v)=,\\nthen by Lemma 6, v /Side Sm(u)(u)and once again the query is answered correctly.\\nIn Case III, by Lemma 7, if uandvare separated by a -cut, they are separated by {{u,v}}\\nSm(u)\\\\{v}(ifSm(u)=) or{{u,v}} Sm(v)\\\\{u}(ifSm(v)=), and this information is stored\\nin the bitbu,v,bv,u.\\nIf we get to Case IV then {u,v}E(G)and neither Sm(u)norSm(v)separateu,v, hence by\\nLemma 7,(u,v)+ 1and the query is answered correctly.\\nCase V is the most subtle. Because vSm(u)and{u,v}E(G), Lemma 7 implies that if', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 24}), Document(page_content='(u,v) =, thenu,vmust be separated by Sm(v). IfSm(v) =then(u,v)+ 1and the\\nquery is answered correctly. If |Side Sm(v)(v)|1then the query explicitly answers the query\\ncorrectly by direct lookup. Thus, we proceed under the assumption that Sm(v)=exists and is\\nnot small.\\nIfuSide Sm(v)(v)then Sm(v)does not disconnect uandv, and by Lemma 6,Side Sm(v)(v)>Side Sm(u)(u), so the query is handled correctly in this case.\\nIfu /Side Sm(v)(v)then Sm(v)separatesuandv, so we must argue thatSide Sm(v)(v)Side Sm(u)(u)for the query algorithm to work correctly. It cannot be that Sm(v)andSm(u)have\\na laminar relation, so by Theorem 2 they must have a crossing matching, wheel, or small type', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 24}), Document(page_content='relation. If they have the small-type relation then the small sides of Sm(u)are contained in Sm(v)\\n(contradicting uSm(v)) or the small sides of Sm(v)are contained in Sm(u), but we have already\\nrules out this case. Thus, the remaining cases to consider are wheel and crossing matching type.\\nSuppose Sm(u),Sm(v)form a 4-wheel (T;C1,C2,C3,C4). ThenuSm(v)appears in a sector\\nof the wheel, say S1. ThenC(1,2)is a cut violating the minimality of Sm(u) =C(1,3).\\nSuppose Sm(u),Sm(v)have a crossing matching type relation. Let A1= Side Sm(u)(u)andA2\\nbe the other side of Sm(u), andB1= Side Sm(v)(v)andB2be the other side of Sm(v). Then\\nuA1\\\\B2, and it must be that the diagonal quadrant A2\\\\B1=. Suppose otherwise, i.e.,', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 24}), Document(page_content='A2\\\\B1=, and letX= (Sm(u)\\\\B2)(Sm(v)\\\\A1)(Sm(u)\\\\Sm(v)). Then by Corollary 3\\nXis a-cut with SideX(u) =A1\\\\B2, contradicting the minimality of Sm(u). Thus, Sm(v)is a\\ncrossing matching cut of Sm(u)in sideA2w.r.t. some QSm(u)\\\\B1withvQ. By Theorem 2\\nanduA1\\\\B2=, we have\\n|A1\\\\Sm(v)|=|B2\\\\Sm(u)||A2\\\\Sm(v)|=|B1\\\\Sm(u)|=|Q|.\\n24', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 24}), Document(page_content='Thus,\\n|Side Sm(u)(u)|=|A1|>|(A1\\\\B1)Q|=|Side Sm(v)(v)|,\\nestablishing the correctness in the crossing matching case. (The strictness of the inequality is\\nbecauseA1\\\\B2=.)\\n4.1 Construction of the Data Structure\\nWe assume Nagamochi-Ibaraki sparsication [36] has already been applied, so Ghas arboricity +1\\nandO(n)edges. We use the recent Forster et al. [22] algorithm for computing the connectivity\\n=(G)inO(poly()n)time and searching for -cuts.\\nTheorem 9 (Consequence of Forster, Nanongkai, Yang, Saranurak, and Yingchareonthaworn-\\nchai [22]).Given parameter sn\\n2and a vertex x, there exists an algorithm that runs in time\\nO(s3)with the following guarantee. If the cut Sms(x)exists, it is reported with probability 3\\n4,', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 25}), Document(page_content='4,\\notherwise the algorithm returns . If the cut Sms(x)does not exist, the algorithm always returns\\n.\\nCorollary 5. GivenxV(G)and an integer sn\\n2, we can, with high probability 1\\n1/poly(n), compute Sms(x)inO(|Side Sms(x)(x)|3)time, or determine that Sms(x)does not\\nexist in O(s3)time.\\nProof.High probability bounds can be accomplished by repeating the algorithm of Theorem 9\\nO(logn)times. Use a doubling search to nd Sms0(x)for eachs0= 2i,i logs. When\\ns0|Side Sms(x)(x)|the procedure will succeed w.h.p.\\nWe call the procedure of Corollary 5 FindSmall (x,s).\\nDenition 1. LetUbe a cut,Aa side ofU. We use the notation A=G\\\\(UA)to be the region\\nof all other sides of U. DeneG(U,A)to be the graph induced by UA, supplemented with a', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 25}), Document(page_content='-clique onU. IfWis a cut inG(U,A), dene SideG(U,A)\\nW(x)to be SideW(x)in the graph G(U,A).\\nLemma 8. LetUbe a-cut,Abe a side of U, andWbe a set ofvertices inG(U,A). ThenW\\nis a-cut inG(U,A)if and only if Wis a laminar cut of Uin one of the sides of A. Moreover,\\nwhenWis such a cut, for any vertex uU\\\\W,\\nSideW(u) = SideG(U,A)\\nW(u)A.\\nProof.A laminar cut WofUin one of the sides of Adoes not disconnect vertices of U, so it is\\na cut inG(U,A). WhenWis a cut in G(U,A), all vertices of U\\\\Wshould be in one side Bof\\nW. Let the other sides of Wform a region C. Then inG, by Lemma 1, there exists paths from\\nvertices inAtoU\\\\Wthat are not blocked by W, so vertices in AandBtogether form a side D', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 25}), Document(page_content='ofW. But any path from CtoAshould pass through some vertex in U, while any path from Cto\\nB(involvingU\\\\W) should pass through W, soWis a cut inG. This proves the rst statement.\\nNoteBhere is exactly SideG(U,A)(u)\\nW, andDis exactly SideW(u), and we have that D=BA.\\nThis proves the second statement.\\nLemma 9 shows how, beginning with a cut Xwhere SideX(u)is small, can nd another cut Y\\n(if one exists) where SideY(u)is aboutM, inO(M4)time. The diculty is that there could be\\nan unbounded number of cuts between XandYthat would prevent the algorithm of Theorem 9\\nfrom nding Ydirectly.\\n25', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 25}), Document(page_content='Lemma 9. Fix any integer Mt/2, vertexu, and cutXwithA= SideX(u),|A|2M. There ex-\\nists an algorithm Expand (u,A,M )that runs in time O(M4)and, w.h.p., returns a cut Ysatisfying\\nthe following properties.\\nSideX(u)SideY(u).\\n|SideY(u)|2M.\\nIf there exists a cut Zthat is (III, M)-small w.r.t. u, then|SideY(u)||SideZ(u)|.\\nProof.This algorithm uses Corollary 5 and Lemma 8.\\n1. Initially YX. While|SideY(u)|<M,\\n(a) For each vertex vY, in parallel,\\ni. In the graph G(Y,SideY(u)), run FindSmall (v,M).\\n(b) The moment any call to FindSmall halts in step (i) with a cut W, stop all such calls and\\nsetYW. If all|Y|calls to FindSmall run to completion without nding a cut, halt\\nand return Y.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 26}), Document(page_content='and return Y.\\nThroughout the algorithm, Yis always a cut such that SideX(u)SideY(u)and|SideY(u)|\\n2M. Furthermore,|SideY(u)|is strictly increasing, so the algorithm terminates. By Corollary 5\\nthe running time of (a) is O(4)where  =|SideW(u)||SideY(u)|if a cutWis found, and\\n =Motherwise. (The extra factor is due to the parallel search in step (a).) The sum of the\\ns telescopes to O(M), so the overall running time is O(M4).\\nSuppose the cut Zexists. If it were not the case that |SideY(u)||SideZ(u)|, then in the last\\niteration,|SideY(u)|<|SideZ(u)|M. We argue below that there is another cut to nd, and\\ntherefore that the probability the algorithm terminates prematurely is 1/poly(n), by Corollary 5.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 26}), Document(page_content='Note that|SideY(u)|+|SideZ(u)|2Mt, soCdef=G\\\\(SideY(u)SideZ(u)YZ)=.\\nApply Corollary 3 to sets CandD={u}, we may set U= MinCut C;D. Because RegionU(C)\\nRegionY(C)\\\\RegionZ(C) =C,Cis actually a region of U, soUis a laminar cut of Y,SideU(u)\\nSideY(u)SideZ(u). Since|SideY(u)|<|SideZ(u)|,U=Y. Then for any vertex vY\\\\U,\\n0<SideG(Y,SideY(u))\\nU(v)|SideU(u)||SideY(u)||SideZ(u)|M.\\nTherefore,Uor some other cut should have been found in step (a) in the last iteration.\\nTheorem 10 (Consequence of Picard and Queyrenne [38]) .LetH= (V,E, cap)be a capacitated\\ns-tow network and fbe a maximum ow. In O(|E|)time we can compute a directed acyclic graph\\nH= (V,E)with|E||E|, and an embedding :VV{}, such that the downward closed', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 26}), Document(page_content='sets ofHare in 1-1 correspondence with the minimum s-tcuts ofH. I.e., ifVVis a vertex\\nset with no arc of EleavingV, then (1(V),1(V))is a mins-tcut inH, and all min s-t\\ncuts inHcan be expressed in this way. Here (v) =ifvappears on the  t side of every min s-t\\ncut.\\nWe use Corollary 6 to nd Smt(u)for potentially many vertices uin bulk.\\nCorollary 6. Fix two disjoint, non-empty vertex sets CandD. InO(2(n|C||D|))time, we\\ncan output a cut S(v)for everyvV\\\\(CD), such that if Sm(v)exists andCSide Sm(v)(v),\\nthenS(v) = Sm(v).\\n26', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 26}), Document(page_content='Proof.Form a ow network Gas in the proof of Corollary 3, shrinking CandDto verticessandt,\\nsplitting each vintovin,vout, etc. The minimum sout-tincuts inGare in 1-1 correspondence with\\nthe minimum vertex cuts separating C,DinG. We are only interested in these cuts if they have\\nsize, so in this case a maximum ow fcan be computed in O(2(n|C||D|))time. (Recall\\nthat the graph is assumed to have arboricity + 1, so every induced subgraph of Ghas density\\nO().)\\nGivenG,f, the Picard-Queyrenne representation G,can be computed in linear time. For\\neachvG, letS(v)be the cut corresponding to the smallest downward-closed set containing\\n(v)inG. Thus, the set{S(v)}vV\\\\(CD)can be enumerated by a bottom-up traversal of Gin', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 27}), Document(page_content='O(|E(G)|) =O((n|C||D|))time. IfCSide Sm(v)(v)then clearly S(v) = Sm(v).\\nWe are now ready to present the entire construction algorithm.\\nPreamble. The algorithm maintains some -cutT(u)for eachu, which is initially , and\\nstores|SideT(u)(u)|. If the algorithm makes no errors, T(u) = Smt(u) = Sm(u)at the end\\nof the computation. The procedure Update (u,U)updatesT(u)UifUis a better cut, i.e.,\\n|SideU(u)| min{|SideT(u)(u)|1,t}, and does nothing otherwise. Update (A,U)is short for\\nUpdate (u,U)for alluA.\\nStep 1: very small cuts. For eachuV, letUFindSmall (u,100)and then Update (u,U).\\nThis takes O(n4)time.\\nStep 2: unbalanced cuts. For each index isuch that 100 < 2it, let= 2i, and', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 27}), Document(page_content='pick a uniform sample ViVof size (nlogn)/.13For eachuVi, compute Sm(u)\\nFindSmall (u,). IfSm(u) = Sm(u)=, we rst do an Update (Side Sm(u)(u),Sm(u)), then com-\\nputeYExpand (u,Sm(u),). For each vYwe compute WvFindSmall (w,)and then\\nUpdate (v,Wv). We then run the algorithm of Corollary 6 with C= Side Sm(u)(u)andD=V\\\\(Y\\nSideY(u)), which returns a set of cuts {S(v)}vV\\\\(CD). For each such vSideY(u)\\\\Side Sm(u)(u),\\ndo an Update (v,S(v)). For each index i, the running time is O(|Vi|4) = O(n4), which is\\nO(n4)overall.\\nStep 3: balanced cuts. SampleO(logn)pairs (x,y)V2. For each such pair, compute\\nUFindSmall (x,t). IfU=, apply the algorithm of Corollary 6 to C= Side Sm(x)(x)and', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 27}), Document(page_content='D={y}, which returns a set {S(v)}. Then do an Update (v,S(v))for everyvV\\\\(CD). By\\nCorollary 5 this takes O(3n)time.\\nStep 4: adjacent vertices. At this point it should be the case that T(u) = Sm(u)for allu. For\\neachvT(u)\\\\N(u)compute and set the bit bu,v. (This information can be extracted from the\\ncalls to FindSmall and the algorithm of Corollary 6 in the same time bounds.)\\nLemma 10 is critical to proving the correctness of the algorithms search strategy.\\nLemma 10. Suppose Sm(u)andSm(v)exists,uSide Sm(v)(v), and suppose there is a cut W\\nsuch that\\nSide Sm(v)(v)<|SideW(u)|t.\\n13The Forster et al. [22] algorithm samples vertices proportional to their degree. Note that after the Nagamochi-', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 27}), Document(page_content='Ibaraki [36] sparsication, the minimum degree is at least and the density of every induced subgraph is at most\\n+ 1, so it is equally eective to do vertex sampling.\\n27', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 27}), Document(page_content='ThenvWSideW(u).\\nProof.BecauseuSide Sm(v)(v),byLemma6, Sm(u)=isalaminarcutof Sm(v)andSide Sm(u)(u)\\nSide Sm(v)(u).\\nConsider the relationship between WandU= Sm(v). We use the same notation U,W,A,\\nBandTfrom Theorem 2. Neither UnorWis (I,1)-small, so they may have laminar, wheel,\\nor crossing matching type relation.\\nIf they have laminar type relation, then uSideW(u)\\\\SideU(u), so either SideW(u)isAior\\nSideU(u)isBj, but they cannot be both true as otherwise\\n|V|=n>2n\\n2\\n+2|Ai|+|Bj||Ai\\\\Bj|+|T|=|V|.\\nIfSideW(u)isAithenvSideW(u). IfSideU(u)isBjthen|SideW(u)|<Side Sm(v)(u), which\\ncontradicts the denition of W.\\nIf they have wheel type relation, then vcannot lie in a sector of the 4-wheel formed by Wand', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 28}), Document(page_content='U, as this would violate the minimality of Sm(v). Therefore vW.\\nIf they have crossing matching type relation, suppose A1\\\\B1=,A2\\\\B2=andA1\\\\B2=.\\nThenvW(and the proof is done) or vA2\\\\B1, because for vA1\\\\B1,W1TU1is a cut\\nwith side smaller than Sm(v), and forvA2\\\\B2,U2TW2is a cut with a side smaller than\\nSm(v).\\nIfvA2\\\\B1, then by Theorem 2, |W2||U2|. Also,A2isSide Sm(v)(v)souA2. Thus\\n|SideW(u)||SideU(v)|=|B2||A2|=|U2||W2||A2\\\\B1|<0,\\nwhich contradicts the condition that |SideW(u)|>Side Sm(v)(v).\\nTheorem11. The construction algorithm correctly computes {Sm(v)}vVand runs in time O(n4).\\nProof.If|Side Sm(v)(v)|100, thenT(v) = Sm(v)after Step 1, with high probability.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 28}), Document(page_content='Suppose that|Side Sm(v)(v)|[2j,2j+1]and2j+1t. Then with high probability, at least\\none vertex xVjis sampled in Step 2 such that xSide Sm(v)(v). Step 2 ( Expand) computes a\\ncutYsuch that|SideY(x)|| Side Sm(v)(v)|, so by Lemma 10, either vSideY(x)orvY. In\\nthe former case Sm(v)is computed using the Corollary 6 algorithm. In the latter case Sm(v)is\\ncomputed directly using FindSmall .\\nFinally, if Sm(v)is balanced, say|Side Sm(v)(v)|t/4, then w.h.p. we would pick a pair (x,y)\\nin Step 3 such that xSide Sm(v)(v)andyV\\\\(Sm(v)Side Sm(v)(v)). If this holds the algorithm\\nof Corollary 6 correctly computes Sm(v).\\n5 Conclusion\\nThis paper was directly inspired by the extended abstract of Cohen, Di Battista, Kanevsky, and', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 28}), Document(page_content='Tamassia [10]. Our goal was to substantiate the main claims of this paper, and to simplify and\\nimprove the data structure that answers (+ 1)-connectivity queries.\\nWe believe that our structural theorems can, ultimately, be used to develop even more versatile\\nvertex-cut data structures. For example, is it possible to answer the following more general queries\\ninO()time using O(n)space?\\nIs-it-a-cut? (u1,...,u):Returntruei{u1,...,u}forms a-cut.\\n28', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 28}), Document(page_content='Part-of-a-cut? (u1,...,ug):Returntruei the input can be extended to a -cut{u1,...,ug}\\n{ug+1,...,u}.\\nWe assumed throughout the paper that was not too large, specically <n/ 4. Whenn<2,\\nallcuts are (I,)-small by our classication, and the classication theorem (Theorem 2) says very\\nlittle about the structure of such cuts. Understanding the structure of minimum vertex cuts when\\nis large, relative to n, is an interesting open problem.\\nReferences\\n[1] A. Abboud, R. Krauthgamer, and O. Trabelsi. Cut-equivalent trees are optimal for min-cut\\nqueries. In Proceedings of the 61st IEEE Annual Symposium on Foundations of Computer\\nScience (FOCS) , pages 105118, 2020.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 29}), Document(page_content='Science (FOCS) , pages 105118, 2020.\\n[2] S. Baswana, K. Choudhary, and L. Roditty. Fault tolerant subgraph for single source reacha-\\nbility: generic and optimal. In Proceedings of the 48th Annual ACM Symposium on Theory of\\nComputing (STOC) , pages 509518, 2016.\\n[3] J. D. Batson, D. A. Spielman, and N. Srivastava. Twice-Ramanujan sparsiers. SIAM J.\\nComput., 41(6):17041721, 2012.\\n[4] G. D. Battista and R. Tamassia. Incremental planarity testing (extended abstract). In Pro-\\nceedings of the 30th Annual Symposium on Foundations of Computer Science (FOCS) , pages\\n436441, 1989.\\n[5] G. D. Battista and R. Tamassia. On-line maintenance of triconnected components with SPQR-\\ntrees.Algorithmica , 15:302318, 1996.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 29}), Document(page_content='trees.Algorithmica , 15:302318, 1996.\\n[6] A. A. Benczr. Counterexamples for directed and node capacitated cut-trees. SIAM J. Com-\\nput., 24(3):505510, 1995.\\n[7] A. A. Benczr and M. X. Goemans. Deformable polygon representation and near-mincuts.\\nIn M. Grtschel and G. O. H. Katona, editors, Building Bridges: Between Mathematics and\\nComputer Science , volume 19 of Bolyai Society Mathematical Studies , pages 103135. 2008.\\n[8] A. A. Benczr and D. R. Karger. Randomized approximation schemes for cuts and ows in\\ncapacitated graphs. SIAM J. Comput. , 44(2):290319, 2015.\\n[9] K. Choudhary. An optimal dual fault tolerant reachability oracle. In Proceedings 43rd Intl\\nColloq. on Automata, Languages, and Programming (ICALP) , 2016.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 29}), Document(page_content='[10] R. F. Cohen, G. Di Battista, A. Kanevsky, and R. Tamassia. Reinventing the wheel: an\\noptimal data structure for connectivity queries (extended abstract). In Proceedings of the 25th\\nAnnual ACM Symposium on Theory of Computing (STOC) , pages 194200, 1993.\\n[11] W. H. Cunningham and J. Edmonds. A combinatorial decomposition theory. Canadian J.\\nMath., 32(3):734765, 1980.\\n[12] E. A. Dinic, A. V. Karzanov, and M. V. Lomonosov. On the structure of the system of\\nminimum edge cuts in a graph. Studies in Discrete Optimization , pages 290306, 1976. (in\\nRussian).\\n29', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 29}), Document(page_content='[13] Y. Dinitz and Z. Nutov. A 2-level cactus model for the system of minimum and minimum +1\\nedge-cuts in a graph and its incremental maintenance. In Proceedings 27th ACM Symposium\\non Theory of Computing (STOC) , pages 509518, 1995.\\n[14] Y. Dinitz and Z. Nutov. A 2-level cactus tree model for the system of minimum and\\nminimum +1edge cuts of a graph and its incremental maintenance. Part I: the odd case.\\nUnpublished manuscript, 1999.\\n[15] Y. Dinitz and Z. Nutov. A 2-level cactus tree model for the system of minimum and\\nminimum +1edge cuts of a graph and its incremental maintenance. Part II: the even case.\\nUnpublished manuscript, 1999.\\n[16] Y. Dinitz and A. Vainshtein. The connectivity carcass of a vertex subset in a graph and its', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 30}), Document(page_content='incremental maintenance. In Proceedings of the 26th Annual ACM Symposium on Theory of\\nComputing (STOC) , pages 716725, 1994.\\n[17] Y. Dinitz and A. Vainshtein. Locally orientable graphs, cell structures, and a new algorithm\\nfor the incremental maintenance of connectivity carcasses. In Proceedings of the 6th Annual\\nACM-SIAM Symposium on Discrete Algorithms (SODA) , pages 302311, 1995.\\n[18] Y. Dinitz and A. Vainshtein. The general structure of edge-connectivity of a vertex subset in\\na graph and its incremental maintenance. odd case. SIAM J. Comput. , 30(3):753808, 2000.\\n[19] R. Duan and S. Pettie. Connectivity oracles for failure prone graphs. In Proceedings 42nd\\nACM Symposium on Theory of Computing , pages 465474, 2010.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 30}), Document(page_content='[20] R. Duan and S. Pettie. Connectivity oracles in graphs subject to vertex failures. SIAM J.\\nComput., 49(6):13631396, 2020.\\n[21] D. Firmani, L. Georgiadis, G. F. Italiano, L. Laura, and F. Santaroni. Strong articulation\\npoints and strong bridges in large scale graphs. Algorithmica , 74(3):11231147, 2016.\\n[22] S. Forster, D. Nanongkai, L. Yang, T. Saranurak, and S. Yingchareonthawornchai. Computing\\nand testing small connectivity in near-linear time and queries via fast local cut algorithms.\\nInProceedings of the 31st ACM-SIAM Symposium on Discrete Algorithms (SODA) , pages\\n20462065. SIAM, 2020.\\n[23] H. N. Gabow. Using expander graphs to nd vertex connectivity. J. ACM, 53(5):800844,\\n2006.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 30}), Document(page_content='2006.\\n[24] Y. Gao, J. Li, D. Nanongkai, R. Peng, T. Saranurak, and S. Yingchareonthawornchai.\\nDeterministic graph cuts in subquadratic time: Sparse, balanced, and k-vertex. CoRR,\\nabs/1910.07950, 2019.\\n[25] L. Georgiadis, G. F. Italiano, L. Laura, and N. Parotsidis. 2-edge connectivity in directed\\ngraphs.ACM Trans. Algorithms , 13(1):9:19:24, 2016.\\n[26] L. Georgiadis, G. F. Italiano, L. Laura, and N. Parotsidis. 2-vertex connectivity in directed\\ngraphs.Inf. Comput. , 261:248264, 2018.\\n[27] L. Georgiadis, G. F. Italiano, and N. Parotsidis. Strong connectivity in directed graphs under\\nfailures, with applications. SIAM J. Comput. , 49(5):865926, 2020.\\n30', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 30}), Document(page_content='[28] R.E.GomoryandT.C.Hu. Multi-terminalnetworkows. Journal of the Society for Industrial\\nand Applied Mathematics , 9, 1961.\\n[29] D. Guseld and D. Naor. Ecient algorithms for generalized cut trees. In Proceedings First\\nACM-SIAM Symposium on Discrete Algorithms , pages 422433, 1990.\\n[30] J. E. Hopcroft and R. E. Tarjan. Dividing a graph into triconnected components. SIAM\\nJ. Comput. , 2(3):135158, 1973.\\n[31] A. Kanevsky, R. Tamassia, G. D. Battista, and J. Chen. On-line maintenance of the four-\\nconnected components of a graph. In Proceedings 32nd IEEE Symposium on Foundations of\\nComputer Science (FOCS) , pages 793801, 1991.\\n[32] B. M. Kapron, V. King, and B. Mountjoy. Dynamic graph connectivity in polylogarithmic', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 31}), Document(page_content='worst case time. In Proceedings of the 24th Annual ACM-SIAM Symposium on Discrete Algo-\\nrithms (SODA) , pages 11311142, 2013.\\n[33] A. Korman. Labeling schemes for vertex connectivity. ACM Trans. on Algorithms , 6(2), 2010.\\n[34] S. Mac Lane. A structural characterization of planar combinatorial graphs. Duke Math. J. ,\\n3(3):460472, 1937.\\n[35] K. Menger. Zur allgemeinen kurventheorie. Fundamenta Mathematicae , 10:96115, 1927.\\n[36] H. Nagamochi and T. Ibaraki. A linear-time algorithm for nding a sparse k-connected span-\\nning subgraph of a k-connected graph. Algorithmica , 7(5&6):583596, 1992.\\n[37] M. P atracu and M. Thorup. Planning for fast connectivity updates. In Proceedings 48th', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 31}), Document(page_content='IEEE Symposium on Foundations of Computer Science (FOCS) , pages 263271, 2007.\\n[38] J.-C. Picard and M. Queyranne. On the structure of all minimum cuts in a network and\\napplications. In Combinatorial Optimization II , volume 13 of Mathematical Programming\\nStudies, pages 816. 1980.\\n[39] C.-P. Schnorr. Bottlenecks and edge connectivity in unsymmetrical networks. SIAM J. Com-\\nput., 8(2):265274, 1979.\\n[40] R. E. Tarjan. Depth-rst search and linear graph algorithms. SIAM J. Comput. , 1(2):146160,\\n1972.\\n[41] W. T. Tutte. A theory of 3-connected graphs. Nederl. Akad. Wetensch. Proc. Ser. A 64 =\\nIndag. Math. , 23:441455, 1961.\\n[42] W. T. Tutte. Connectivity in Graphs . University of Toronto Press, 1966.', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 31}), Document(page_content='[43] H. Whitney. Congruent graphs and the connectivity of graphs. American J. Mathematics ,\\n54(1):150168, 1932.\\n[44] H. Whitney. Non-separable and planar graphs. Trans. Amer. Math. Soc. , 34(2):339362, 1932.\\n31', metadata={'source': '/share/lab4/ych/papers/paper2.pdf', 'page': 31})]\n",
      "[Document(page_content='arXiv:2201.00408v1  [cs.DS]  2 Jan 2022Optimal Vertex Connectivity Oracles\\nSeth Pettie\\nUniversity of MichiganThatchaphol Saranurak\\nUniversity of MichiganLonghui Yin\\nTsinghua University\\nAbstract\\nAk-vertex connectivity oracle for undirected Gis a data structure that, given u,vV(G),\\nreports min{k,(u,v)}, where(u,v) is the pairwise vertex connectivity between u,v. There\\nare three main measures of eciency: construction time, query tim e, and space. Prior work of\\nIzsak and Nutov [ IN12 ] shows that a data structure of total size O(kn) can even be encoded as\\naO(k)-bit labeling scheme so that vertex-connectivity queries can be an swered in O(k) time.\\nThe construction time is polynomial, but unspecied.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 0}), Document(page_content='In this paper we address the top three complexity measures.\\nSpace. We prove that any k-vertex connectivity oracle requires ( kn) bits of space. This an-\\nswers a long-standing question on the structural complexity of ve rtex connectivity, and\\ngives a strong separation between the complexity of vertex- and e dge-connectivity. Both\\nIzsak and Nutov [ IN12 ] and our data structure match this lower bound up to polyloga-\\nrithmic factors.\\nQuery Time. We answer queries in O(logn) time, independent of k, improving on (k) time\\nof [IN12 ]. The main idea is to build instances of SetIntersection data structures, with\\nadditional structure based on ane planes. This structure allows f or optimum query time', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 0}), Document(page_content='that is linear in the output size (This evades the general k1/2o(1)andk1o(1)lower bounds\\nonSetIntersection from the 3SUM orOMv hypotheses, resp. [ KPP16 ,HKNS15 ].)\\nConstruction Time. We build the data structure in time roughly that of a max-ow comput a-\\ntion on a unit-capacity graph, which is m4/3+o(1)using state-of-the-art algorithms [ KLS20 ].\\nMax-ow is a natural barrier for many problems that have an all-pair s-min-cut avor. The\\nmain technical contribution here is a fast algorithm for computing a k-bounded version\\nof a Gomory-Hu tree for element connectivity , a notion that generalizes edge and vertex\\nconnectivity.\\nThis work was supported by NSF grant CCF-1815316.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 0}), Document(page_content='1 Introduction\\nMost measures of graph connectivity can be computed in polynomial time, and much of the re-\\ncent work in graph algorithms aims at reducing these complexities to some natural barrier , ei-\\nther near-linear [ Kar00 ,KP09 ,FNY+20,GMW20 ,GMW21 ,MN20 ,vdBLL+21,Sar21 ], max-ow-\\ntime [ LP20 ,LNP+21], or matrix-multiplication-time [ CLL13 ,AGI+19]. Graph connectivity has\\nalso been extensively studied from a structural perspective, where the aims are to understand\\nthe structure of some/all minimum cuts. This genre includes Gomory-Hu trees [ GH61 ], the cac-\\ntus representation [ DKL76 ], block-trees, SPQR-trees, and extensions to higher verte x connectiv-', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 1}), Document(page_content='ity [BT96 ,KTBC91 ,CDBKT93 ,PY21 ], and many others [ Ben95b ,BG08 ,GN93 ,DV94 ,DV95 ,\\nDV00 ,DN95 ,DN99a ,DN99b ,PQ80 ,GILP16 ,GILP18 ,FGI+16].\\nIn this paper we study the data structural approach to understanding graph connectivity, which\\nincorporates elements of the algorithmic andstructural camps, but goes further in that we want to\\nbe able to eciently query the connectivity, e.g., either ask for the size of a min-cut o r the min-cut\\nitself.\\nSuppose we are given an undirected graph Gand wish to be able to answer pairwise edge- and\\nvertex-connectivities up to some threshold k. Let(u,v) and(u,v) be the maximum number of\\nedge-disjoint and internally vertex-disjoint paths, resp ., between utov. By Mengers theorem,', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 1}), Document(page_content='these are equal to the minimum number of edges and vertices, r esp., necessary to disconnect uand\\nv.1\\ne-conn(u,v):Return min{(u,v),k}.\\ne-cut(u,v):If(u,v)< k, return an edge-cut separating u,vwith size (u,v).\\nv-conn(u,v):Return min{(u,v),k}.\\nv-cut(u,v):If(u,v)< k, return a vertex-cut separating u,vwith size (u,v).\\nThe edge-connectivity problems are close to being solved. A Gomory-Hu tree T[GH61 ] (akacut\\nequivalent tree ) is an edge-weighted tree such that the bottleneck edge ebetween any u,vhas\\nweight(u,v), and the partition dened by T{e}corresponds to a (u,v)-edge cut, which can\\nbe explicitly associated with eif we wish to also answer e-cutqueries. Bottleneck queries can be', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 1}), Document(page_content='answered in O(1) time with O(nlogn) preprocessing, or O((n)) time with O(n) preprocessing;\\nsee [Pet06 ,DLW09 ,Cha87 ].2The time to compute the full Gomory-Hu tree is O(m3/2n1/6) [AKT20 ]\\nand there are faster O(n2)-time algorithms on simple graphs [ AKT21 ,LPS21 ] orO(m+nk3)-time\\nalgorithms [ HKP07 ] for representing connectivity up to k.\\nThus,e-conn-queries can be answered in O(1) time by a data structure occupying space O(n).\\nIt is a long-standing open problem whether a similar result i s possible for v-conn-queries. In\\n1979 Schnorr [ Sch79 ] proposed a cut-equivalent tree for roundtrip ow3in directed graphs, and in\\n1990 Guseld and Naor [ GN90 ] used Schnorrs result to build a Gomory-Hu-type tree for ve rtex', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 1}), Document(page_content='connectivity. Benczur [ Ben95a ] found errors in Schnorr [ Sch79 ] and Guseld and Naor [ GN90 ], and\\n1If{u,v} E, then(u,v) represents the size of a mixed cut separating u,vconsisting of {u,v}and(u,v)1\\nother vertices.\\n2These upper and lower bounds are in the comparison model. Whe nGis unweighted, all min-cut values are\\nintegers in [1 ,n), which can be sorted in linear time. In this case O(n) preprocesssing for O(1)-time queries is\\npossible.\\n3min{f(u,v),f(v,u)}\\n1', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 1}), Document(page_content='Citation Space (Words) Labeling (Bits) Query Time Construction Time\\nBlock-tree k= 2O(n) O(1) O(m)\\nBlock-tree + SPQR-\\ntree [ BT96 ]k= 3O(n) O(1) O(m)\\nBlock-tree + SPQR-\\ntree + [ KTBC91 ]k= 4O(n) O(1) O(m+n(n))\\n[KKKP04 ]O(n2k) O(2klogn)O(2k) poly(n)\\n(klog(n/k3))any any\\n[Kor10 ] O(nk3) O(k3logn)O(klogk) poly(n)\\n[HL09 ] O(nk2) O(k2logn)O(logk) poly(n)\\n[IN12 ] O(nklogn)O(klog3n)O(klogn) poly(n)\\n[AGI+19] O(n2) O(nlogn)O(1) O(nk)\\n[PY21 ]k=(G) + 1O(n(G))O((G) logn)O(1) O(m+npoly((G)))\\n[Nut21 ] ( )O(nk2+n2) O(1) poly(n)\\nNewO(nklogn)O(klog3n)O(logn)Tow(m)poly(k,logn)\\n(nk/logn) ( k) avg.any any\\nTable 1: A history of vertex-connectivity oracles. By convention, space f or centralized data structures is', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 2}), Document(page_content='measured in O(logn)-bit words and space for labeling schemes is measured in bits. With a c ouple exceptions,\\nall data structures and lower bounds are for v-conn(u,v) = min{(u,v),k}queries, where kis an arbitrary\\nparameter. The constructions based on block trees, SPQR trees [BT96 ], and [ KTBC91 ] only work for\\nk{2,3,4}, and Pettie and Yin [ PY21 ] only works when k=(G) + 1 where (G) is the global minimum\\nvertex connectivity of G. Nutovs [ Nut21 ] data structure ( ) determines whether (u,v)kand if so, returns\\na pointer to a cut of size at most kinO(1) time. The ( klog(n/k3)) lower bound of Katz et al. [ KKKP04 ]\\nis for the worst-case (longest) label length; it implies nothing on ave rage length. The new ( nk)-bit lower', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 2}), Document(page_content='bound is for the total size of the data structure, and implies an ( k)-bit lower bound on the average length\\nof any labeling scheme.\\nproved more generally that there is no cut-equivalent tree f or vertex connectivity. Benczur [ Ben95a ,\\npp. 505-506] suggested a way to get a ow-equivalent tree for roundtrip ow using a result of Cheng\\nand Hu [ CH91 ], which would yield a Gomory-Hu-type tree suitable for answ eringv-conn (but not\\nv-cut) queries. This too, turned out to be incorrect. Hassin and Le vin [HL07 ] gave an example of\\na vertex-capacitated graph (integer capacities in [1 ,nO(1)]) that has ( n2) distinct pairwise vertex\\nconnectivities, which cannot be captured by a Gomory-Hu-ty pe tree representation.4', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 2}), Document(page_content='When the underlying graph has unit capacity , the counterexamples of [ Ben95a ,HL07 ] do not\\nrule out a representation of vertex-connectivity using, sa y,O(1) trees, nor do they rule out some\\ncompletely dierent O(n)-space structure for answering v-conn-queries, independent of k.\\nMost prior data structures supporting v-conn queries were actually labeling schemes . I.e., a\\nvertexlabeling:V{0,1}is created such that a v-conn(u,v) query is answered by inspecting\\n(u),(v). Katz, Katz, Korman, and Peleg [ KKKP04 ] initiated this line of research into labeling for\\nconnectivity. They proved that the maximum label length to a nswerv-conn queries is ( klog(n/k3))', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 2}), Document(page_content='andO(2klogn). To be specic, they give a class of graphs for which a (1 /k2)-fraction of the\\n4Hassin and Levin [ HL07] pointed out that Benczurs proposal yields a Gomory-Hu-ty pe tree representation for\\nvertex separations  in a capacitated graph G= (V,E,c:VR+). The minimum separation of u,vis the minimum\\nofc(u),c(v),and the minimum c(K) over all vertex cuts Kdisconnecting u,v.\\n2', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 2}), Document(page_content='vertices require ( klog(n/k3))-bit labels. However, this does not imply any non-trivial bound on the\\naverage/total label length. Their upper bound was subseque ntly improved to O(k3logn) [Kor10 ]\\nand then to O(k2logn) [HL09 ].5Using a dierent approach, Izsak and Nutov [ IN12 ] gave an\\nO(klog3n)-bit labeling scheme for v-conn queries. A centralized version of the data structure takes\\nO(knlogn) total space6and can be augmented to support v-cutqueries with O(k2nlogn) total\\nspace.\\nThe labeling schemes [ KKKP04 ,Kor10 ,HL09 ,IN12 ] focus on label-length, and do not discuss\\nthe construction time in detail, which is a large polynomial .\\n1.1 New Results', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 3}), Document(page_content='1.1 New Results\\nWe resolve the long-standing question concerning the space complexity of representing vertex con-\\nnectivity; cf. [ Ben95a ,HL07 ]. In particular, we prove that any data structure answering v-conn\\nqueries requires space ( kn/logn) (i.e., ( kn)bits), and that the lower bound extends to threshold\\nqueries (decide whether (u,v)k), equality queries (decide whether (u,v) =k), and approxi-\\nmate queries (distinguish (u,v)< k\\nkfrom(u,v)> k+\\nk). This implies that Izsak and\\nNutovs [ IN12 ] centralized data structures are optimal to within a log2n-factor, and that even\\ntheaverage length of their labeling scheme cannot be improved by more th an a log3n-factor;', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 3}), Document(page_content='cf. [KKKP04 ]. It also implies a strong separation between the space comp lexity of storing all\\nedge-connectivities ( O(n) space) and all vertex-connectivities (( n2/logn) space when k=n).\\nAlthough the Izsak-Nutov structure is space-optimal, its O(klogn) query time and polynomial\\nconstruction time can be substantially improved. We design a version of this structure that allows\\nforO(logn) query time independent of k. The key problem is to create random instances of\\nSetIntersection that are still structured enough to answer intersection que riesSiSjoptimally, in\\ntimeO(|SiSj|). Conditional lower bounds from 3SUM andOMv [KPP16 ,HKNS15 ] imply that\\nthis should be impossible for worst-case instances of SetIntersection .', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 3}), Document(page_content='Turning to construction time, we prove that the vertex conne ctivity oracle (or labeling scheme)\\ncan be constructed in time Tuow(m)poly(k,logn), where Tuow(m) is the time for one max-\\now computation on unit-capacity graphs with medges. The main subproblem solved in the\\nconstruction algorithm is computing a Gomory-Hu tree for element connectivities up tok.\\n1.2 Organization\\nSection 2covers some preliminary concepts such as vertex connectivi ty, element connectivity,\\nGomory-Hu trees, and the (vertex-cut version of) the isolat ing cuts lemma of [ LP20 ,LNP+21].\\nSection 3presents the lower bound on representations of vertex conne ctivity. Section 4presents', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 3}), Document(page_content='a space- and query-ecient vertex connectivity oracle base d on Izsak and Nutovs [ IN12 ] labeling\\nscheme. In order to build this oracle eciently, we need to co mpute Gomory-Hu trees that capture\\nall element connectivities up to k. In Section 5we show how to do this in Tuow(m)poly(k,logn)\\ntime.\\nSection 6concludes with some outstanding open problems.\\n5The labeling schemes of Katz et al. [ KKKP04 ], Korman [ Kor10], and Hsu and Lu [ HL09] dierentiate between\\n(u,v)k0and(u,v)< k0using labels of size O(2k0logn),O(k2\\n0logn), andO(k0logn), respectively. They can\\nbe used to answer v-connqueries by concatenating labels for all k0= 1,2,...,k, thereby introducing an O(k)-factor\\noverhead in [ Kor10,HL09].', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 3}), Document(page_content='overhead in [ Kor10,HL09].\\n6Following convention, the space of centralized data struct ures is measured in O(logn)-bit words and labeling\\nschemes are measured in bits.\\n3', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 3}), Document(page_content='2 Preliminaries\\n2.1 Vertex Connectivity, Element Connectivity, and Gomory -Hu Trees\\nDeneG(u,v) to be the vertex connectivity of u,vinG= (V,E), i.e., the maximum number of\\ninternally vertex-disjoint paths between uandv. By Mengers theorem [ Men27 ], this is the size of\\nthe smallest mixed cut C(E(V{u,v})) whose removal disconnects u,v.7Element connectivity\\nis a useful generalization of vertex- and edge-connectivit y [Che15 ,CRX15 ,JMVW02 ,CK12 ]. Let\\nUVbe a set of terminals. Then for u,vU,\\nG,U(u,v) is the maximum number of paths between\\nuandvthat are E-disjoint and ( VU)-disjoint. By duality, this is equivalently the size of the\\nsmallest mixed cut C(E(VU)) whose removal disconnects u,v. Observe that when U=V,\\n', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 4}), Document(page_content='\\nG,U(u,v) =G(u,v) is the same as edge-connectivity, and when U={u,v},\\nG,U(u,v) =G(u,v)\\ncaptures vertex connectivity. More generally we have Lemma 2.1, which follows directly from the\\ndenitions.\\nLemma 2.1. Fix an undirected graph G= (V,E)and a terminal set UV. For any u,vU,\\n\\nG,U(u,v)G(u,v)with equality if and only if there exists a mixed G(u,v)-cutCdisconnecting\\nu,vwithCU=.\\nIfCis a mixed cut, the connected components of GCare called sides ofC. Note that\\nminimum edge-cuts have two sides but minimum vertex-cuts ma y have an unbounded number of\\nsides. For any AV,Ais the set of vertices adjacent to AinG, but not in A. Thus,Ais a\\nvertex cut disconnecting AfromV(AA).', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 4}), Document(page_content='vertex cut disconnecting AfromV(AA).\\nIt is well known that Gomory-Hu trees exist for element conne ctivity; see [ Sch03 ,CRX15 ]. We\\nuse the following general denition:\\nDenition 2.2. Ak-Gomory-Hu tree for element connectivity w.r.t. graph Gand terminal set U\\nis a triple (T,f,C )satisfying\\n(Flow equivalency) T= (VT,ET,w:ET[1,k))is a weighted tree and f:UVT. If\\nf(u) =f(v)then\\nG,U(u,v)kand otherwise, \\nG,U(u,v) = min eT(f(u),f(v))w(e), where\\nT(x,y)is the unique T-path between xandy.\\n(Cut equivalency) C:ET2E(VU). For any eT(f(u),f(v)),C(e)is aw(e)-cut\\ndisconnecting u,v. (Each of the two connected components in Terepresents the union of\\nsome subset of the sides of C(e).)', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 4}), Document(page_content='some subset of the sides of C(e).)\\nNote that fis unnecessary ( VT=U) ifk=is unbounded, and that Cis unneces-\\nsary if we are only interested in min {\\nG,U(u,v),k}-queries. This denition can be extended\\nto (1 +)-approximations by relaxing the rst criterion to \\nG,U(u,v)mineT(f(u),f(v))w(e)\\n(1 +)\\nG,U(u,v), with trivial f(VT=Uandfmaps trivially), and the second criterion similarly.\\n2.2 Isolating Cut Lemma and Max-Flows\\nLi and Panigrahis [ LP20 ]isolating cuts lemma nds, for a terminal set I, the minimum edge-cut\\nseparating uIfromI{u}in time proportional to O(log|I|) max-ows. It was generalized to\\n7Sometimes only pure vertex cuts CV {u,v}are considered and G(u,v) is left undened or articially', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 4}), Document(page_content='dened to be |V|1 whenever u,vare adjacent in G. This denition fails to distinguish highly connected and p oorly\\nconnected pairs of vertices that happen to be adjacent.\\n4', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 4}), Document(page_content='vertex connectivity in [ LNP+21] and here we generalize this lemma slightly further to be abl e to\\nhandleelement connectivity.\\nLemma 2.3 (Isolating cuts, vertex version with forbidden terminals) .LetIFbe an independent\\nset in graph G= (V,E), andIF=. We want to nd, for each vI, a setSvVsuch that\\n(i)SvI={v}and(Sv)F=, (ii) it minimizes |Sv|, (iii) subject to (ii), it minimizes |Sv|.\\nThen{Sv}vIcan be computed with log|I|calls to max-ow on graphs with O(m)edges,O(m)\\nvertices, and capacities in {1,}. If we do not care to minimize |Sv|if it is larger than k, then\\nthe max-ow instances can be unit-capacity multigraphs wit hO(m+k|F|)edges and vertices.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 5}), Document(page_content='Proof. (sketch) The proof follows [ LNP+21, Lemma 4.2]. The authors called max-ow instances\\nto compute the isolating cuts. Our lemma adds a new requireme nt, that SvF=. This can\\nbe eected by replacing vFin the ow networks with two vertices and an edge vinvoutwith\\ncapacity. (Or in the unit-capacity case, with k+ 1 parallel edges from vintovout.) This ensures\\nvertices in Fnever appear in the cuts Svwe are interested in.\\n3 Space Lower Bound on Vertex Connectivity Oracles\\nInformal strategy and intuitions. We use an error-correcting-code-type argument to derive\\nan (n2)-bit lower bound in the case that k=n. By taking the product of n/k copies of this', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 5}), Document(page_content='construction on ( k)-vertex graphs, we derive the ( kn)-bit lower bound for general k[1,n].\\nThe idea is to show the existence of a codebookTofnnBoolean matrices with the following\\nproperty. Each TT can be represented by a certain graph G[T] onO(n) vertices. We compute\\nab-bit vertex connectivity oracle for this graph and query G[T](u,v) for all pairs u,v. From these\\nvalues we reconstruct a dierent Boolean matrix T=T, which is within the decoding radius of T,\\nand therefore lets us deduce the identity of the original mat rixT. In other words, it must be that\\nblog2|T|. A key technical idea is to show that each TT in the codebook can, in a certain', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 5}), Document(page_content='sense, be approximately factored as the product of two rectangular Boolean matrices , with addition\\nand multiplication over Z.\\nThe specics of the construction are detailed in Theorem 3.1.\\nTheorem 3.1. There exists a constant c5and a subsetT { 0,1}nnof boolean matrices\\nhaving the following properties.\\n1. (Code Properties) |T|= 2n2/3, each row of each TThas Hamming weight exactly n/2, and\\nevery two T,TThas Hamming distance at least n2/3.\\n2. (Matrix Decomposition) For every TT, there exists A{0,1}ncn,B{0,1}cnnsuch\\nthatC=ABencodesTin the following way. Let T{0,1}nnbe such that\\nT(i,j) ={0ifC(i,j)<2n\\n1ifC(i,j)2n\\nThenT,Thave Hamming distance less than n2/6. Moreover, C(i,j)2.1nfor alli,j.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 5}), Document(page_content='3. (Vertex Connectivity) Let A,Bbe the matrices corresponding to Tfrom Part 2. Let G[T] =\\n(XYZ,E)be an undirected tripartite graph with |X|=|Z|=nand|Y|=cn, where\\n5', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 5}), Document(page_content='E(XY)encodesAandE(YZ)encodesB. Let Tbe such that\\nT(i,j) ={0if(xi,zj)<4n2\\n1if(xi,zj)4n2\\nThenT,Thave Hamming distance less than n2/6.\\nProof. For Part 1, a simple probabilistic construction shows the ex istence ofT. Pick a random\\ncodebookT0containing (1+ o(1))2n2/3matrices and discard a negligible fraction of codewords tha t\\nare within distance (2 /5)n2of another codeword. Obtain TfromT0as follows. Take each T0T0\\nand see if it is within Hamming distance O(n3/2) of a matrix T, all of whose rows have Hamming\\nweightn/2. If so, include TTas a representative of T0. Only a negligible fraction of T0matrices\\nfail to satisfy this property. Thus, Thas the requisite size and each pair of matrices in Thas', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 6}), Document(page_content='Hamming distance at least (2 /5)n2O(n3/2)> n2/3.\\nTurning to Part 2, the construction of A,B is probabilistic. We pick Buniformly at random\\nsuch that each row has Hamming weight n/2, then choose Adepending on B. We call ( i,k)eligible\\nif the vector B(k,) has an unusually high agreement with T(i,), in particular, if\\n|{j:B(k,j) =T(i,j)}|n/2 +n.\\nFor each row i, we setA(i,k) = 1 for the rst 4 nvalues of kfor which ( i,k) is eligible. Since the\\nprobability of ( i,k) being eligible is some constant p, it is possible to build Awith high probability\\nifcis suciently large, say 4 p1+ 1.\\nSuppose T(i,j) = 1 and consider the random variable C(i,j). By the denition of eligibility\\nand the fact that rows of BandThave Hamming weight n/2,', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 6}), Document(page_content='Pr(B(k,j) = 1|(i,k) eligible)1/2(n/2 +n)\\nn/2=1\\n2+1n\\nThusC(i,j) is a random variable that dominates Binom(4 n,1/2 + 1/n), hence E(C(i,j))\\n2n+4n. The case when T(i,j) = 0 is symmetric, in which case Binom(4 n,1/21/n) dominates\\nC(i,j). By a Cherno bound, the probability that T(i,j)=T(i,j) is the probability that C(i,j)\\ndeviates from its expectation by at least 4n, which is at most exp( 2(4n)2/4n) = exp(8).\\nThe Hamming distance between TandTis therefore at most n2exp(8)< n2/6 in expectation.\\nLastly, by a Cherno bound, the probability that C(i,j) deviates from 2 nby a constant factor\\nis exponentially small. In particular, we have C(i,j)2.1nfor alli,jwith high probability. This\\nproves the existence of matrices A,B for anyTT.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 6}), Document(page_content='proves the existence of matrices A,B for anyTT.\\nPart 3. Observe that C(i,j) reects the maximum ow from xitozjifG[T] were a unit-\\ncapacity network with all edges directed from XYZ. However, G[T] is undirected, and by\\nMengers theorem (xi,zj) is the maximum number of internally vertex disjoint paths f romxi,zj.\\nWe consider paths of length 2 (corresponding to C(i,j)) and two types of paths of length 4.\\nFor technical reasons we will modify the construction of Aas follows. For each row i, set\\nA(i,k) = 1 for r=O(clogn) values of kchosen uniformly at random, then set A(i,k) = 1 for\\n4nradditional values of kfor which ( i,k) is eligible. This changes the expectation of C(i,j) by', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 6}), Document(page_content='O(clogn)/n <1 but does not otherwise aect the analysis in Part 2.\\nWe claim that with high probability, the vertex connectivit y ofxi,zjis exactly\\n(xi,zj) = min{C(i,j) + 2(n1),4n}.\\n6', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 6}), Document(page_content='In particular there are (xi,zj) pathsP=P0P1P2, where|P0|=C(i,j) are length-2 paths,\\nP1aren1 paths internally disjoint from P0of the form xiYXYzjandP2are up\\nton1 paths disjoint from P0P1of the form xiYZYzj.\\nWe construct P1as follows. Choose Y1,xto be any n1 neighbors of xithat are not part\\nofP0paths, and Y1,zto be any n1 neighbors of zjthat are not part of P0paths. Clearly\\nY1,xY1,z=. LetG1,x,G1,zbe the subgraphs of G[T] induced by X{xi}Y1,xandX{xi}Y1,z,\\nrespectively. These graphs contain many edges of derived fr omA, but we only consider the redges\\nper vertex generated randomly.8Sincer= (clogn) and|Y|=cn, vertices in both G1,xand', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 7}), Document(page_content='G1,zhave degree (log n) with high probability. It is well known that such graphs hav e perfect\\nmatchings w.h.p. (see [ Bol11 ] or [ FK16 ]); call them M1,x,M1,z. Together with xi,zj, these form\\nn1 pathsP1internally disjoint from P0. The construction of paths P2is symmetric. Let Y2,x\\nbe min{n1,4n|P0||P1|}neighbors of xinot already included in P0,P1, andY2,zbe|Y2,x|\\nneighbors of zjnot included in P0,P1. Note that both Y2,xandY2,zhave size at least 0 .9nbecause\\n|P0|2.1nand|P1|n. The graphs G2,x,G2,zinduced by Z{zj}Y2,xandZ{zj}Y2,z\\nagain contain perfect matchings M2,x,M2,zwith high probability.9Together with xiandzjthese\\ngenerate|Y2,x|paths internally disjoint from P0,P1.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 7}), Document(page_content='We conclude that with high probability, C(i,j)<2nif and only if (xi,zj)<2n+ 2(n1)\\nand, from Part 2, that there exist A,B such that T,T have Hamming distance less than n2/6.\\nCorollary 3.2. Suppose D(G,k)is a data structure for an undirected n-vertex graph Gthat can\\ndetermine whether (u,v)< kor(u,v)k. Then Drequires (kn)bits of space in the worst\\ncase.\\nProof. Pick any T T, and let G=G[T] be the ( c+ 2)n-vertex graph encoding of Tfrom\\nTheorem 3.1. Using D(G,k) we can generate the matrix T, wherek= 4n2, and then deduce\\nTsince Tis within its decoding radius. Thus, Drequires at least log |T|= (n2) bits of space.\\nFor general values of k, we can take ( n/k) disjoint copies of this construction, each having ( k)', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 7}), Document(page_content='vertices and requiring ( k2) space.\\nRemark 3.3.The lower bound of Corollary 3.2also applies to data structures D(G,k) that dis-\\ntinguish between (u,v) =kand(u,v)=k. For this case we would use the construction of\\nTheorem 3.1withk= 4nand let T(i,j) = 1 i (xi,zj) = 4n.\\nCorollary 3.4. Suppose D(G,k, )is a data structure for an undirected n-vertex graph Gthat can\\ndistinguish between (u,v)<(1)kor(u,v)>(1 +)k. Then Drequires (n2)bits of space\\nfor some .\\nProof. The construction of Theorem 3.1and Corollary 3.2still works when k= (n) and=\\n(1/n).\\n8The edges included by the eligibility criterion have subtle dependencies, which makes reasoning about them', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 7}), Document(page_content='somewhat tricky. Including truly random edges in Ais a technical hack and surely not necessary.\\n9Note that G2,x,G2,zcorrespond to submatrices of B, which was chosen randomly with density 1/2. Due to the\\nHamming weight restriction, the entries of Bare slightly negatively correlated, which only improves the chance of\\nnding perfect matchings.\\n7', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 7}), Document(page_content='4 Vertex Connectivity Oracles\\nLemma 2.1says that for any terminal set U,\\nG,U(u,v)never underestimates the true value G(u,v)\\nand achieves the equality \\nG,U(u,v) =G(u,v) in the event that some minimum mixed u-vcut\\nCu,vis disjoint from U. Furthermore, \\nG,Uis superior than Ginasmuch as it can be succinctly\\nrepresented as a Gomory-Hu tree (Denition 2.2) and queried via bottleneck edge queries [ Pet06 ,\\nDLW09 ,Cha87 ].\\nIzsak and Nutovs [ IN12 ] ingenious algorithm proceeds by sampling several termina l sets with\\nprobability 1 /k. Each terminal set includes both uandvwith probability 1 /k2andavoidsCu,vwith\\nconstant probability if |Cu,v|k, henceO(k2logn) terminal sets suce to accurately capture all', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 8}), Document(page_content='vertex connectivities up to kwith high probability. The space for the centralized data st ructure is\\njust that of storing O(k2logn) Gomory-Hu trees and data structures for answering bottlen eck-edge\\nqueries. Each tree is on O(n/k) terminals, for a total of O(knlogn) space. A query v-conn(u,v)\\nneeds to examine all terminal sets containing bothuandv. This is a classic SetIntersection query.\\nEach of u,vis in (klogn) sets, and are jointly in (log n) sets. In this section we show how\\nto build appropriate SetIntersection instances such that queries are answered in (optimal) O(logn)\\ntime. (If minimum cuts are associated with edges in the Gomor y-Hu tree, a v-cut(u,v) query can', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 8}), Document(page_content='be answered in O(1) additional time be returning a pointer to the appropriat e cut. This increases\\nthe space to O(k2nlogn).)\\nA terminal set UVcaptures u,vif there exists a (u,v)-cutCVEsuch that\\nU({u,v}C) ={u,v}.\\nWe show how to nd O(k2logn) terminal sets that capture all pairs in V2using a construction\\nbased on ane planes and 3-wise independent hash functions.\\nLemma 4.1. There is an algorithm using O(log2n)random bits that generates terminal sets U\\nwith the following properties.\\n|U|=O(k2logn)and each UUhas|U|=O(n/k).\\nGiven vertices u,vwith(u,v)kwe can nd O(logn)setsU1,...,U O(logn)such that each,\\nindependently, captures u,vwith constant probability. As a consequence, w.h.p., Ucaptures\\nall ofV2.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 8}), Document(page_content='all ofV2.\\nProof. Letp0be the rst prime larger than n=|V|andpbe the rst prime larger than 2 k. Let\\nH= (P,L) be a subset of an ane plane, dened as follows. P={ui,j|i[p],j[p0/p]}is\\na set of points arranged in a rectangular grid and L={s,j|s,j[p]}is a set of lines, where\\ns,j={ut,j+stmodp|t[p0/p]}is the line with slope spassing through u0,j. We pick a hash\\nfunction h:VPof the form\\nh(x) = (ax2+bx+c) modp0\\nwherea,b,c are chosen uniformly at random from [ p0], then form the p2= (k2) terminal sets\\nU[h] ={Us,j}as follows.\\nUs,j={v|h(v)s,j}.\\nNow x any two vertices u,vand a(u,v) cutCwith(u,v)k. ThenU[h] will capture u,vif\\n(i)h(u),h(v) dier in their 1st coordinates of the rectangular grid P, and, assuming this happens,\\n8', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 8}), Document(page_content='(ii)CUs,j=wheres,jis the unique line containing h(u),h(v). The probability of (i) is\\n1p/p0= 1(k/n) and the probability of (ii) is\\nPr(CUs,j=|h(u),h(v))1\\nxCVPr(h(x)s,j|h(u),h(v))1kp0/p/p01/2\\nwhere the second last inequality is because |s,j|p0/p,|C|k, andhis sampled from a 3-wise\\nindependent hash family.\\nLetUbe the union ofU[h1],...,U[hO(logn)] using independent hash functions h1,...,h O(logn).\\nIt follows that|U|=O(p2logn) =O(k2logn), that given u,vwe can identify U1,...,U O(logn)U\\ninO(logn) time such that at least one of these terminal sets captures u,vw.h.p.10\\nWe now turn to the load balancing condition |U|=O(n/k). Note that if the coecients of h', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 9}), Document(page_content='satisfy (a,b,c )= (0,0,c) thenhis at most a 2-to-1 function (as the polynomial dening hhas degree\\n2), meaning that each UU has|U|<2p0/p=O(n/k). The performance of the algorithm is\\nclearly quite bad when a=b= 0 (each terminal set Uis eitherorV) so we can remove these\\nhash functions from the hash family and only improve the prob ability of success.\\nRemark 4.2.One way thatU[h] can fail to capture u,vis ifh(u) andh(v) agree on their 1st\\ncoordinate. This could be rectied by including the lines wi th innite slope in L, but this only\\nseems to work when kn. Whenkndoing so would violate the load balancing constraint\\n|U|=O(n/k) as some lines would necessarily have size ( k).', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 9}), Document(page_content='Now, by using the collection Uof terminal sets with additional structure from Lemma 4.1instead\\nof theO(k2logn) random terminal sets generated independently as used in [ IN12 ], we can speed\\nup the query time from O(k) toO(logn). Below, we state the guarantee of our oracle formally.\\nTheorem 4.3. Given an undirected graph G= (V,E)andk[1,n], a data structure with size\\nO(knlogn)can be constructed in O(m) +Tuow(nk)poly(k,logn) =O(m) +n4/3+o(1)poly(k)time\\nsuch that v-conn(u,v) = min{G(u,v),k}queries can be answered in O(logn)time. Using space\\nO(k2nlogn), av-cut(u,v)query can be answered in O(1) additional time; it returns a pointer to a\\nG(u,v)-sizeu-vcut whenever G(u,v)< k.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 9}), Document(page_content='G(u,v)-sizeu-vcut whenever G(u,v)< k.\\nThe claims of Theorem 4.3concerning construction time are substantiated in Section 5. In\\nthe context of our vertex connectivity oracle, note that we c an assume that our original graph has\\nO(nk) edges by applying Nagamochi-Ibaraki algorithm [ NI92 ] withO(m) running time to reduce\\nthe number of edges to O(kn). So the construction time is n4/3+o(1)poly(k) using the max-ow\\nalgorithm for unit-capacity graphs by Kathuria, Liu, and Si dford [ KLS20 ].\\n5 Gomory-Hu Trees for Element Connectivity\\nThe goal in this section is to prove the following:\\nTheorem 5.1. Ak-Gomory-Hu tree for element connectivity w.r.t. graph Gand terminal set U\\ncan be constructed in O(kTuow(m+k|U|))time.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 9}), Document(page_content='can be constructed in O(kTuow(m+k|U|))time.\\n10Given points h(u),h(v) diering in 1st coordinate, we can clearly identify s,jcontaining them in O(1) time using\\na table of inverses modulo p.\\n9', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 9}), Document(page_content='Note that, given the above theorem, we can indeed conclude Th eorem 4.3because there are\\nO(k2logn) terminal sets in the oracle construction and we just need to build a Gomory-Hu tree\\nfor each terminal set by calling Theorem 5.1. Asm=O(nk) and|U|=O(n/k) by Lemma 4.1,\\nthis takes Tuow(m+k|U|) =Tuow(O(nk)) for each terminal set.\\nObstacles in Adapting Algorithms of [ LP21] for Element Connectivity. The proof of\\nTheorem 5.1is obtained by adapting the Gomory-Hu tree construction for edge connectivity by\\nLi and Panigrahi [ LP21 ] to work for element connectivity . Although we use the same high-level\\napproach, element connectivity introduces some extra comp lication that we need to deal with.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 10}), Document(page_content='For example, given an input graph G, all Gomory-Hu tree algorithms for edge connectivity\\nproceed by nding a minimum edge cut ( A,B), contract one side, say B, of the cut into a single\\nvertexb, and recurse on the contracted graph denoted by G. By submodularity of edge cuts, we\\nhave that the edge connectivity between any two vertices a1,a2Aare preserved in G. This is\\ncrucial for the correctness of the whole algorithm.\\nUnfortunately, the direct analog of this statement fails co mpletely for element connectivity. For\\nexample, suppose p,q /Bare disconnected by an element cut Cof graph G. Then in graph G,\\nC={b}(C\\\\B) becomes an element cut disconnecting pandq. As long as Ccontains more', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 10}), Document(page_content='than one element in B(an edge, or a non-terminal vertex), |C|<|C|, so(p,q) decreased.\\nTo bypass this complication, we actually exploit the genera lity of element connectivity. When\\nwe recurse in a contracted graph, the trick is to add the contr acted node into a terminal set for\\nelement connectivity. That is, the terminal set will change throughout the recursion so that we can\\npreserve element connectivity between vertices inside the subject graph.\\nIn the rest of this section, we formally prove Theorem 5.1.\\n5.1 The Approximate Element Connectivity Gomory-Hu Tree Al gorithm\\nInstead of proving Theorem 5.1directly, it is more convenient to prove the following (1 + )-', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 10}), Document(page_content='approximation version, which is precisely the element conn ectivity analog of the result in [ LP21 ].\\nTheorem 5.2. A(1 +)-approximate Gomory-Hu tree for element connectivity w.r. t. graph G\\nand terminal set Ucan be computed in O(1Tow(m))time, where Tow(m)is the time to compute\\nmax ow in an m-edge graph.\\nTheorem 5.1almost follows from Theorem 5.2just by setting = 1/k. However, there is some\\nminor things to take care of, and we give the formal proof in Se ction 5.2.\\nBefore we give the proof of Theorem 5.2, observe that as a simplifying assumption, Lemma 2.3\\n(isolating cuts with forbidden terminals) required that IFbe an independent set. We can force', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 10}), Document(page_content='any instance to satisfy this property by subdividing all edg es inE(IF)2. As a consequence,\\nfrom now we can assume that all element cuts in the modied gra ph consist solely of vertices.11\\n5.1.1 Algorithm\\nThe precise algorithm for Theorem 5.2is described in Algorithm 1. For the reader to better\\nunderstand, we rst briey explain how the algorithm works, how the input and the output of the\\nalgorithm relate to Denition 2.2.\\n11If (x,y) is subdivided into ( x,vxy),(vx,y,y), then any vertex-only element cut containing vx,yin the modied\\ninstance contains ( x,y) in the original instance, and vice-versa.\\n10', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 10}), Document(page_content='The basic framework of the algorithm is a recursion. For a ran dom set of terminals Ri, we\\ncall Lemma 2.3to compute its isolating cuts Si\\nv. We select those vsuch that Si\\nv(1 +)andSi\\nvU|U|/2 into set Ri\\nsm. NowSi\\nvis a (1 + )-approximation to the minimum element cut\\nbetween Si\\nvandV\\\\(Si\\nvSi\\nv), so we split the problem into sub-graphs Gvgenerated by Si\\nvfor\\neachvRi\\nsmand one large part, which we call Glg. We specify the new parameters added in the\\nalgorithm.\\nAs mentioned earlier, to make sure the element cuts represen ted by the sub-trees are still exact,\\nor of good approximation in the original graph G, we add a new parameter: the forbidden set', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 11}), Document(page_content='F. The vertices in Fare terminals counted when computing the connectivity, but queries related\\nto them are not supported. Accordingly, the output Tis a (1 + )-approximate Gomory-Hu tree,\\nthat represents element connectivity in Gwith the terminal set UF, while the tree nodes only\\nrepresent vertices from U.12Foru,vU, the bottleneck edge weight between f(u) andf(v) onT\\nis\\nG,UF(u,v). In the top-level call Fis set to, but may accumulate up to O(|U|) vertices in the\\nrecursion.\\nAs will be proved in Lemma 5.3, the element connectivity between vertices inside Ulgare\\npreserved exactly in the contracted graph Glg. For the small graphs Gv, by Lemma 5.4, we accept', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 11}), Document(page_content='a (1 +)-factor approximation to element connectivity, which acc rues to (1 + )log|U|as a vertex\\ncan only appear in the small branch of the recursion log |U|times.\\nTo link the sub-trees at correct nodes and to compute f, we added a tool function g:V\\nVT{} that maps vertices of Ginto tree nodes of T, or a symbol.gindicates at which tree\\nnodes we should link two sub-trees. Taking Glgas example again, as the recursion goes down, and\\neachyvnally would appear in the base case for some tree node tv, we would set g(yv) =tv. From\\nthis construction, tvis the only terminal that no element cut disconnect yvandtv. Therefore, when\\nlinking the sub-tree of GlgwithGv, we should link at the tree node tv=g(yv), and the same holds', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 11}), Document(page_content='forGv. Moreover, we will make sure that at the end, g(v)=for every vU. From the denition\\nofg,g(v) withvUsatises the properties of the embedding function fin Denition 2.2.\\nTo summarize, to compute (1 + )-approximate Gomory-Hu tree, call Algorithm 1with desired\\nG,U,, andF=. It outputs ( T,g,C ). We set the embedding f(v) =g(v) for allvU, and then\\nreturn (T,f,C ), which satises Denition 2.2.\\n5.1.2 Correctness\\nWe prove the results needed to show the correctness of Algori thm1. Denote Flg=F{yv|vRi\\nsm}\\nandFv=F{xv}.\\nLemma 5.3. For any two vertices p,qUlg, we have \\nGlg,UlgFlg(p,q) =\\nG,UF(p,q).\\nProof. We rst show that \\nGlg,UlgFlg(p,q)\\nG,UF(p,q). Suppose Cis a minimum element cut', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 11}), Document(page_content='G,UF(p,q). Suppose Cis a minimum element cut\\ndisconnecting pandqinGlgwith terminal set UlgFlg. ThenCdoes not contain any yv, soCis\\nstill an element cut for pandqinG, and therefore \\nGlg,UlgFlg(p,q) =|C|\\nG,UF(p,q).\\nIt remains to show that \\nGlg,UlgFlg(p,q)\\nG,UF(p,q). Suppose Cis a minimum element\\ncut disconnecting pandqinGwith terminal set UF, and let A,B be the sides containing p,q,\\nrespectively. Every vRi\\nsmis by denition not in C; let the side of Ccontaining vbeDv.\\nWithout loss of generality we assume vandqare in dierent sides. For brevity, all the following\\nunspecied element cuts are with respect to GandUF. LetH=DvA, we have that His a\\n12I.e.,f:UV(T) does not embed FinT.\\n11', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 11}), Document(page_content='Algorithm 1: ApproxElemConnGHTree (G= (V,E),U,F, )\\ninput : The graph G= (V,E), the terminal set U, the forbidden set F, the\\napproximation accuracy \\noutput: A (1 +)-approximate element-connectivity Gomory-Hu tree ( T,g,C )\\n1if|U|= 1then // The Base Case\\n2 Construct Twith one node t,g(u)tfor alluV(G) andCan empty function\\n3return (T,g,C )\\n4end\\n5Letthe global minimum element connectivity // See Remark 5.7\\n6CallCutThresholdStep( G,U,F, (1 +))and store its output s,{Rj\\nsm,Rj,Sj\\nv}\\n7Fixi{0,1,,log|U|}that maximizesvRism(Si\\nvU).\\n8foreach vRi\\nsmdo\\n9 LetGvthe graph with V\\\\(Si\\nvSi\\nv) contracted into a vertex xv.\\n10 LetUvSi\\nvU.\\n11 Let (Tv,gv,Cv)ApproxElemConnGHTree( Gv,Uv,F{xv},).\\n12end\\n13LetGlgthe graph GwithSi', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 12}), Document(page_content='12end\\n13LetGlgthe graph GwithSi\\nvcontracted into a vertex yvfor each vRi\\nsm.\\n14LetUlgU\\\\vRism(Si\\nvU).\\n15Let (Tlg,glg,Clg)ApproxElemConnGHTree( Glg,Ulg,F{yv|vRi\\nsm},).\\n16Initialize TTlg(vRismTv), and then add edges ( gv(xv),glg(yv)) with weightSi\\nv.\\nLetginherit values from glgor one of the{gv}. If the value for vis dened in more than\\none such function, set g(v). LetCinherit the assignment of Clgand{Cv}, and for\\nthe new edges set C((gv(xv),glg(yv)))Si\\nv.\\n17return (T,g,C ).\\nAlgorithm 2: CutThresholdStep (G= (V,E),U,Fin,W)\\n1Setsa uniformly random vertex in U.\\n2R0U.\\n3forjfrom 0tolog|U|do\\n4 Call Lemma 2.3to compute sets{Sj\\nv:vRj}, withI=RjandF= (U\\\\Rj)Fin.\\n5 LetRj\\nsm{vRj\\\\{s}:Sj\\nvU|U|/2 andSj\\nvW}.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 12}), Document(page_content='vU|U|/2 andSj\\nvW}.\\n6Rj+1sampling each vertex of Rjwith probability1\\n2, butswith probability 1.\\n7end\\n8returnsand, for each j,{Rj\\nsm,Rj,{Sj\\nv}vRj\\nsm}.\\n12', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 12}), Document(page_content='minimum element cut between {v,p}and{q}, and(HSi\\nv) is an element cut between {v,p}and\\n{q}, so(HSi\\nv)|H|. Now that Si\\nvis also a minimum element cut between {v}andRi\\\\{v},\\nand(Si\\nvH) is also an element cut between {v}andRi\\\\{v}, we have(HSi\\nv)Si\\nv. By\\nthe submodularity of element-connectivity,\\n|H|+Si\\nv(HSi\\nv)+(HSi\\nv).\\nHence this inequality holds with equality, so(HSi\\nv)=Si\\nv. But by Lemma 2.3,Si\\nvis also\\nminimum in size among minimum isolating cuts, so HSi\\nv=Si\\nv, and therefore Si\\nvH.\\nIfDv=A, we already have Si\\nvDv. IfDv=A, then noticing that in GC,Dvis not\\nconnected to A, whileSi\\nvis connected to v, we know that Si\\nvA=andSi\\nvDv.\\nWe have shown that Si\\nvDv. When contracting Si', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 13}), Document(page_content='We have shown that Si\\nvDv. When contracting Si\\nvinto a vertex xv, the cut C=Dvis\\nnot aected, so Cis still an element cut between pandqinGlgwith terminal set UlgFlg, and\\n\\nGlg,UlgFlg(p,q)|C|=\\nG,UF(p,q).\\nLemma 5.4. For any two vertices p,qUv, we have 1\\nGv,UvFv(p,q)/\\nG,UF(p,q)1 +.\\nProof. We rst show that \\nGv,UvFv(p,q)\\nG,UF(p,q). Suppose Cis a minimum element cut\\ndisconnecting pandqinGvwith terminal set UvFv. ThenCdoes not contain xv, soCis still\\nan element cut disconnecting pandqinG, so\\nG,UF(p,q)|C|=\\nGv,UvFv(p,q).\\nNext, we show that \\nGv,UvFv(p,q)(1 +)\\nG,UF(p,q). Suppose Cis a minimum element\\ncut disconnecting pandqinGwith terminal set UFand letA,B be the sides of p,q. Without', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 13}), Document(page_content='loss of generality, suppose Adoes not contain s. The following unspecied element cuts are with\\nrespect to GandUF.\\nWe have that (Si\\nvA) is an element cut disconnecting pands. Therefore,(Si\\nvA).\\nFurthermore, by the denition of Si\\nv,Si\\nv(1 +). Therefore, by the submodularity of element\\ncuts,\\n(1 +)+|A|Si\\nv+|A|(Si\\nvA)+(Si\\nvA)+Si\\nvA.\\nNow that Si\\nvAcontains pbut not q,(Si\\nvA) is an element cut disconnecting pandq,\\nand since it is contained in Gv, it is still an element cut in Gvwith terminal set UvFv, so(Si\\nvA)\\nGv,UvFv(p,q). And by denition |A|=\\nG,UF(p,q).\\nTherefore,\\n\\nGv,UvFv(p,q)+|A|(1 +)\\nG,UF(p,q).', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 13}), Document(page_content='\\nGv,UvFv(p,q)+|A|(1 +)\\nG,UF(p,q).\\nLemma 5.5. The assignment g(v) =occurs if and only if vappears in C(e)for some edge.\\nTherefore, gvalue of vertices in UFnever equals.\\nProof. From the construction of GlgandGv, it can be seen that only the vertices in Si\\nv=\\nC((gv(xv),glg(yv))) are dened twice (or more), so their g-value are set to . These are all the\\nvertices such that g(v) =.\\nRemark 5.6.From Lemma 5.3, Lemma 5.4and Lemma 5.5, in line 17 of Algorithm 1, theg-value\\nofxv,yvare not, so linking the sub-trees would be successful. And g(v) forvUequals to.\\n13', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 13}), Document(page_content='Remark 5.7.As stated the algorithm computes the global element connect ivity. In reality is a\\nlower bound on this quantity, which is increased once we are s ure it has increased by a 1 + factor.\\nAs we show in the proof of Theorem 5.2, with high probability, the global element connectivity\\nincreases by a factor of 1 + everyO(log3n) steps taken in the  Glg branch of the recursion tree.\\nTherefore, what the algorithm actually does is initialize = 1, record the recursion depth on the\\nGlgbranch, and update (1 +)whenever this depth is a multiple of (log3n). In this way,\\nnever exceeds the global element connectivity w.h.p., whic h suces to establish correctness.\\n5.1.3 Running Time Analysis', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 14}), Document(page_content='5.1.3 Running Time Analysis\\nThe running time analysis in this section closely follows Li and Panigrahi [ LP21 ].\\nLemma 5.8. Keeping denitions of Ri,Ri\\nsm,Si\\nvas in line 4, 5, 6 of Algorithm 2. Keeping deni-\\ntions ofGlg,Ulg,Flgas in line 13, 14, 15 of Algorithm 1. Dene PU2to be\\nP={(u,v) :\\nG,UF(u,v)W,and ifAis the side of the minimum u-v\\nelement cut containing u, then|AU||U|/2}.\\nSimilarly dene PlgwithGlg,Ulg,FlgandW. Then\\nE(|Plg|)(\\n1(1\\nlog2|U|))\\n|P|.\\nProof. We need to lower bound the size of Q=P\\\\Plg. Dene Ui\\nsm=vRism(Si\\nvU),Usm=\\nlog|U|\\ni=1Ui\\nsm, andU={v|(v,s)P}. We will show that E(|Q|)(1\\nlog2n)|P|follows from the\\nfollowing three claims.\\n(1) For each uU, there are at least |U|/2 vertices vsuch that ( u,v)P.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 14}), Document(page_content='(2)E(|Usm|)(|U|/log|U|).\\n(3) For each ( u,v)P,uUwith probability at least 1 /2;\\nFor Claim (1), consider the minimum element cut disconnecti ngsanduU. There are at least\\n|U|/2 terminals vnot in the same side as u, and each ( u,v)P. Claim (2) is proved in Lemma 5.9.\\nClaim (3) holds because sis randomly chosen from Uand there are at least |U||U|/2 =|U|/2\\nterminals not in the side of u. Whensis such a terminal, uU.\\nThe algorithm xes i{1,2,,log|U|}that maximizesUi\\nsm. Then,\\nE(|Q|)|U|\\n2E(Ui\\nsm)|U|\\n2 log|U|E(|Usm|)|U|\\n2 log|U|(|U|\\nlog|U|)\\n(1\\nlog2|U|)\\n|P|.\\nFor the rst inequality, Claim (1) implies that each vU\\nsmis involved in|U|/2 pairs in P, all\\nof which do not appear in Plgwhenever vUi', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 14}), Document(page_content='of which do not appear in Plgwhenever vUi\\nsm. The second inequality follows from the choice of\\ni. The third inequality follows from Claim (2). The fourth ine quality follows from Claim (3) and\\nthe following bound on the size of P.\\n|P|/2E(|{(u,v)P:uU}|)|U||U|.\\nNote each uappears in at most |U|pairs ofP.\\n14', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 14}), Document(page_content='Lemma 5.9 (Claim (2) restated) .E(|Usm|) = (|U|/log|U|).\\nProof. Root the element connectivity Gomory-Hu tree Tats. For each vertex vU, letUvbe\\nthe set of terminals in the subtree rooted at v. For a terminal vU, we nd the edge e(v) along\\nthe path from stovwith minimum weight, and when not unique, the one with maximu m depth.\\nLetr(v) be the deeper endpoint of e(v). By the denition of U, a terminal vUif and only if\\nw(e(v))WandUr(v)|U|/2.\\nWe say that a vertex vUisactive ifvRi(v)wherei(v) =logUr(v). In addition,\\nifUr(v)Ri(v)={v}, then we say that vhits all of the vertices in Ur(v), including itself. For\\ncompleteness, we dene vertices in U\\\\Uto be inactive; they do not hit other vertices. Now we\\nshow that', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 15}), Document(page_content='show that\\n(a) each vertex that is hit is in Usm;\\n(b) the total number of pairs ( u,v) for which vUhitsuis (|U|) in expectation;\\n(c) each vertex uis hit by at most O(log|U|) vertices in vU.\\nFor (a), suppose uis hit by v. Then by denition, Ur(v)Ri(v)={v}. The isolating cut for v\\nreturned by Lemma 2.3corresponds to the edge joining r(v) to its parent, so all vertices in Ur(v)\\nare onvs side of the cut, and appear in Usm, because vRi\\nsm, sinceSi(v)\\nvU=Ur(v)|U|/2\\nandw(e(v))W.\\nFor (b), the probability that vRi(v)andvis the only such vertex is (1 2i(v))|Ur(v)|12i(v)=\\n(1/2i), and when it happens, it hitsUr(v)= (2i(v)) vertices, so the contribution in the expec-', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 15}), Document(page_content='tation is (1). Since each vUcontributes (1) in expectation, their sum is ( |U|).\\nFor (c), we rst show that for any dierent vertices v,wUthat both hit u,i(v)=i(w).\\nSinceuUr(v)anduUr(w), without loss of generality we assume r(v)Ur(w), soUr(v)Ur(w).\\nFrom the denition of Ri,R0R1Rlog|U|, soRi(v)Ri(w)=Rmax(i(v),i(w)). Then,\\n={v}{w}= (Ri(v)Ur(v))(Ri(w)Ur(w)) =Rmax(i(v),i(w))Ur(v),\\nbecause Ri(v)Ur(v)={v}=, we conclude that max( i(v),i(w))> i(v), soi(v)< i(w). Then,\\nsincei(v)[1,log|U|] has at most O(log|U|) kinds of choices, uis hit by at most O(log|U|)\\nvertices.\\nFinally, the proof follows from\\nE[Usm]E[|{u:uis hit}|]E[|{(u,v) :vU,uis hit by v}|]\\nO(log|U|)(E[U]\\nlog|U|).', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 15}), Document(page_content='O(log|U|)(E[U]\\nlog|U|).\\nThe rst inequality is because claim (a); the second inequal ity is because claim (c); and the\\nthird inequality is because claim (b).\\n5.2 Proof of Theorem 5.2and Theorem 5.1\\nNow we are ready to give the proof for Theorem 5.2and Theorem 5.1.\\n15', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 15}), Document(page_content='Proof of Theorem 5.2.The recursion makes progress in one of two ways. In the non- Glg branches\\n{Gv}, eachGvcontains at most half the number of terminals. Suppose we fol low the  Glg branch\\n(log3n) times, yielding G,U,FandP. By Lemma 5.8, withW= (1 +),E(|P|)(1\\n(1/log2n))(log3n)|P|=n(1), meaning P=is empty w.h.p. and the global minimum element\\ncut ofG,UFhas increased to at least (1 + )and we can update accordingly.\\nThis implies the total depth of recursion is O(1log4n) w.h.p. The total size of all graphs on\\neach layer of recursion is O(m), hence by Lemma 2.3, the total time is O(1log4nTow(m) logn) =\\nO(1Tow(m)).\\nAs for the correctness, by Lemma 5.3theGlg-branch preserves the exact value of \\nG,UF, and', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 16}), Document(page_content='G,UF, and\\nall the non- Glgbranches{Gv}introduce a (1+ )-factor approximation to the element connectivity.\\nSince the depth of recursion in the non- Glgbranches is at most log |U|, the tree returned is a\\n(1 +)log|U|= 1 +0approximate Gomory-Hu tree, for =0/log|U|. Expressed in terms of 0,\\nthe running time is still O(1\\n0Tow(m)).\\nProof of Theorem 5.1.The proof follows from the proof of Theorem 5.2by setting = (1\\nk), and\\nwe only address the dierence of k-Gomory-Hu tree.\\nTo prove correctness, a new base case is added13: if > k , stop recursion, construct Twith\\none node t, setg(u)tfor alluGandCan empty function and return ( T,g,C ). At the nal', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 16}), Document(page_content='output, construct fasf(v)g(v) for allvU. Then (T,f,C ) works exactly as in Denition 2.2.\\nTo bound running time, since we are not concerned with cut-va lues exceeding k, when calling\\nLemma 2.3we can use any unit capacity ow algorithm, which runs in O(Tuow(m+k|U|)) time,\\nso the total time bound is O(kTuow(m+k|U|)).\\n6 Conclusion\\nIn this paper we proved that ( kn/logn) space is necessary for encoding vertex connectivity\\ninformation up to k. This establishes the optimality of several previous resul ts. For example,\\nNagamochi-Ibaraki [ NI92 ] sparsiers encode all vertex connectivities up to k, but their space cannot\\nbe improved much, even if the format of the representation is not constrained t o be a graph . It', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 16}), Document(page_content='also implies that even the average length of the Izsak-Nutov [ IN12 ] labeling scheme cannot be\\nimproved much. We improved [ IN12 ] to have near-optimal query time O(logn), independent of k,\\nand improved its the construction time to nearly max-ow tim e.\\nHere we highlight a few open problems.\\nThere is a trivial ( kn) space lower bound for data structures answering v-cutqueries. Our\\ndata structure (and Izsak-Nutov [ IN12 ]) can be augmented to support fast v-cutqueries with\\nO(k2nlogn) space. Is this necessary? Note that if it is, the lower bound cannot be purely\\ninformation-theoretic; it must hinge on the requirement th at queries be answered eciently .14', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 16}), Document(page_content='A special case of the vertex connectivity oracle problem is a nswering v-conn(u,v) queries\\nwhenk=(G)+1. In other words, decide whether u,vare separated by a globally minimum\\ncut. Globally minimum vertex cuts have plenty of structure [ PY21 ,CDBKT93 ], but it is still\\nnot clear whether (kn) bits are necessary to answer such queries.\\n13It can be inserted between line 5 and 6 in Algorithm 1\\n14There are two natural ways to answer v-cutqueries optimally, either enumerate their elements in O(k) time,\\nor return a pointer in O(1) time to a pre-stored list of elements. The latter model wa s recently advocated by\\nNutov [Nut21] and seems to be easier to characterize from a lower bound per spective.\\n16', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 16}), Document(page_content='Can ak-Gomory-Hu tree for element connectivity be constructed in O(m+npoly(k)) time,\\nperhaps by extending the methods of [ FNY+20,PY21 ]?\\nReferences\\n[AGI+19] Amir Abboud, Loukas Georgiadis, Giuseppe F. Italiano, R obert Krauthgamer, Nikos\\nParotsidis, Ohad Trabelsi, Przemyslaw Uznanski, and Danie l Wolleb-Graf. Faster al-\\ngorithms for all-pairs bounded min-cuts. In Proceedings 46th International Colloquium\\non Automata, Languages, and Programming (ICALP) , pages 7:17:15, 2019. cited\\non page 1,2\\n[AKT20] Amir Abboud, Robert Krauthgamer, and Ohad Trabelsi . Cut-equivalent trees are\\noptimal for min-cut queries. In Proceedings of the 61st IEEE Annual Symposium on\\nFoundations of Computer Science (FOCS) , pages 105118, 2020. cited on page 1', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 17}), Document(page_content='[AKT21] Amir Abboud, Robert Krauthgamer, and Ohad Trabelsi . APMF <APSP? Gomory-\\nHu tree for unweighted graphs in almost-quadratic time. Accepted to FOCS21 , 2021.\\narXiv:2106.02981. cited on page 1\\n[Ben95a] A. A. Bencz ur. Counterexamples for directed and n ode capacitated cut-trees. SIAM\\nJ. Comput. , 24(3):505510, 1995. cited on page 1,2,3\\n[Ben95b] A. A. Bencz ur. A representation of cuts within 6/5 times the edge connectivity with\\napplications. In Proceedings 36th IEEE Symposium on Foundations of Computer Sc i-\\nence (FOCS) , pages 92102, 1995. cited on page 1\\n[BG08] A. A. Bencz ur and M. X. Goemans. Deformable polygon r epresentation and near-\\nmincuts. In M. Gr otschel and G. O. H. Katona, editors, Building Bridges: Between', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 17}), Document(page_content='Mathematics and Computer Science , volume 19 of Bolyai Society Mathematical Stud-\\nies, pages 103135. Springer, 2008. cited on page 1\\n[Bol11] B ela Bollob as. Random Graphs, Second Edition , volume 73 of Cambridge Studies in\\nAdvanced Mathematics . Cambridge University Press, 2011. cited on page 7\\n[BT96] G. Di Battista and R. Tamassia. On-line maintenance o f triconnected components\\nwith SPQR-trees. Algorithmica , 15:302318, 1996. cited on page 1,2\\n[CDBKT93] Robert F Cohen, Giuseppe Di Battista, Arkady Kane vsky, and Roberto Tamassia.\\nReinventing the wheel: an optimal data structure for connec tivity queries (extended\\nabstract). In Proceedings of the 25th Annual ACM Symposium on Theory of Comput -', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 17}), Document(page_content='ing (STOC) , pages 194200, 1993. cited on page 1,16\\n[CH91] Chung-Kuan Cheng and T. C. Hu. Ancestor tree for arbit rary multi-terminal cut\\nfunctions. Ann. Oper. Res. , 33(3):199213, 1991. cited on page 2\\n[Cha87] B. Chazelle. Computing on a free tree via complexity -preserving mappings. Algorith-\\nmica, 2(3):337361, 1987. cited on page 1,8\\n17', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 17}), Document(page_content='[Che15] Chandra Chekuri. Some open problems in element conn ectivity. Unpublished Survey.\\nAvailable at http://chekuri. cs. illinois. edu/papers/el em-connectivity-open-probs.\\npdf, 2015.cited on page 4\\n[CK12] Julia Chuzhoy and Sanjeev Khanna. An O(k3logn)-approximation algorithm for\\nvertex-connectivity survivable network design. Theory Comput. , 8(1):401413, 2012.\\ncited on page 4\\n[CLL13] Ho Yee Cheung, Lap Chi Lau, and Kai Man Leung. Graph co nnectivities, network\\ncoding, and expander graphs. SIAM J. Comput. , 42(3):733751, 2013. cited on\\npage 1\\n[CRX15] Chandra Chekuri, Thapanapong Rukkanchanunt, and C hao Xu. On element-\\nconnectivity preserving graph simplication. In Proceedings 29th Annual European', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 18}), Document(page_content='Symposium on Algorithms (ESA) , pages 313324, 2015. cited on page 4\\n[DKL76] E. A. Dinic, A. V. Karzanov, and M. V. Lomonosov. On th e structure of the system\\nof minimum edge cuts in a graph. Studies in Discrete Optimization , pages 290306,\\n1976. (in Russian). cited on page 1\\n[DLW09] Erik D. Demaine, Gad M. Landau, and Oren Weimann. On c artesian trees and range\\nminimum queries. In Proceedings of the 36th International Colloquium on Automata ,\\nLanguages and Programming (ICALP) , pages 341353, 2009. cited on page 1,8\\n[DN95] Y. Dinitz and Z. Nutov. A 2-level cactus model for the s ystem of minimum and\\nminimum+1 edge-cuts in a graph and its incremental maintena nce. In Proceedings', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 18}), Document(page_content='27th ACM Symposium on Theory of Computing (STOC) , pages 509518, 1995. \\ncited on page 1\\n[DN99a] Y. Dinitz and Z. Nutov. A 2-level cactus tree model fo r the system of minimum and\\nminimum+1 edge cuts of a graph and its incremental maintenan ce. Part I: the odd\\ncase. Unpublished manuscript, 1999. cited on page 1\\n[DN99b] Y. Dinitz and Z. Nutov. A 2-level cactus tree model fo r the system of minimum and\\nminimum+1 edge cuts of a graph and its incremental maintenan ce. Part II: the even\\ncase. Unpublished manuscript, 1999. cited on page 1\\n[DV94] Yem Dinitz and Alek Vainshtein. The connectivity ca rcass of a vertex subset in\\na graph and its incremental maintenance. In Proceedings of the 26th Annual ACM', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 18}), Document(page_content='Symposium on Theory of Computing (STOC) , pages 716725, 1994. cited on page\\n1\\n[DV95] Yem Dinitz and Alek Vainshtein. Locally orientable graphs, cell structures, and a new\\nalgorithm for the incremental maintenance of connectivity carcasses. In Proceedings\\nof the 6th Annual ACM-SIAM Symposium on Discrete Algorithms (S ODA) , pages\\n302311, 1995.cited on page 1\\n[DV00] Yem Dinitz and Alek Vainshtein. The general structu re of edge-connectivity of a\\nvertex subset in a graph and its incremental maintenance. od d case.SIAM J. Comput. ,\\n30(3):753808, 2000. cited on page 1\\n18', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 18}), Document(page_content='[FGI+16] Donatella Firmani, Loukas Georgiadis, Giuseppe F. Ital iano, Luigi Laura, and Fed-\\nerico Santaroni. Strong articulation points and strong bri dges in large scale graphs.\\nAlgorithmica , 74(3):11231147, 2016. cited on page 1\\n[FK16] Alan Frieze and Micha/suppress l Karo nski. Introduction to Random Graphs . Cambridge Uni-\\nversity Press, 2016. cited on page 7\\n[FNY+20] Sebastian Forster, Danupon Nanongkai, Liu Yang, Thatch aphol Saranurak, and Sor-\\nrachai Yingchareonthawornchai. Computing and testing sma ll connectivity in near-\\nlinear time and queries via fast local cut algorithms. In Proceedings of the 31st ACM-\\nSIAM Symposium on Discrete Algorithms (SODA) , pages 20462065, 2020. cited\\non page 1,17', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 19}), Document(page_content='on page 1,17\\n[GH61] R. E. Gomory and T. C. Hu. Multi-terminal network ows .Journal of the Society for\\nIndustrial and Applied Mathematics , 9, 1961.cited on page 1\\n[GILP16] Loukas Georgiadis, Giuseppe F. Italiano, Luigi La ura, and Nikos Parotsidis. 2-edge\\nconnectivity in directed graphs. ACM Trans. Algorithms , 13(1):9:19:24, 2016. \\ncited on page 1\\n[GILP18] Loukas Georgiadis, Giuseppe F. Italiano, Luigi La ura, and Nikos Parotsidis. 2-vertex\\nconnectivity in directed graphs. Inf. Comput. , 261:248264, 2018. cited on page 1\\n[GMW20] Pawel Gawrychowski, Shay Mozes, and Oren Weimann. M inimum cut in O(mlog2n)\\ntime. In Proceedings 47th International Colloquium on Automata, Lang uages, and', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 19}), Document(page_content='Programming (ICALP) , volume 168 of LIPIcs , pages 57:157:15. Schloss Dagstuhl -\\nLeibniz-Zentrum f ur Informatik, 2020. cited on page 1\\n[GMW21] Pawel Gawrychowski, Shay Mozes, and Oren Weimann. A note on a recent algorithm\\nfor minimum cut. In Proceedings 4th SIAM Symposium on Simplicity in Algorithms\\n(SOSA) , pages 7479, 2021. cited on page 1\\n[GN90] D. Guseld and D. Naor. Ecient algorithms for genera lized cut trees. In Proceedings\\nFirst ACM-SIAM Symposium on Discrete Algorithms , pages 422433, 1990. cited\\non page 1\\n[GN93] Dan Guseld and Dalit Naor. Extracting maximal infor mation about sets of minimum\\ncuts.Algorithmica , 10(1):6489, 1993. cited on page 1', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 19}), Document(page_content='[HKNS15] M. Henzinger, S. Krinninger, D. Nanongkai, and T. S aranurak. Unifying and strength-\\nening hardness for dynamic problems via the online matrix-v ector multiplication\\nconjecture. In Proceedings 47th Annual ACM Symposium on Theory of Computing\\n(STOC) , pages 2130, 2015. cited on page , 3\\n[HKP07] Ramesh Hariharan, Telikepalli Kavitha, and Debmal ya Panigrahi. Ecient algorithms\\nfor computing all low s-tedge connectivities and related problems. In Proceedings of\\nthe Eighteenth Annual ACM-SIAMSymposium on Discrete Algorit hms (SODA) , pages\\n127136, 2007.cited on page 1\\n19', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 19}), Document(page_content='[HL07] Refael Hassin and Asaf Levin. Flow trees for vertex-c apacitated networks. Discrete\\napplied mathematics , 155(4):572578, 2007. cited on page 2,3\\n[HL09] Tai-Hsin Hsu and Hsueh-I Lu. An optimal labeling for n ode connectivity. In Proceed-\\nings of the 20th International Symposium on Algorithms and Com putation (ISAAC) ,\\npages 303310. Springer, 2009. cited on page 2,3\\n[IN12] Rani Izsak and Zeev Nutov. A note on labeling schemes f or graph connectivity. Inf.\\nProcess. Lett. , 112(12):3943, 2012. cited on page , 2,3,8,9,16\\n[JMVW02] Kamal Jain, Ion I. Mandoiu, Vijay V. Vazirani, and D avid P. Williamson. A primal-\\ndual schema based approximation algorithm for the element c onnectivity problem. J.', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 20}), Document(page_content='Algorithms , 45(1):115, 2002. cited on page 4\\n[Kar00] D. R. Karger. Minimum cuts in near-linear time. J. ACM , 47(1):4676, 2000. cited\\non page 1\\n[KKKP04] Michal Katz, Nir A Katz, Amos Korman, and David Pele g. Labeling schemes for ow\\nand connectivity. SIAM J. Comput. , 34(1):2340, 2004. cited on page 2,3\\n[KLS20] Tarun Kathuria, Yang P. Liu, and Aaron Sidford. Unit capacity maxow in almost\\nO(m4/3) time. In Proceedings 61st Annual IEEE Symposium on Foundations of Com-\\nputer Science (FOCS) , pages 119130, 2020. cited on page , 9\\n[Kor10] A. Korman. Labeling schemes for vertex connectivit y.ACM Trans. on Algorithms ,\\n6(2), 2010.cited on page 2,3', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 20}), Document(page_content='6(2), 2010.cited on page 2,3\\n[KP09] David R. Karger and Debmalya Panigrahi. A near-linea r time algorithm for construct-\\ning a cactus representation of minimum cuts. In Proceedings of the Twentieth Annual\\nACM-SIAM Symposium on Discrete Algorithms (SODA) , pages 246255, 2009. \\ncited on page 1\\n[KPP16] T. Kopelowitz, S. Pettie, and E. Porat. Higher lower bounds from the 3SUM con-\\njecture. In Proceedings 27th Annual ACM-SIAM Symposium on Discrete Algor ithms\\n(SODA) , pages 12721287, 2016. cited on page , 3\\n[KTBC91] A. Kanevsky, R. Tamassia, G. Di Battista, and J. Che n. On-line maintenance of\\nthe four-connected components of a graph. In Proceedings 32nd IEEE Symposium on', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 20}), Document(page_content='Foundations of Computer Science (FOCS) , pages 793801, 1991. cited on page 1,\\n2\\n[LNP+21] Jason Li, Danupon Nanongkai, Debmalya Panigrahi, Thatc haphol Saranurak, and Sor-\\nrachai Yingchareonthawornchai. Vertex connectivity in po ly-logarithmic max-ows.\\nInProceedings of the 53rd ACM Symposium on Theory of Computing (STO C), 2021.\\ncited on page 1,3,5\\n[LP20] Jason Li and Debmalya Panigrahi. Deterministic min- cut in poly-logarithmic max-\\nows. In Proceedings 61st IEEE Annual Symposium on Foundations of Comp uter\\nScience, (FOCS) , pages 8592, 2020. cited on page 1,3,4\\n20', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 20}), Document(page_content='[LP21] Jason Li and Debmalya Panigrahi. Approximate Gomory Hu tree is faster than n1\\nmax-ows. In Proceedings of the 53rd Annual ACM Symposium on Theory of Com-\\nputing (STOC) , pages 1738-1748, 2021. cited on page 10,14\\n[LPS21] Jason Li, Debmalya Panigrahi, and Thatchaphol Sara nurak. A nearly optimal all-pairs\\nmin-cuts algorithm in simple graphs. Accepted to FOCS21 , 2021. arXiv:2106.02233.\\ncited on page 1\\n[Men27] Karl Menger. Zur allgemeinen kurventheorie. Fundamenta Mathematicae , 10:96115,\\n1927.cited on page 4\\n[MN20] Sagnik Mukhopadhyay and Danupon Nanongkai. Weighte d min-cut: sequential, cut-\\nquery, and streaming algorithms. In Proccedings of the 52nd Annual ACM Symposium', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 21}), Document(page_content='on Theory of Computing (STOC) , pages 496509, 2020. cited on page 1\\n[NI92] H. Nagamochi and T. Ibaraki. A linear-time algorithm for nding a sparse k-connected\\nspanning subgraph of a k-connected graph. Algorithmica , 7(5&6):583596, 1992. \\ncited on page 9,16\\n[Nut21] Zeev Nutov. Data structure for node connectivity qu eries. arXiv preprint\\narXiv:2110.09102 , 2021.cited on page 2,16\\n[Pet06] Seth Pettie. An inverse-Ackermann type lower bound for online minimum spanning\\ntree verication. Combinatorica , 26(2):207230, 2006. cited on page 1,8\\n[PQ80] J.-C. Picard and M. Queyranne. On the structure of all minimum cuts in a net-\\nwork and applications. In Combinatorial Optimization II , volume 13 of Mathematical', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 21}), Document(page_content='Programming Studies , pages 816. Springer, 1980. cited on page 1\\n[PY21] Seth Pettie and Longhui Yin. The structure of minimum vertex cuts. In Proceedings\\n48th International Colloquium on Automata, Languages, and Pr ogramming (ICALP) ,\\nvolume 198 of LIPIcs , pages 105:1105:20. Schloss Dagstuhl - Leibniz-Zentrum f  ur\\nInformatik, 2021. cited on page 1,2,16,17\\n[Sar21] Thatchaphol Saranurak. A simple deterministic alg orithm for edge connectivity. In\\nProceedings 4th SIAM Symposium on Simplicity in Algorithms, (SOSA) , pages 8085,\\n2021.cited on page 1\\n[Sch79] C.-P. Schnorr. Bottlenecks and edge connectivity i n unsymmetrical networks. SIAM\\nJ. Comput. , 8(2):265274, 1979. cited on page 1', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 21}), Document(page_content='J. Comput. , 8(2):265274, 1979. cited on page 1\\n[Sch03] A. Schrijver. Combinatorial Optimization - Polyhedra and Eciency . Springer, 2003.\\ncited on page 4\\n[vdBLL+21] Jan van den Brand, Yin Tat Lee, Yang P. Liu, Thatchaphol Sa ranurak, Aaron Sidford,\\nZhao Song, and Di Wang. Minimum cost ows, mdps, and 1-regression in nearly linear\\ntime for dense instances, 2021. cited on page 1\\n21', metadata={'source': '/share/lab4/ych/papers/paper3.pdf', 'page': 21})]\n",
      "[Document(page_content='Linear Algebra and its Applications 431 (2009) 833842\\nContents lists available at ScienceDirect\\nLinear Algebra and its Applications\\njournal homepage: www.elsevier.com/locate/laa\\nMaps preserving product XYYXon factor von Neumann\\nalgebras/H32891\\nJianlian Cuia,, Chi-Kwong Lib\\naDepartment of Mathematical Sciences, Tsinghua University, Beijing 100084, PR China\\nbDepartment of Mathematics, The College of William & Mary, Williamsburg, VA 13185, USA\\nARTICLE INFO ABSTRACT\\nArticle history:\\nReceived 26 February 2009\\nAccepted 23 March 2009\\nAvailable online 29 April 2009\\nSubmitted by P. emrl\\nAMS classication:Primary: 47B48, 46L10\\nKeywords:\\nNew productsIsomorphismvon Neumann algebrasLetAandBbe two factor von Neumann algebras. For A,BA,', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 0}), Document(page_content='dene by [A,B]=ABBAthe new product of Aand B. In this\\npaper, we prove that a nonlinear bijective map :ABsatises\\n([A,B])=[(A),(B)]for all A,BAif and only if is a-\\nring isomorphism. In particular, if the von Neumann algebras Aand\\nBare type I factors, then is a unitary isomorphism or a conjugate\\nunitary isomorphism.\\n 2009 Elsevier Inc. All rights reserved.\\n1. Introduction\\nAs a kind of new products in a -ring, the operation XYYXwas discussed in [6]. This product\\nXYYXis found playing a more and more important role in some research topics, and its study\\nhas recently attracted many authors attention. This product was extensively studied because, by', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 0}), Document(page_content='the fundamental theorem of emrl in [6], maps of the form TTAATnaturally arise in the\\nproblem of representing quadratic functionals with sesquilinear functionals (see, for example, [ 7,8]).\\nemrl in [9] proved every Jordan -derivation J:B(H)B(H)(satisfying J(T2)=TJ(T)+J(T)T)\\n/H32891The rst author was supported by National Natural Science Foundation of China (Nos. 1087 1111, 10501 029), the NSFC-KOSEF\\nScientic Cooperation Program (No. 10611140471) and the Specialized Research Fund for Doctoral Program of Higher Education\\n(No. 200800030059). The second author was partially supported by USA NSF and HK RCG.\\nCorresponding author.\\nE-mail addresses: jcui@math.tsinghua.edu.cn (J. Cui), ckli@math.wm.edu (C.-K. Li).', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 0}), Document(page_content='0024-3795/$ - see front matter  2009 Elsevier Inc. All rights reserved.doi:10.1016/j.laa.2009.03.036', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 0}), Document(page_content='834 J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842\\nis of the form J(T)=TAAT, where B(H)denotes the algebra of all bounded linear operators on\\na Hilbert space H. Motivated by the work of emrl and the theory of rings (and algebras) equipped\\nwith a Lie product [T,S]= TSSTor a Jordan product TS=TS+ST, Molnr recently in [5] ini-\\ntiated the systematic study of this new product, and studied the relation between subspaces and\\nideals of B(H). Where he showed that if a subspace NofB(H)satises ABBANforAB(H)\\nand BN, then Nis an ideal; and also, if the dimension of His an odd natural number, then\\nN=B(H). In addition, he proved that if His of dimension greater than 1 and NB(H)is an ideal,', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 1}), Document(page_content='then span {ABBA|AN,BB(H)}= span{BAAB|AN,BB(H)}= N.I n[ 2], Brear and\\nFoner generalized Molnrs results to rings with involution in different ways, and studied the rela-tionship between (ordinary) ideals of a ring Rand left and right ideals of Rwith respect to the product\\nAB\\nBA. Their approach is entirely algebraic and is completely different from one used by Molnr,\\nand it is based on discovering certain identities that connect the product ABBAwith the initial,\\nassociative product.\\nLetAand Bbe two -rings. For A,BA, denote by [A,B]=ABBAthe new product of AandB.\\nA map :ABis called new products preserving if ([A,B])=[(A),(B)]for all A,BA.I n', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 1}), Document(page_content='[1], the authors studied the bijective map preserving this new product on B(H), where His a complex\\nHilbert space of dimension greater than 2. They showed that such maps are in fact -automorphisms\\nor conjugate -automorphisms. This result shows that, in some sense, the new product ABBA\\nstructure is determine enough the -algebraic structure of B(H). In this paper, we will discuss such\\na problem on more general factor von Neumann algebras. We prove that such a bijective map onfactor von Neumann algebras must be a\\n-additive isomorphism (see Main Theorem). In particular,\\nif the factor is of type I, then -isomorphism is spatial, which generalized the main result in [ 1]t o', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 1}), Document(page_content='any complex Hilbert space case (see Corollary 1). We mention here the method used in [ 1]i sn o t\\ncompletely t for general von Neumann algebras since the notion of nite-rank is meaningless ingeneral von Neumann algebras.\\nAs usual,\\nRand Cdenote respectively the real eld and complex eld. Recall that a factor is a von\\nNeumann algebra whose center only contains the scalar operators. An algebra Ris called prime if\\nARB={0}implies that A=0o rB =0. It is well known that every factor von Neumann algebra is a\\nprime algebra.\\nOur main result is as follows:\\nMain Theorem. LetAand Bbe two factor von Neumann algebras. Assume that :ABis a bijective\\nmap. Thensatises (ABBA)=(A)(B)(B)(A)for all A, BAif and only if is a\\n-ring isomorphism.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 1}), Document(page_content='-ring isomorphism.\\n2. The proof of Main Theorem\\nIn this section, we will complete the proof of the main theorem by proving several claims. The\\nfollowing results will be used many times in the proof of theorem.\\nLemma 1. LetAbe a factor von Neumann algebra, and AA.Then AB =BAfor every B Aimplies\\nthat ARI.\\nProof. In fact, take B=I, then A=A, and therefore, AB=BAfor every BA, hence Abelongs to\\nthe center of A. Note that Ais a factor, it follows that ARI.\\nLemma 2. LetAbe a factor von Neumann algebra, and BA.Then AB =BAfor every A Aimplies\\nthat B=0.\\nProof. It follows that AB=BAfor every Hermitian element A, and hence AB=BAfor every AA\\nsince A=A+A\\n2+iAA\\n2i, whereA+A\\n2andAA\\n2iare Hermitian. So there exists a scalar Csuch', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 1}), Document(page_content='2iare Hermitian. So there exists a scalar Csuch\\nthat B=I. Taking AAsuch that A/=A, one has (AA)=0, and consequently, =0 and\\nB=0.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 1}), Document(page_content='J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842 835\\nProof of Main Theorem\\nClaim 1. (0)=0.\\nFor any AA,w eh a v e (A)(0)(0)(A)=(0). It follows from the surjectivity of that\\nthere exists AAsuch that (A)=iI(where, iis the imaginary number unit), so 2i (0)=(0),\\nand hence (0)=0.\\nClaim 2. (RI)=RI,(CI)=CI andpreserves Hermitian elements in both directions .\\nClaim 1 and the injectivity of imply that\\nAB=BA(A)(B)=(B)(A)for all A,BA. (2.1)\\nLetRbe arbitrary. Then the equality IA=A(I)(AA) implies that (I)(A)=\\n(A)(I). Now the surjectivity of ensures that\\n(I)S=S(I)for all SB.\\nLemma 1 implies that (I)RI. A similar discussion implies that (A)RIARI.S o(RI)=\\nRI.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 2}), Document(page_content='RI.\\nFor any Hermitian element AA(that is, A=A), Eq. (2.1) implies that (A)(I)=(I)(A),\\nand hence it follows from (I)RIand(I)/=0 that (A)=(A). Conversely, assume that (A)\\nis Hermitian. Then, it follows from (RI)=RIand Eq. (2.1) again that Ais Hermitian. So preserves\\nHermitian elements in both directions.\\nLetCbe arbitrary. Then, for every Hermitian element AA, the equality AI=(I)A\\nimplies that (A)(I)=(I)(A). Since preserves Hermitian elements in both directions,\\nit follows from the surjectivity of that S(I)=(I)Sfor every Hermitian element SB, and\\ntherefore, T(I)=(I)Tfor all TBsince T=S1+iS2with S1and S2being Hermitian, so\\n(I)CI. A similar discussion implies that (A)CIACI.S o(CI)=CI.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 2}), Document(page_content='Claim 3. (iA)=i(A)(AA)or(iA)= i(A)(AA)andpreserves projections in both\\ndirections .\\nApplying Claim 2, we have (\\n1\\n2iI)\\n(C\\\\R)Iand(\\n1\\n2I)\\nRI. It follows from1\\n2iI=[\\n1\\n2iI,1\\n2I]\\nthat\\n(1\\n2iI)\\n=2(\\n1\\n2I)\\n(\\n1\\n2iI)\\n, (2.2)\\nAlso the equality 1\\n2I=[\\n1\\n2iI,1\\n2iI]\\nimplies that\\n(\\n1\\n2I)\\n=2(1\\n2iI)2\\n(2.3)\\nand1\\n2I=[\\n1\\n2iI,1\\n2iI]\\nensures that\\n(\\n1\\n2I)\\n=2(\\n1\\n2iI)2\\n. (2.4)\\nNow Eqs. (2.2)(2.4) ensure that (\\n1\\n2I)\\n=1\\n2I, and\\n(1\\n2iI)\\n=1\\n2iI. (2.5)', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 2}), Document(page_content='836 J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842\\nSo, for every AA,w eh a v e\\n(iA)=([1\\n2iI,A]\\n)\\n=[\\n(1\\n2iI)\\n,(A)]\\n=(\\n(1\\n2iI)\\n(1\\n2iI))\\n(A),\\nwhich, together with Eq. (2.5), implies that\\n(iA)=i(A)(AA)or(iA)= i(A)(AA).\\nFor every projection PA, since 2iP =iPII(iP),w eh a v e (2iP)= 2i(P), and hence,\\n2i(P)=(2iP)=([iP,P])=[(iP),(P)]= 2i(P)2,\\nso(P)2=(P). That is, (P)is a projection. Conversely, assume that (P)is a projection. Since\\n1has the same property as has, a similar discussion implies that Pis a projection. Hence \\npreserves projections in both directions.\\nClaim 4. LetP(A)and P(B)denote respectively the set of all projections in Aand B,then:P(A)', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 3}), Document(page_content='P(B)preserves the order and orthogonality in both directions .\\nLetP,RP(A)be arbitrary and PR=RP=0. That is, Pand Rare orthogonal projections. Then it\\nfollows from Claims 1 and 3 that\\n0=([iP,R])=[(iP),(R)]= i((P)(R)+(R)(P)),\\nand consequently, (P)(R)+(R)(P)=0. Note that (P)and(R)are projections, so (P)(R)\\n=(R)(P)=0. Conversely, if (P)and(R)are orthogonal projections in B, then a similar dis-\\ncussion implies that Pand Rare orthogonal projections. Hence :P(A)P(B)preserves the\\northogonality in both directions.\\nFor any P,RP(A)with PR, that is, PR=RP=P. By Claim 3,\\n2i(P)=(2iP)=([iP,R])=[(iP),(R)]= i((P)(R)+(R)(P)),\\nand therefore, 2 (P)=(P)(R)+(R)(P).S o(P)=(P)(R)=(R)(P). That is,', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 3}), Document(page_content='(P)(R).L e tP ,RP(A)such that (P)(R), a similar discussion is applied to 1,w e\\nget that PR, and hence, :P(A)P(B)preserves the order in both directions.\\nClaim 5. Let AAbe an Hermitian element and R.Then\\n(A)+(IA)RI.\\nLetAAbe an Hermitian element and R. For every Hermitian element XA, since[A,X]=\\n[X,IA], one has\\n[(A),(X)]=[(X),(IA)],\\nwhich, together with Claim 2, implies that, for every Hermitian element XA,\\n((A)+(IA))(X)=(X)((A)+(IA)).\\nIt follows from Claim 2 again that (A)+(IA)commutes with every Hermitian element in B,\\nand hence, commutes with every element in B,s o(A)+(IA)CI. Note that (A)+(I\\nA)is Hermitian, it follows that (A)+(IA)RI.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 3}), Document(page_content='A)is Hermitian, it follows that (A)+(IA)RI.\\nChoose an arbitrary nontrivial projection P1inAand let P2=IP1. Then, Claims 2 and 3 ensure\\nthat there exist nontrivial projections Qi(i=1, 2)such that (Pi)=Qi. By Claim 5, Q1+Q2=I.L e t\\ni,j=1, 2, write Aij=PiAPjand Bij=QiBQj, then\\nA=2\\ni,j=1Aijand B=2\\ni,j=1Bij.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 3}), Document(page_content='J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842 837\\nClaim 6. (Aij)=Bij(i/=j).\\nLeti/=jand XAijbe arbitrary. Since X=[Pi,X],w eh a v e\\n(X)=[(Pi),(X)]=Qi(X)(X)Qi.\\nIt follows that (X)Qi=0 and(X)=Qi(X), and hence Qj(X)=0. So\\n(X)=2\\ni,j=1Qi(X)Qj=Qi(X)QjBij.\\nThat is, (Aij)Bij. Since 1has the same property as has, we have Bij(Aij)Therefore,\\n(Aij)=Bij.\\nClaim 7. (Aii)=Bii(i=1, 2).\\nLetj/=i.S e tQ Bjjbe an arbitrary projection. Then Qi+QBis a projection and Qi+QQi.\\nBy Claims 3 and 4, there exists a projection PQAwith PQPisuch that (PQ)=Qi+Q. Since,\\nfor every AAii,w eh a v e [PQ,A]=0, it follows that [Qi+Q,(A)]=0, which, together with\\n[Qi,(A)]=0, implies that', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 4}), Document(page_content='[Qi,(A)]=0, implies that\\n(A)Q=Q(A)for every projection QBjj. (2.6)\\nTaking Q=Qjin Eq. (2.6) and multiplying Qirespectively from the left side and the right side of Eq.\\n(2.6), one obtains that\\nQi(A)Qj=0 and Qj(A)Qi=0. (2.7)\\nNote that Bjjis a factor von Neumann algebra, and a von Neumann algebra is generalized by its\\nprojections if and only if it has no innite dimensional abelian summand (see, for example, [ 4]). It\\nfollows from Eq. ( 2.6) that Qj(A)QjCQj, which, together with Eq. (2.7), implies that, for every\\nAAii,(A)Bii+CQj.\\nFor every AiAii, dene a function fi:Aii Cas follows:\\nfi(Ai)Qj=Qj(Ai)Qj, where j/=i.\\nThen(Ai)=Qi(Ai)Qi+fi(Ai)Qj. Take a nonzero element XAij(i/=j). Then it follows from', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 4}), Document(page_content='[X,Ai]=0 that[(X),(Ai)]=0, that is,\\n(X)(Qi(Ai)Qi+fi(Ai)Qj)=(Qi(Ai)Qi+fi(Ai)Qj)(X).\\nBy Claim 6, (X)Bij. Multiplying Qjfrom the right side of the above expression, one has fi(Ai)(X)=\\n0. Note that (X)/=0, we have fi(Ai)=0 for every AiAii.S of i()0, and therefore, (Aii)Bii.\\nThe same discussion is applied to 1, the inverse inclusion relation can be similarly proved. Hence\\n(Aii)=Bii.\\nClaim 8. For i ,j=1, 2, let A ijAij,then\\n(Aii+Aij)=(Aii)+(Aij),i/=j,\\n(Aii+Aji)=(Aii)+(Aji),i/=j,\\n(Aii+Ajj)=(Aii)+(Ajj),i/=j,\\n(Aij+Aji)=(Aij)+(Aji),i/=j.\\nLet(T)=(Aii)+(Aij). Then, for every XjjAjj, it follows from Claims 6 and 7 that\\n([Xjj,T])=[(Xjj),(T)]\\n=[(Xjj),(Aii)+(Aij)]\\n=[(Xjj),(Aij)]=([Xjj,Aij]).', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 4}), Document(page_content='838 J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842\\nThis, together with the injectivity of , implies that\\nXjj(TAij)=(TAij)X\\njjfor every XjjAjj. (2.8)\\nMultiplying Pifrom the right side of Eq. (2.8), one has Xjj(TAij)Pi=0 for every XjjAjj. That is,\\nPjXPj(TAij)Pi=0 for every XA. Note that Ais prime, so PjTPi=0.Multiplying Pifrom the left\\nside of Eq. (2.8), similarly, one gets that PiTPj=Aij. It follows from Eq. (2.8) again and Lemma 2 that\\nPjTPj=0.\\nOn the other hand, for every XiiAii, by Claims 6 and 7, one has\\n([T,Xii])=[(T),(Xii)]\\n=[(Aii)+(Aij),(Xii)]\\n=[(Aii),(Xii)]=([Aii,Xii]).\\nSo(TAii)Xii=Xii(TAii)for every XiiAii, and hence, there exists a real number Tsuch that', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 5}), Document(page_content='PiTPi=Aii+TPi. Therefore T=2\\ni,j=1PiTPj=Aii+Aij+TPiand\\n(Aii+Aij+TPi)=(Aii)+(Aij).\\nFor every XijAij(i/=j), it follows from the above expression that there exists a real number such\\nthat\\n(AiiXijXijA\\nij+TXij)=([Aii+Aij+TPi,Xij])\\n=[(Aii+Aij+TPi),(Xij)]\\n=[(Aii)+(Aij),(Xij)]\\n=([Aii,Xij])+([Aij,Xij])\\n=(AiiXij)+(XijA\\nij)\\n=(AiiXijXijA\\nij+Pi).\\nThusTXij=Pi, and hence T=0. So\\n(Aii+Aij)=(Aii)+(Aij). (2.9)\\nFor every TjjAjj, it follows from [Tjj,Aii+Aji]=[Tjj,Aji]that\\n[(Tjj),(Aii+Aji)(Aji)]=0.\\nBy Claim 7, we have, for every SjjBjj,\\nSjj((Aii+Aji)(Aji))=((Aii+Aji)(Aji))S\\njj.\\nA similar discussion just as Eq. (2.8) implies that\\nQj(Aii+Aji)Qi=(Aji),Qi(Aii+Aji)Qj=0 and Qj(Aii+Aji)Qj=0.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 5}), Document(page_content='By Claim 7, there exists BiiAiisuch that\\nQi(Aii+Aji)Qi=(Bii).\\nSo\\n(Aii+Aji)=(Bii)+(Aji).\\nFor every TjiAji(j/=i), the above expression and Eq. (2.9) imply that\\n(TjiA\\nii)+(TjiA\\nji)=(TjiA\\niiTjiA\\nji)=([Aii+Aji,Tji])\\n=[(Aii+Aji),(Tji)]\\n=[(Bii)+(Aji),(Tji)]\\n=(TjiB\\nii)+(TjiA\\nji).', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 5}), Document(page_content='J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842 839\\nSoTji(A\\niiB\\nii)=0 for every TjiAji, and hence, Bii=Aii. Hence\\n(Aii+Aji)=(Aii)+(Aji).\\nLet(T)=(A11)+(A22). For every T11A11,w eh a v e\\n([T11,T])=[(T11),(T)]=[(T11),(A11)+(A22)]=([T11,A11]).\\nThis implies that T11(TA11)=(TA11)T\\n11for every T11A11, and therefore P1TP2=0,P2TP1=0\\nand P1TP1=A11. Similarly, one can prove that P2TP2=A22.S o\\n(A11+A22)=(A11)+(A22). (2.10)\\nFor every TiiAii,w eh a v ea l w a y s [Aij+Aji,Tii]=[Aji,Tii](i/=j). It follows that, for every Sii\\nBii,\\n((Aij+Aji)(Aji))Sii=Sii((Aij+Aji)(Aji)),\\nsoQj(Aij+Aji)Qi=(Aji)and there exists Rsuch that Qi(Aij+Aji)Qi=Qi. Similarly, it', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 6}), Document(page_content='follows from [Aij+Aji,Tjj]=[Aij,Tjj](TjjAjj) that Qi(Aij+Aji)Qj=(Aij)and Qj(Aij+\\nAji)Qj=Qjfor some R. Thus\\n(Aij+Aji)=(Aij)+(Aji)+Qi+Qj. (2.11)\\nTake a nonzero element TijAij(i/=j), it follows from Eqs. ( 2.10) and (2.11) that\\n(AjiTij)+(TijA\\nij)=(AjiTijTijA\\nij)\\n=([Aij+Aji,Tij])\\n=[(Aij+Aji),(Tij)]\\n=[(Aij)+(Aji)+Qi+Qj,(Tij)]\\n=(AjiTij)+(TijA\\nij)+()(Tij),\\nand hence ()(Tij)=0, so=.\\nFor all TiiAii, it follows from Eq. (2.11) again that there exist Rsuch that\\n(TiiAij)+(AjiT\\nii)+Qi+Qj\\n=(TiiAijAjiT\\nii)\\n=([Tii,Aij+Aji])\\n=[(Tii),(Aij)+(Aji)+Qi+Qj]\\n=(TiiAij)+(AjiT\\nii)+((Tii)(Tii)).\\nIt follows that\\nQi+Qj=((Tii)(Tii))for all TiiAii.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 6}), Document(page_content='Qi+Qj=((Tii)(Tii))for all TiiAii.\\nMultiply Qjin the above expression, then Qj=0, and hence =0 and\\n0=((Tii)(Tii))for all TiiAii,\\nwhich implies that =0. Therefore\\n(Aij+Aji)=(Aij)+(Aji).\\nClaim 9. Let A ijAij(i,j=1, 2).Then(2\\ni=1Aij)\\n=2i=1(Aij).\\nFor every TiiAii, since [Aii+Aij+Aji,Tii]=[Aii+Aji,Tii](i/=j), it follows from Claim 7 that,\\nfor every SiiBii,\\n((Aii+Aij+Aji)(Aii+Aji))Sii=Sii((Aii+Aij+Aji)(Aii+Aji)).', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 6}), Document(page_content='840 J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842\\nHence Claims 68 and Lemma 1 imply that Qj(Aii+Aij+Aji)Qi=(Aji)and\\nQi(Aii+Aij+Aji)Qi=(Aii)+Qifor some R.\\nFor every TjjAjj, it follows from [Aii+Aij+Aji,Tjj]=[Aij,Tjj](i/=j) and Claim 7 that, for every\\nSjjBjj,\\n((Aii+Aij+Aji)(Aij))Sjj=Sjj((Aii+Aij+Aji)(Aij)).\\nSoQi(Aii+Aij+Aji)Qj=(Aij)and there exists Rsuch that Qj(Aii+Aij+Aji)Qj=Qj.\\nThus\\n(Aii+Aij+Aji)=(Aii)+Qi+(Aij)+(Aji)+Qj. (2.12)\\nFor every TiiAii, it follows from Eq. (2.12) that there exist ,Rsuch that\\n(TiiAiiAiiT\\nii)+(TiiAij)+(AjiT\\nii)+Qi+Qj\\n=(TiiAii+TiiAijAiiT\\niiAjiT\\nii)\\n=([Tii,Aii+Aij+Aji])\\n=[(Tii),(Aii)+Qi+(Aij)+(Aji)+Qj]\\n=(TiiAiiAiiT', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 7}), Document(page_content='=(TiiAiiAiiT\\nii)+(TiiAij)+(AjiT\\nii)+((Tii)(Tii)).\\nSo===0. On the other hand, for every TjjAjj, it follows from Eq. (2.12) and Claim 8 that\\n(TjjAji)+(AijT\\njj)=(TjjAjiAijT\\njj)\\n=([Tjj,Aii+Aij+Aji])\\n=[(Tjj),(Aii)+(Aij)+(Aji)+Qj]\\n=(TjjAji)+(AijT\\njj)+((Tjj)(Tjj)),\\nand hence =0. So\\n(Aii+Aij+Aji)=(Aii)+(Aij)+(Aji). (2.13)\\nFor every T11A11,w eh a v e [T11,A11+A12+A21+A22]=[T11,A11+A12+A21]. So, for every\\nS11B11, it follows that\\nS11((A11+A12+A21+A22)(A11+A12+A21))\\n=((A11+A12+A21+A22)(A11+A12+A21))S\\n11.\\nThis, together with Eq. (2.13), ensures that\\nP1(A11+A12+A21+A22)P1=(A11),\\nP1(A11+A12+A21+A22)P2=(A12),\\nP2(A11+A12+A21+A22)P1=(A21).\\nBy Claim 7, there exists C22A22such that', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 7}), Document(page_content='By Claim 7, there exists C22A22such that\\nP2(A11+A12+A21+A22)P2=(C22).\\nThus\\n(A11+A12+A21+A22)=(A11)+(A12)+(A21)+(C22).\\nFor every T22A22, it follows from the above expression and Eq. ( 2.13) that\\n(T22A21)+(A12T\\n22)+(T22A22A22T\\n22)\\n=(T22A21A12T\\n22+T22A22A22T\\n22)\\n=([T22,A11+A12+A21+A22])', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 7}), Document(page_content='J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842 841\\n=[(T22),(A11)+(A12)+(A21)+(C22)]\\n=(T22A21)+(A12T\\n22)+(T22C22C22T\\n22).\\nSoT22(C22A22)=(C22A22)T\\n22for every T22A22, and hence, C22=A22and the claim holds.\\nClaim 10. Let A ii,BiiAiiand A ij,BijAij(i/=j).Then\\n(Aij+Bij)=(Aij)+(Bij)and(Aii+Bii)=(Aii)+(Bii).\\nIt follows from [Pi+Aij,Pj+Bij]=Aij+BijA\\nijBijA\\nij, Claim 8 and Eq. (2.13) that\\n(Aij)+(Bij)(Aij)(Bij)(Aij)\\n=[Qi+(Aij),Qj+(Bij)]\\n=[(Pi+Aij),(Pj+Bij)]\\n=([Pi+Aij,Pj+Bij])\\n=(Aij+BijA\\nijBijA\\nij)\\n=(Aij+Bij)+(A\\nij)+(BijA\\nij).\\nMultiplying respectively Qiand Qjfrom the left side and right side of the above expression, one has\\n(Aij+Bij)=(Aij)+(Bij).', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 8}), Document(page_content='(Aij+Bij)=(Aij)+(Bij).\\nLetTijAij(i/=j) be arbitrary. Applying the above expression, we have\\n(Aii+Bii)(Tij)=[(Aii+Bii),(Tij)]\\n=([Aii+Bii,Tij])=(AiiTij+BiiTij)\\n=(AiiTij)+(BiiTij)\\n=([Aii,Tij])+([Bii,Tij])\\n=[(Aii),(Tij)]+[(Bii),(Tij)]\\n=((Aii)+(Bii))(Tij).\\nClaim 6 implies that ((Aii+Bii)(Aii)(Bii))Sij=0 for all SijBij, and hence (Aii+Bii)=\\n(Aii)+(Bii).\\nClaim 11. Let A ii,BiiAiiand A ij,BijAij(i/=j).Then\\n(AiiBii)=(Aii)(Bii),(AijBji)=(Aij)(Bji),\\n(AiiBij)=(Aii)(Bij),(AijBjj)=(Aij)(Bjj).\\nLetXAij(i/=j) be arbitrary. Then (AiiX)=([Aii,X])=(Aii)(X), and hence,\\n(AiiBii)(X)=(AiiBiiX)=(Aii)(BiiX)=(Aii)(Bii)(X)\\nfor all XAij. Now Claim 6 implies that\\n(AiiBii)=(Aii)(Bii). (2.14)', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 8}), Document(page_content='(AiiBii)=(Aii)(Bii). (2.14)\\nFrom Claim 6, it follows that\\n(AijBji)=([Aij,Bji])=[(Aij),(Bji)]=(Aij)(Bji).\\nThus, for every TjiAji(j/=i), the above expression and Eq. (2.14) imply that\\n(AiiBij)(Tji)=(AiiBijTji)=(Aii)(BijTji)=(Aii)(Bij)(Tji),\\nand therefore,', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 8}), Document(page_content='842 J. Cui, C.-K. Li / Linear Algebra and its Applications 431 (2009) 833842\\n(AiiBij)=(Aii)(Bij).\\nSimilarly, for every TjiAji(j/=i),\\n(Tji)(AijBjj)=(TjiAijBjj)=(TjiAij)(Bjj)=(Tji)(Aij)(Bjj).\\nSo\\n(AijBjj)=(Aij)(Bjj).\\nClaim 12. :ABis a-ring isomorphism .\\nClaims 9 and 10 imply that is additive. Next, we prove that is multiplicative. For any A,BA,\\nwrite A=2\\ni=1Aijand B=2i=1Bij. Then\\nAB=(A11B11+A12B21)+(A11B12+A12B22)\\n+(A21B11+A22B21)+(A21B12+A22B22).\\nIt follows from Claims 9, 10 and 11 that (AB)=(A)(B).\\nFor every AA,w eh a v eA =A+A\\n2+iAA\\n2i, whereA+A\\n2andAA\\n2iare self-adjoint. It follows from\\n(iA)= i(A)(AA) that(A)=(A)for every AA,s ois a-ring isomorphism.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 9}), Document(page_content='The following corollary generalized the result in [ 1], where the author assume that the Hilbert\\nspace is at least of dimension 3.\\nCorollary 1. LetAand Bbe type I factor von Neumann algebras acting on complex Hilbert spaces H and\\nK,respectively .Then a bijective map :ABsatisfying (ABBA)=(A)(B)(B)(A)\\nif and only if there exists a unitary or conjugate unitary operator U :HK such that (A)=UAUfor\\nevery A A.\\nProof. Since every ring isomorphism from Aonto Bis spatial, the result follows from Main\\ntheorem. \\nCorollary 2. LetAand Bbe von Neumann algebras acting on complex Hilbert spaces H and K ,respectively .\\nAssume that Aand Bare nite factors .Then a linear bijective map :ABsatisfying (ABBA)=', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 9}), Document(page_content='(A)(B)(B)(A)if and only if there exists a unitary operator U :HK such that (A)=UAU\\nfor every A A.\\nProof. The result follows from Main Theorem and [3, Proposition 10, pp. 304], which states that every\\nisomorphism between nite factors is spatial. \\nReferences\\n[1] R. An, J. Hou, A characterization of -automorphisms of B(H), in press.\\n[2] M. Brear, M. Foner, On ring with involution equipped with some new product, Publ. Math. Debrecen, 57 (2000) 121134.\\n[3] J. Dixmier, Von Neumann Algebras, North-Holland Publishing Company, 1981.[4] P. Fillmore, D. Topping, Operator algebras generated by projections, Duke Math. J. 34 (1967) 333336.[5] L. Molnr, A condition for a subspace of B', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 9}), Document(page_content='(H)to be an ideal, Linear Algebra Appl. 235 (1996) 229234.\\n[6] P. emrl, Quadratic functionals and Jordan -derivations, Studia Math. 97 (1991) 157165.\\n[7] P. emrl, On Jordan -derivations and an application, Colloq. Math. 59 (1990) 241251.\\n[8] P. emrl, Quadratic and quasi-quadratic functionals, Proc. Amer. Math. Soc. 119 (1993) 11051113.[9] P. emrl, Jordan\\n-derivations of standard operator algebras, Proc. Amer. Math. Soc. 120 (1994) 515519.', metadata={'source': '/share/lab4/ych/papers/paper4.pdf', 'page': 9})]\n",
      "[Document(page_content='PHYSICAL REVIEW A 101, 032307 (2020)\\nQuantum algorithm for solving linear differential equations: Theory and experiment\\nTao Xin,1,2,*Shijie Wei,1,3,*Jianlian Cui,4Junxiang Xiao,1Iigo Arrazola,5Lucas Lamata,5,6Xiangyu Kong,1Dawei Lu,2,\\nEnrique Solano,5,7,8and Guilu Long1,9,3,\\n1State Key Laboratory of Low-Dimensional Quantum Physics and Department of Physics, Tsinghua University, Beijing 100084, China\\n2Shenzhen Institute for Quantum Science and Engineering and Department of Physics, Southern University of Science and Technology,\\nShenzhen 518055, China\\n3Beijing Academy of Quantum Information Sciences, Beijing 100193, China\\n4Department of Mathematics, Tsinghua University, Beijing 100084, China', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='5Department of Physical Chemistry, University of the Basque Country UPV /EHU, Apartado 644, 48080 Bilbao, Spain\\n6Departamento de Fsica Atmica, Molecular y Nuclear, Universidad de Sevilla, 41080 Sevilla, Spain\\n7IKERBASQUE, Basque Foundation for Science, Maria Diaz de Haro 3, 48013 Bilbao, Spain\\n8International Center of Quantum Articial Intelligence for Science and Technology (QuArtist) and Department of Physics, Shanghai\\nUniversity, 200444 Shanghai, China\\n9Tsinghua National Laboratory of Information Science and Technology and The Innovative Center of Quantum Matter, Beijing 100084, China\\n(Received 20 January 2020; accepted 12 February 2020; published 6 March 2020)', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='Solving linear differential equations (LDEs) is a hard problem for classical computers, while quantum\\nalgorithms have been proposed to be capable of speeding up the calculation. However, they are yet to be realizedin experiment as it cannot be easily converted into an implementable quantum circuit. Here, we present andexperimentally realize an implementable gate-based quantum algorithm for efciently solving the LDE problem:given an NNmatrix M,a nN-dimensional vector b, and an initial vector x(0), we obtain a target vector x(t)a s\\na function of time taccording to the constraint dx(t)/dt=Mx(t)+b. We show that our algorithm exhibits an', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='exponential speedup over its classical counterpart in certain circumstances, and a gate-based quantum circuit isproduced which is friendly to the experimentalists and implementable in current quantum techniques. In addition,we experimentally solve a 4 4 linear differential equation using our quantum algorithm in a four-qubit nuclear\\nmagnetic resonance quantum information processor. Our algorithm provides a key technique for solving manyimportant problems which rely on the solutions to linear differential equations.\\nDOI: 10.1103/PhysRevA.101.032307\\nI. INTRODUCTION\\nLinear differential equations (LDEs) are an important', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='framework with which to describe the dynamics of a plethoraof physical models, involving classical as well as quantumsystems. They play key roles in many applications, e.g.,predicting climate change and calculating fusion energy. Infact, many of the main applications of supercomputers arein the form of large systems of differential equations [ 1].\\nGenerally, solving an LDE is a hard problem for a classicalhigh-performance computer, in particular when the size ofthe conguration space is large, as for example in quantumsystems or uid dynamics.\\nA possible way to overcome the above difculty is to uti-', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='lize quantum computing. Quantum information processing isone of the most fruitful elds of research in physics nowadays.Besides the famous Shor factoring algorithm [ 2,3] and Grover\\nsearch algorithm [ 4], a quantum computer is also capable\\nof solving linear systems of equations [ 5,6] exponentially\\nfaster than any classical computers. In recent years, rst steps\\n*These authors contributed equally to this work.\\nludw@sustech.edu.cn\\ngllong@tsinghua.edu.cntowards solving linear equations have been demonstratedin optics [ 7,8], nuclear magnetic resonance (NMR) [ 9,10],\\nand superconducting circuits [ 11]. However, extending the', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='algorithm to differential equations is not straightforward.Although some quantum algorithms have been proposed[1214], they are not easily implemented using state-of-the-\\nart techniques due to the lack of quantum circuits. Therefore,it is timely to design an implementable quantum algorithm andcarry out the experimental demonstrations for solving LDEsin controllable quantum platforms.\\nIn this work, we present a quantum algorithm for solving', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='LDEs with the gate-based circuit only comprising of standardquantum gates, which is straightforward to be realized incurrent technologies. The precision of our algorithm can beboosted exponentially by adding the number of ancilla qubits.We further demonstrate it in a four-qubit NMR system, whichis a quantum platform with a myriad of successes in the eldof quantum technologies [ 15]. Many of the rst demonstra-\\ntions of quantum algorithms were achieved in this platform[1623], which inherited a high degree of quantum control in\\nNMR spectroscopy during the 20th century. This includes therecent demonstration of quantum machine learning [ 24] and\\nlinear solvers of equations [ 9]. In this work, we carry out a', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='proof-of-principle experiment to implement an LDE solver ina four-qubit NMR quantum processor.\\n2469-9926/2020/101(3)/032307(13) 032307-1 2020 American Physical Society', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 0}), Document(page_content='TAO XIN et al. PHYSICAL REVIEW A 101, 032307 (2020)\\nProblem. The description of the problem for solving LDEs\\nis as follows. An unknown vector x(t) starts from an initial\\npoint x(0) and follows an evolution described by an LDE\\ndx(t)/dt=Mx(t)+b, where Mis an arbitrary NNma-\\ntrix, while bandx(t)a r e N-dimensional vectors.\\nThe analytical solution of the equation can be written\\nasx(t)=eMtx(0)+(eMtI)M1b, involving matrix ex-\\nponentials and inversions. For a classical computer, to ap-proximate the solution in general requires time that scales atleast as O(N\\n3)[25], which is dominated by the computation\\nofeMt. This runtime is not surprising since solving linear', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='systems of equations, which is equivalent to computing thematrix inversion only, already requires O(N) time classically\\n[5]. Here, we provide a quantum algorithm to estimate the\\nsolution of such an equation in O(logN) time, which yields\\nan exponential speedup compared to the classical counterpartin certain circumstances.\\nII. OUR ALGORITHM FOR SOLVING LDES\\nA. The algorithm framework\\nNow we present the basic idea of nding x(t) based on our\\nquantum algorithm. By Taylor expansion, the solution x(t)i s\\napproximately\\nx(t)k\\nm=0(Mt)m\\nm!x(0)+k\\nn=1Mn1tn\\nn!b, (1)\\nwhere kis the approximation order. The vectors x(0) and bcan\\nbe described by quantum states |x(0)=\\njxj(0)/x(0)|j\\nand|b=\\njbj/b|j, respectively, where xj(0) and bjare', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='jbj/b|j, respectively, where xj(0) and bjare\\nthejth elements of these vectors, |jis the N-dimensional\\ncomputational basis, and  is the modulus operation. The\\nmatrix Mcan be described by the operator Adened as\\nA=\\ni,jMij/M|ij|. Hence, the kth-order approximate\\nsolution converts to\\n|x(t)k\\nm=0x(0)(MAt)m\\nm!|x(0)\\n+k\\nn=1b(MA)n1tn\\nn!|b, (2)\\nup to normalization. Our algorithm provides a general frame-\\nwork for computing Eq. ( 2) employing a quantum system with\\nthe assistance of ancilla qubits. The algorithm works for bothunitary and nonunitary As, and in the following we consider\\neach of the two situations, respectively.\\n1. Case I\\nIf the operator Ais unitary, the powers of Awill be also uni-', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='tary. Let Um=Am,Un=An,Cm=x(0)(Mt)m/m!, and\\nDn=b(Mt)n1t/n!. By substituting them into Eq. ( 2),\\nx(t) can be represented by\\n|x(t)1\\nN2(k\\nm=0CmUm|x(0)+k\\nn=1DnUn1|b)\\n, (3)FIG. 1. Quantum circuit for solving LDEs when Ais unitary.\\nIt includes a rst ancilla register with one qubit, a second ancilla\\nregister with T=log2(k+1) qubits, and a work system. All ancilla\\nregisters are initially prepared in |0|0T. The controlled operations\\nUxandUbare used to create |x(0)and|b, respectively. The evo-\\nlution operator during encoding and decoding isk\\n=0||U.\\nThe state after each step is denoted as |i,i=1,2,3. At the end\\nof the circuit, we measure the state vector of the work system in the', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='subspace where all ancilla qubits are |0.\\nwhereN2=C2+D2withC=CmandD=Dnis\\nthe normalization factor. Thus, the jth element of x(t) would\\nbexj(t)=N2j|x(t).\\nWe employ a composite quantum system incorporating a\\nwork system and two ancilla registers to perform our algo-rithm as shown in Fig. 1. The framework is divided into four\\nsteps as follows.\\na. Encoding. log\\n2Nwork qubits are needed to encode\\ntheN-dimensional vectors. |x(0)and|bare prepared and\\nstored by the work qubits labeled by the subspace of therst ancilla register as |0|x(0)and|1|b, respectively. In\\naddition, a second ancilla register with log\\n2(k+1) qubits\\nis added and transformed into a specic superposition state\\n|0k\\nm=0Cm|m+| 1k\\nn=1Dn|n.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='|0k\\nm=0Cm|m+| 1k\\nn=1Dn|n.\\nAssume the input state of the work qubits is |and all\\nancilla qubits are |0a ss h o w ni nF i g . 1. The rst operator V\\nis chosen as\\nV=1\\nN(\\nCD\\nDC)\\n. (4)\\nThe encoded states |x(0)and|bare realized by performing\\ncontrolled operations UxandUbon the input state |de-\\npending on the state of the rst ancilla qubit, respectively. Ajoint-controlled operation |00|V\\nS1Ux+|11|VS2\\nUbis applied subsequently, where UxandUbare used to\\nevolve the work qubits into |x(0)and|b, and VS1andVS2\\nare (k+1)(k+1) operations acting on the second ancilla\\nregister. The elements of the rst rows in VS1andVS2are\\nchosen as\\nVS1(:,1)=1/C[\\nC0,\\nC1,...,\\nCk1,\\nCk],\\nVS2(:,1)=1/D[\\nD1,\\nD2,...,\\nDk,0], (5)', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='Ck],\\nVS2(:,1)=1/D[\\nD1,\\nD2,...,\\nDk,0], (5)\\nwhile all other elements are arbitrary as long as VS1andVS2\\nare unitary. After computation, the initial state |in=| 0\\n|0T|is evolved into\\n|1=1\\nN(\\n|0k\\nm=0\\nCm|m|x(0)+| 1k\\nn=1\\nDn|n1|b)\\n.\\n032307-2', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 1}), Document(page_content='QUANTUM ALGORITHM FOR SOLVING LINEAR  PHYSICAL REVIEW A 101, 032307 (2020)\\nb. Entanglement creation. A series of controlled opera-\\ntions is applied, to realize the operationk\\n=0||U\\non the work qubits which is controlled by the second ancilla\\nregister. The work qubits and the ancilla registers are nowentangled, and the whole state is\\n|\\n2=1\\nN(\\n|0k\\nm=0\\nCm|mUm|x(0)\\n+|1k\\nn=1\\nDn|n1Un1|b)\\n. (6)\\nc. Decoding. All the operations in the encoding stage are\\nreversely applied. |00|WS1+|11|WS2on the ancilla\\nregisters are applied, where WS1=V\\nS1andWS2=V\\nS2,f o l -\\nlowed by the last operator W=Von the rst ancilla. Only\\nthe subspace where all ancilla qubits are |0is concerned, and', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='the state of the whole system in this subspace is\\n|3=1\\nN2|0|0T(k\\nm=0CmUm|x(0)+k\\nn=1DnUn1|b)\\n.\\nd. Measurement. We measure the nal state of the work\\nqubits in the subspace where all ancilla qubits are |0.I ti s\\nobvious by comparing with Eq. ( 3) that|x(t)will be directly\\nextracted; i.e., the solution to the LDE is obtained up to afactorN\\n2.\\n2. Case II\\nThis case in which Ais nonunitary is similar to the rst\\ncase, but more complicated. As Acan be decomposed into\\na linear combination of unitary operators A=L\\ni=1iAi,a s\\ngiven in the duality quantum computing formalism [ 2629],\\nwe need a third ancilla register to label the linear combinationA\\nis. Compared with the rst case, we need more ancilla qubits', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='and controlled operations. We give details in Appendix A.\\nB. The complexity of our algorithm\\nThere is no phase estimation or quantum Fourier transfor-\\nmation in our algorithms. The speedup of the algorithm comesfrom the nonunitary [see Eq. ( 2)] to unitary transformation', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='by adding ancillary qubits. The combination of an ancillarysystem with a work system provides additional freedom toprocess information. We create superposition states on the an-cillary system, and then perform controlled operations on thework system. The physical picture is that different unitary op-erations are implemented simultaneously on the work systembut in the different subspaces. Subsequently, all the operationsin the rst stage are reversely applied. The physical picture isthat we combine all the information in the different subspacesand obtain a nal result in a subspace where the ancillarysystem is |0. In fact, superposition and entanglement, as the', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='most important quantum resources, are both employed duringthe algorithm as shown in Fig. 1. Hence, we deem it natural\\nto yield quantum speedup in this algorithm for solving specialproblems.\\nGenerally speaking, the cost of a quantum algorithm in-\\nvolves two aspects. One aspect is qubit resources correspond-ing to space complexity. The other aspect is gate complexityFIG. 2. Quantum circuit in the encoding part for preparing the\\ninitial state |1when matrix Ais unitary.\\ncorresponding to time complexity. Next, we present a detailed\\ndiscussion about complexity for our algorithm when Ais\\nunitary.\\nQubit resources. In our algorithm, we need ancillary qubits\\nto realize the nonunitary evolution in Eq. ( 2) in a unitary way.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='The number of ancilla qubits is 1 +log(k+1), where kis the\\napproximate order in Eq. ( 2) and determines the gap be-\\ntween the ideal and approximate solutions with k=ln(C0/)\\nandC0constant (proof in Appendix B). In most cases, a\\nfairly small kis sufcient, as it exponentially improves the\\nsolutions precision .\\nGate complexity. In the encoding part (before |1in the\\ncircuit shown in Fig. 1), it is equivalent to a circuit where\\nthe four controlled operations Ux,Ub,VS1, and VS2are im-\\nplemented subsequently (see Fig. 2). Let us analyze the gate\\ncomplexity in the encoding part block by block.\\nFor the system, the vectors x(0) and bare rst loaded into\\nthe initial state |0|x(0)and|1|b(controlled UxandUb).', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='There are some proposed methods for loading the classicaldata, such as the quantum random access memory (qRAM)approach [ 3032]. qRAM is an important approach to prepare\\nthe initial state in many algorithms, especially in quantum ma-chine learning. The complexity for updating the data is aboutO(logN) after quantum memory is established. Hence, the\\ncomplexity to prepare the C|0|x(0)+D|1|b(orange part)\\nisO(log(2 N))O(logN)i nF i g . 2. The controlled operators\\nV\\nS1andVS2are real (2 k+2)(2k+2) matrices. They can\\nbe decomposed into O((log(2 k+2))3(2k+2)2)O(k2)\\nelementary gates via QR decomposition [ 33]. Thus, the gate\\ncomplexity for preparing the initial state |1isO(logN+\\nk2) by ignoring smaller terms and constants.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='k2) by ignoring smaller terms and constants.\\nIn the middle part of Fig. 1, the controlled operations\\nUmcan be decomposed into O((k+1) log( k+1) log N)\\nO(klogklogN) basic gates [ 34].\\nIn the decoding part, all the operations in the encoding\\nstage are reversely applied. Thus, it has the same gate com-plexity compared to the encoding part.\\nIn summary, the gate complexity of our algorithm is\\nO(klogklogN+logN+k\\n2). The performance of our algo-\\nrithm depends on two factors, kandN.I fkis polylogarithmic\\ninN, our algorithm achieves an exponential speedup. In\\nmost cases, a fairly small Taylor order kis enough, as it', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='exponentially improves the solutions precision. Therefore,we conclude that our algorithm yields a quantum speedup inmost circumstances. The complexity analysis for nonunitary\\n032307-3', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 2}), Document(page_content='TAO XIN et al. PHYSICAL REVIEW A 101, 032307 (2020)\\nFIG. 3. (a) Molecular structure and Hamiltonian parameters of\\n13C-labeled trans -crotonic acid. C 1,C2,C3,a n dC 4are used as four\\nqubits in the experiment, while M, H 1,a n dH 2are decoupled through-\\nout the experiment. In the table, the chemical shifts with respect tothe Larmor frequency and J-coupling constants (in hertz) are listed by\\nthe diagonal and off-diagonal numbers, respectively. The relaxation\\ntime scales T\\n2(in seconds) are shown at the bottom. (b) NMR\\nquantum circuit to realize the solution of a four-dimensional LDE\\nwith four qubits. A (labeled by C 1) and B (labeled by C 2) are work\\nqubits to encode the vectors |x(0)and|b. Qubit 1 (labeled by C 4)', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='and qubit 2 (labeled by C 3) are used as ancilla qubits. This circuit\\nstarts from |0000which is prepared by the spatial average method.\\nThe input state |is then created by implementing the rotations\\nRA\\ny()a n d RB\\ny() on the work qubits. Ux=IIandUb=xx\\nare applied to realize the preparation of the vectors |x(0)and|b,\\nrespectively. Finally, we measure the state of the work qubits when\\nthe ancilla qubits are |00. Durations of the optimized pulses for each\\nstep are also given.\\nAis presented in Appendix C. We also present an alternative\\napproach of our algorithm to solve LDEs with the less ancil-lary qubits in Appendix D.\\nIII. EXPERIMENTAL IMPLEMENTATION\\nA. Experimental setup\\nExperimentally, we demonstrate the quantum algorithm for', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='solving a four-dimensional LDE with a four-qubit nuclearmagnetic resonance system. We make use of the nuclear spinsin a sample of\\n13C-labeled trans -crotonic acid dissolved in\\nacetone-D 6. The internal Hamiltonian of this system can be\\ndescribed as\\nHint=4\\nj=1jj\\nz+4\\nj<k,=1\\n2Jjkj\\nzk\\nz, (7)\\nwhere jis the chemical shift of the jth spin and Jjkis the\\nJ-coupling strength between spins jandk. We assigned C 1\\nand C 2as system qubits and C 4and C 3as ancilla qubits,\\nrespectively. The structure and parameters of the moleculeare shown in Fig. 3(a). All experiments were carried out\\non a Bruker ADV ANCE 600 MHz spectrometer at roomtemperature.B. Protocol and results\\nIn experiment, we demonstrate a four-dimensional LDE\\ndx(t)/dt=Mx(t)+bwith', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='dx(t)/dt=Mx(t)+bwith\\nM=II+2Ix,\\nx(0)=[\\ncos2\\n2,cos\\n2sin\\n2,cos\\n2sin\\n2,sin2\\n2]\\n,\\nb=[\\nsin2\\n2,cos\\n2sin\\n2,cos\\n2sin\\n2,cos2\\n2]\\n.\\nThe value of ranges from 0 .1to 0.5with the increment\\n0.1. The nonunitary Mcan be decomposed into a linear\\ncombination of M0=IIandM1=Ix. The initial\\nvector |x(0)and|bare realized by applying two-qubit op-\\nerations UxandUbon|, respectively, where |is created\\nby|=RA\\ny()RB\\ny()|00with Rj\\ny()=eij\\ny/2.\\nThe accuracy of the solution depends on the order k.W es e t\\nthe order k=4, leading to four qubits to implement the quan-\\ntum circuit [see Fig. 3(c)] for solving the LDE. The forms of\\nV,W,Uc,VS1,VS2,WS1, and WS2can be found in Appendix E.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='To experimentally realize our algorithm, we make use of thenuclear spins in a sample of\\n13C-labeled trans -crotonic acid\\ndissolved in acetone-D 6shown in Fig. 3(a)[3537].\\nFirst, we use the spatial averaging technique to prepare the\\npseudopure state (PPS) [ 38,39] from the thermal equilibrium.\\nAt thermal equilibrium, an NMR sample stays in the Boltz-mann distribution,\\n\\nthermal=I\\n16+(\\n1\\nz+2\\nz+3\\nz+4\\nz)\\n, (8)\\nwhere Iis a 16 16 identity matrix and the polarization\\n105. It is a highly mixed state which is not suitable\\nfor quantum computing. Starting from this state, we use thespatial averaging technique to realize the preparation of thefollowing PPS:\\n\\n0000=1\\n16I+|00000000|. (9)', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='\\n0000=1\\n16I+|00000000|. (9)\\nThe initialization processing usually includes local unitary\\nrotations and z-gradient elds for suppressing the undesired\\ncoherence. Considering that the identity part does not evolveunder any unitary operations or inuence any measurementsin NMR, the deviation density matrix |00000000|can serve\\nas the initial state of the quantum circuit. Figure 4presents\\nexperimental spectra of the PPS for different carbon nucleiand the reconstructed density matrix of the PPS by performingquantum state tomography. The delity between the ideal purestate|0000and the experimental PPS is about 0.99, which\\nunderpins subsequent experiments.\\nSubsequently, we perform the operations involved in our', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='algorithm. All the operations are individually realized usingshaped pulses optimized by the gradient method [ 4042].\\nEach shaped pulse is simulated to be about 0.998 delity whilebeing robust to the static eld distributions and inhomogene-ity.\\nFinally, we need to measure the state of the work qubits\\nwhen the ancilla are |00. In experiment, we performed four-\\nqubit state tomography to extract the desired results from thenal density matrix [ 43,44]. It also enables us to evaluate the\\n032307-4', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 3}), Document(page_content='QUANTUM ALGORITHM FOR SOLVING LINEAR  PHYSICAL REVIEW A 101, 032307 (2020)\\nFIG. 4. Experimental spectra of the nuclei C 1C4and the reconstructed density matrix of the PPS. (a) NMR signals of the nuclei C 1C4\\nare measured by applying the corresponding /2 readout pulses after the PPS preparation. (b) Top and bottom plots respectively show the real\\nand imaginary part of the reconstructed PPS matrix. The zaxis represents the value of the element in the matrix.\\nquality of our implementation by comparing the distance be-\\ntween the target state thand the experimentally reconstructed\\ndensity matrix expt.\\nWe x t=0.4 and range from 0 .1to 0.5with the in-\\ncrement 0 .1in experiments. In other words, we demonstrate', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 4}), Document(page_content='the solutions to ve LDEs with different initial vectors |x(0)\\nand offset vectors |bat a xed time t=0.4. For each value\\nof, the experiment is repeated four times to estimate the\\nuncertainty. After the implementation of the quantum circuit,we perform the four-qubit state tomography by applying 17readout pulses (Appendix F). On average, the experimental\\ndelity for all states is F=0.946(4), estimated by\\nF(\\nth,expt)=Tr(thexpt)/\\nTr(\\n2\\nth)\\nTr(\\n2\\nexpt)\\n. (10)\\nTaking =0.1as an example, the comparison between the\\nexperimental and simulated NMR spectra of the work qubitsis given in Figs. 5(a) and 5(b), and they are in excellent\\nagreement. The real parts of the density matrices for \\nexptand', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 4}), Document(page_content='exptand\\nthare also displayed in Fig. 5(c)to evaluate the performance\\na\\nbc(arb. units) (arb. units)\\nFIG. 5. NMR spectra of (a) C 1(work qubit A) and (b) C 2(work\\nqubit B) followed by a readout pulse R12\\ny(/2)RAB\\nx(/2) for =\\n0.1. The gray and blue lines show the experimental and simulated\\nspectra, respectively. (c) Real part of the density matrices exptand\\nthfor=0.1.of our experiment. Furthermore, considering that M,|x(0),\\nand|bare all real in our setting, the solution x(t) should be\\nalso real. We use a maximum-likelihood (ML) approach toconstruct a real state \\nmlwhich is closest to the experimentally\\nmeasured density matrix expt[35,45]. After obtaining ml,w e', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 4}), Document(page_content='calculate the reduced state vector of work qubits A and B inthe subspace where the ancilla are |00, and then reproduce\\nthe solutions to the LDEs by amplifying the result by N\\n2=\\n4.059. Table Isummarizes all experimental results of the ve\\nLDEs and the comparison between theory and experiment.\\nIV . CONCLUSION\\nIn summary, we present a quantum algorithm and the\\nrelevant quantum circuit for solving N-variable LDEs, which\\nachieves an exponential speedup O(logN) over its classical\\ncounterpart in certain circumstances. As a proof-of-principledemonstration, we experimentally realize the solution to aset of LDEs with the dimension 4 4 in a four-qubit NMR', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 4}), Document(page_content='quantum processor. The experimental solutions to these LDEsare obtained with about 5.36% indelity. The error mainlycomes from the imperfections of the initial state preparation,the imprecisions and inhomogeneity of the optimized pulses,the decoherence effect, and the readout error in tomography.We numerically simulate each of the above factors to estimatethe error distribution (Appendix G). On average, numerical\\nresults show that the error in state preparation, shaped pulses,decoherence, and readout are 1.07%, 0.84%, 1.19%, and1.23%, respectively. The sum is 4.33% by assuming all errorsare additive, which is slightly smaller than the measured1F. As the discrepancy is quite small, our error estimation', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 4}), Document(page_content='is consistent with the experimental results. It indicates theaccuracy of the experimental implementation.\\nUnlike Shors or Harrow-Hassidim-Lloyd (HHL) algo-\\nrithms where the core is phase estimation, the speedup ofour algorithm comes from the nonunitary [see Eq. ( 2)] to\\nunitary transformation by adding ancillary qubits. It is calledthe linear combination of unitaries (LCU). LCU is alsoa universal subroutine in designing and developing quan-tum algorithms [ 46]. Traditional quantum computing based\\non a closed quantum system undergoes unitary evolution.\\n032307-5', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 4}), Document(page_content='TAO XIN et al. PHYSICAL REVIEW A 101, 032307 (2020)\\nTABLE I. Experimental results of our algorithm for solving an LDE dx(t)/dt=Mx(t)+bat a xed time t=0.4s .(see Fig. 3)\\nranges from 0 .1to 0.5with a 0 .1increment. Theoretical and experimental solutions x(t) are both shown. To evaluate the performance,\\nwe compute the inner product (normalized) between the theoretical and experimental x(t). Similarity between vectors canddis dened as\\nthe cosine similarity |cd|/|c|2|d|2. Error bars come from the uncertainty in repeated experiments, which is mainly attributed to the drift of\\ntemperature and inhomogeneity of the magnetic eld.\\n0.1 0.2 0.3 0.4 0.5', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='0.1 0.2 0.3 0.4 0.5\\n Theory Experiment Theory Experiment Theory Experiment Theory Experiment Theory Experiment\\nResults x(t) 2.184 2.280 0.006 2.295 2.333 0.005 2.305 2.277 0.003 2.214 2.154 0.002 2.030 2.066 0.006\\n1.676 1.747 0.009 1.951 2.059 0.006 2.110 2.193 0.002 2.137 2.214 0.006 2.030 2.049 0.004\\n0.635 0.708 0.007 1.066 1.040 0.008 1.466 1.453 0.004 1.799 1.829 0.005 2.030 2.105 0.003\\n0.819 0.881 0.008 1.134 1.064 0.007 1.462 1.372 0.007 1.770 1.701 0.002 2.030 1.892 0.004\\nSimilarity 99.99% 0.003% 99.93% 0.009% 99.94% 0.003% 99.95% 0.003% 99.92% 0.005%\\nHowever, the evolution for this LDE problem described by\\nEq. ( 2) is nonunitary. To make it implementable in a unitary', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='quantum circuit, we added an ancillary system to let theevolution of the whole system be unitary and provided thegate-based quantum circuit which is friendly to experimen-talists. This is the intuition when developing our algorithm.Furthermore, as long as the target is some linear combinationof unitary operators, our model provides a general way toenable its realization in a unitary quantum circuit at the costof ancillary qubits. We anticipate it to be heuristic whenexploring quantum algorithms with nonunitary evolutions inthe future, such as route optimization of unmanned vehiclesin articial intelligence.\\nACKNOWLEDGMENTS\\nS.W. and G.L. are grateful to the following funding', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='sources: National Basic Research Program of China,the National Natural Science Foundation of China(Grants No. 11974205 and No. 11774197), the NationalKey Research and Development Program of China(2017YFA0303700), the Key Research and DevelopmentProgram of Guangdong province (2018B030325002),and Beijing Advanced Innovation Center for Future Chip(ICFC). T.X. and D.L. are supported by the National NaturalScience Foundation of China (Grants No. 11905099, No.11605005, No. 11875159, and No. U1801661), Science,Technology and Innovation Commission of ShenzhenMunicipality (Grants No. ZDSYS20170303165926217and No. JCYJ20170412152620376), Guangdong Innovativeand Entrepreneurial Research Team Program (Grant No.2016ZT06D348), and Guangdong Basic and', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='(Grant No.2016ZT06D348), and Guangdong Basic and Applied BasicResearch Foundation (Grant No. 2019A1515011383). I.A.,L.L., and E.S. acknowledge nancial support from SpanishGovernment PGC2018-095113-B-I00 (MCIU /AEI/FEDER,', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='UE), EU FET Open Grant Quromorphic (828826), BasqueGovernment IT986-16, Ph. D. Grant No. PRE-2015-1-0394,and the projects QMiCS (820505) and OpenSuperQ (820363)of the EU Flagship on Quantum Technologies.\\nAPPENDIX A: MATHEMATICAL DETAILS OF\\nOUR ALGORITHM\\nWe present a mathematical representation of our algorithm\\nby considering the following two cases.1.Ais unitary\\nIn order to solve an LDE where the matrix Ais unitary,\\nwe need a composite quantum system with a (1 +T)-qubit\\nancilla register and a log2(N)-qubit work system. Suppose the\\ninput state of the work system is |and all ancilla qubits\\nare prepared in state |0|0T. First, the rst ancilla qubit\\nevolves to a superposition state after a unitary operation V\\nis performed,\\nV=1\\nN(\\nCD\\nDC)', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='is performed,\\nV=1\\nN(\\nCD\\nDC)\\n. (A1)\\nThe encoded states |x(0)and|bare realized by performing\\ncontrolled operations UxandUbon the input state |, respec-\\ntively. The initial state |0|0T|is thus\\nC\\nN|0|0T|x(0)+D\\nN|1|0T|b. (A2)\\nThen, we dene ( k+1)(k+1) controlled operations VS1\\nandVS2with\\nVS1=1\\nC\\nC0QQQQQC1QQQQQ\\n QQQQQCkQQQQQ\\n\\n(k+1)(k+1),(A3)\\nVS2=1\\nD\\nD1QQQQQD2QQQQQ\\n QQQQQDkQQQQQ\\n0 QQQQQ\\n\\n(k+1)(k+1),(A4)\\nwhere Qs are arbitrary elements that make VS1and VS2\\nunitary. Then, Eq. ( A2) is changed to\\n1\\nN(\\n|0k\\nm=0\\nCm|m|x(0)+| 1k\\nn=1\\nDn|n1|b)\\n.\\nThe controlled operation Uc=|00|U0+|11|\\nU1++| kk|Ukis implemented afterwards, where\\nUk=Ak. The state of the whole system is\\n1\\nN|0k\\nm=0', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='1\\nN|0k\\nm=0\\nCm|mUm|x(0)+1\\nN|1k\\nn=1\\nDn|n1Un1|b.\\n032307-6', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 5}), Document(page_content='QUANTUM ALGORITHM FOR SOLVING LINEAR  PHYSICAL REVIEW A 101, 032307 (2020)\\nFIG. 6. Universal quantum circuit for solving any LDEs. The framework includes four parts: rst ancilla register with one qubit, second\\nancilla register with kqubits, third ancilla register with kqudits where each qudit has Llevels, and a work system. All ancilla registers are\\ninitially prepared in the ground state |0|0k|0k\\nL.|0Ldenotes the ground state of an L-level system, which can be encoded by a log2(L)-qubit\\nquantum system. Hence, all operations acting on the third ancilla register are LLmatrices. The red squares denote jointly controlled', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 6}), Document(page_content='operations, with the corresponding circuit shown on the right. At the end of the circuit, we measure the state of the work system in the\\nsubspace where all ancilla registers are |0|0k|0k\\nL.\\nSubsequently, we implement the operations WS1=V\\nS1and\\nWS2=V\\nS2controlled by the state of the rst register on the\\nsecond register, which leads to\\n1\\nN(\\n|0|0Tk\\nm=0Cm\\nCUm|x(0)+| 1|0Tk\\nn=1Dn\\nDUn1|b)\\nin the subspace where the second ancilla qubits are all |0T.\\nThe last unitary operation W=Vis applied on the rst\\nregister. Analogously, we focus on the subspace where allancilla qubits are |0, and the nal state is\\n1\\nN2|0|0T(k\\nm=0CmUm|x(0)+k\\nn=1DnUn1|b)\\n.(A5)\\nThat is, if we measure the state of the work qubits in the', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 6}), Document(page_content='subspace where the ancillas are |0|0T, the result directly\\nrepresents the solution to the LDE amplied by a factor N2.\\nThe successful probability of yielding the correct answer is\\n1\\n(N2)2(k\\nm=0C2\\nm+k\\nn=1D2\\nn)\\n1\\nN4. (A6)\\n2.Ais nonunitary\\nFirst, the nonunitary matrix Acan be decomposed into a\\nlinear combination of unitary operators A=L\\ni=1iAi, where\\ntheAis are unitary matrices. Thus, the solution can be written\\nas\\n|x(t)k\\nm=0x(0)(Mt)m(L\\ni=1iAi)m\\nm!|x(0)\\n+k\\nn=1bMn1tn(L\\ni=1iAi)n1\\nn!|b.\\nTo obtain the solution, we need to add the third ancilla register\\ncompared to the case when Ais unitary. The rst ancilla', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 6}), Document(page_content='register is still encoded in one qubit. The second ancillaregister consists of kqubits, and the third ancilla register\\nconsists of kqudits where each qudit is an L-level quantum\\nsystem.\\nA universal quantum circuit to solve any LDE is illustrated\\nin Fig. 6. Initially, all ancilla registers are prepared in the\\nground state |0|0k|0k\\nL, where |0Ldenotes the ground state\\nof an L-level quantum system. The work system employs the\\ninput state |to subsequently encode the vectors |x(0)and\\n|b. First, we implement the following operation Von the rst\\nancilla register:\\nV=\\nG1\\nG2\\n1+G2\\n2G2\\nG21+G2\\n2G2\\nG21+G2\\n2G1\\nG21+G2\\n2\\n, (A7)\\nwhere the parameters G1andG2are dened as\\nG1=k\\nm=0x(0)(Mt)m\\nm!(L\\ni=1i)m\\n, (A8)\\nG2=k\\nn=1b(Mt)n1t', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 6}), Document(page_content='m!(L\\ni=1i)m\\n, (A8)\\nG2=k\\nn=1b(Mt)n1t\\nn!(L\\ni=1i)n1\\n. (A9)\\nIn this way, we can encode the vectors |x(0)and|bby\\nthe controlled operations Uxand Ubon the work qubits,\\nrespectively. We then perform the controlled operations VS1\\nandVS2on the second ancilla register depending on the state of\\nthe rst ancilla register. VS1andVS2are 2k2kmatrices. The\\nmth element of the rst column has the following denition:\\nV(m,1)\\nS1=v(m,1)\\nS1\\nm|v(m,1)\\nS1|2,V(m,1)\\nS2=v(m,1)\\nS2\\nm|v(m,1)\\nS2|2,\\nwhere\\nv(m,1)\\nS1={\\nx(0)(Et)j\\nj!, m=2k2kj+1\\n0, other case,\\nv(m,1)\\nS2={\\nb(Mt)j1t\\nj!, m=2k2kj+1\\n0, other case.\\n032307-7', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 6}), Document(page_content='TAO XIN et al. PHYSICAL REVIEW A 101, 032307 (2020)\\nBesides, we apply the unitary operation VTon each L-level\\nqudit of the third ancilla register, where VTis an LLmatrix.\\nTheth element of the rst column in VTis\\nV(,1)\\nT=v(,1)\\nT\\n|v(,1)\\nT|2,with v(,1)\\nT=i, (A10)\\nwhere VT\\n,0=i. After implementing the unitary operations\\nV,VS1,VS2, and VT, the state of all ancilla registers will change\\nfrom the initial state |0|0k|0k\\nLto the following state:\\nG1\\nG2\\n1+G2\\n2|02k1\\nm=0V(m+1,0)\\nS1|m(L\\n=1V(,1)\\nT|1L)k\\n+G2\\nG2\\n1+G2\\n2|12k1\\nm=0V(m+1,0)\\nS2|m(L\\n=1V(,1)\\nT|1L)k\\n.\\nTo entangle the ancilla and the work qubits, we perform\\nthe controlled operation Uon the work system, which is', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 7}), Document(page_content='jointly controlled by the states of the second and third ancillaregisters. If we focus on the subspace |0|0\\nk|0k\\nLof all ancilla\\nregisters, the state of the work system can be written as\\n|0\\nmV(m+1,1)\\nS1|m(L\\n=1V(,1)\\nTA|1L)j\\n|x(0)\\n+|0\\nmV(m+1,1)\\nS2|m(L\\n=1V(,1)\\nTA|1L)j\\n|b.\\nHere, the sum index m=2k2kj,=G1/\\nG2\\n1+G2\\n2, and\\n=G2/\\nG2\\n1+G2\\n2.\\nFor decoding, we need to perform the inverse operations\\non all ancilla registers. The operations WS1=V\\nS1andWS2=\\nV\\nS2are implemented on the second register, which is con-\\ntrolled by the state of the rst register, and we reverse therst and third registers by applying W=V\\nandWT=V\\nT,', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 7}), Document(page_content='andWT=V\\nT,\\nrespectively. Finally, we measure the state of work qubitsin the subspace where all ancilla registers stay on the state|0|0\\nk|0k\\nL;|0|0k|0k\\nL|is changed to\\n1\\nS|0|0k|0k\\nL(k\\nm=0x(0)(MAt)m\\nm!)\\n|x(0)\\n+1\\nS|0|0k|0k\\nL(k\\nn=1b(MA)n1tn\\nn!)\\n|b,\\nwhere S=G1+G2. One can obtain the solution to the LDE\\nby multiplying S. If we directly measure the state of the work\\nsystem at the end of circuit, the probability of successfullydetecting the auxiliary state |0|0\\nk|0k\\nLisPs=As2/S2,\\nwhere Asis equal to\\nk\\nj=0x(0)(MAt)j\\nj!|x(0)+k\\nj=1b(MA)j1tj\\nj!|b).\\nPsis approximately 1 /S2.Sis the amplitude of the state of the\\nwork system on the subspace |0|0k|0k', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 7}), Document(page_content='work system on the subspace |0|0k|0k\\nLof all registers. Toimprove the desired amplitude and obtain a near-100% solu-\\ntion, we can adopt the robust obvious amplitude amplicationbyStimes before measurement.\\nAPPENDIX B: ERROR BOUNDS\\nIn this section, we analyze the indelity between the exact\\nsolution  x(t) and the approximate solution x(t), and give\\nan upper bound of the error =x(t)x(t). Since every\\nsquare complex matrix is similar to a Jordan matrix, for an n\\nncomplex matrix M, there exists an nninvertible matrix\\nTsuch that M=TJT1, where J=J1J2 Jm, and\\nJiis adidiJordan block with eigenvalues i,\\nJi=\\n\\ni 10  00\\n0i 1 00\\n00 i 00\\n     \\n000  i 1\\n000  0i\\n,\\nfori=1,2,...m, and\\nm', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 7}), Document(page_content='000  0i\\n,\\nfori=1,2,...m, and\\nm\\ni=1di=n. Thus, eMt=TeJtT1.\\nOne can compute that\\neJt=m\\ni=1eitJ\\ni,\\nwhere\\nJ\\ni=\\n1 t\\n1\\n2t21\\n(di2)!tdi2 1\\n(di1)!tdi1\\n01 t1\\n(di3)!tdi3 1\\n(di2)!tdi2\\n001 1\\n(di4)!tdi4 1\\n(di3)!tdi3\\n     \\n000  1 t\\n000  01\\n\\nis ad\\nidicomplex matrix. It follows that\\neJt=max{etReiJ\\ni|i=1,2,...m},\\nwhere J\\nidenotes the spectral norm, that is, the largest\\nsingular value of J\\ni. A Taylor expansion of ezwith Lagrange\\nremainder reads\\nez=k\\ni=1zk\\nk!+ez\\n(k+1)!zk+1,\\nwhere 0 << 1 is a constant. Let\\nC=(\\nx(0)+b\\nM)\\nTT1\\nmax{etReiJ\\ni|i=1,2,..., m}.\\nThen, the error is given by\\n=x(t)x(t)Mtk+1\\n(k+1)!C.\\nWhen kis sufciently large,\\n(k+1)!', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 7}), Document(page_content='(k+1)!C.\\nWhen kis sufciently large,\\n(k+1)!\\n2(k+1)(k+1\\ne)k+1\\n,\\nand it follows that\\n\\n2\\nC(eMt\\nk+1)k+11\\nk+1,\\n032307-8', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 7}), Document(page_content='QUANTUM ALGORITHM FOR SOLVING LINEAR  PHYSICAL REVIEW A 101, 032307 (2020)\\nand hence,\\nln\\n2\\nC(k+1)[lneMtln(k+1)]1\\n2ln(k+1)\\nso\\nln\\n2\\nC(k+1)[lneMtln(k+1)].\\nSince\\nln(k+1)lneMtk+1eMt\\nk+1,\\nwe have\\nk+1eMt+lnC\\n21\\n.\\nTherefore, klneeMt1C\\n21\\n.L e t C0=eeMt1C\\n2. Then, k\\nlnC0\\n, which implies that the larger the value of k, the smaller\\nthe error .\\nAPPENDIX C: THE COMPLEXITY ANALYSIS FOR\\nNONUNITARY A\\nGenerally speaking, the cost of a quantum algorithm in-\\nvolves two aspects. One aspect is qubit resource correspond-ing to space complexity. The other aspect is gate complexitycorresponding to time complexity. We have given the com-plexity analysis for unitary A. In this section, we present a', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='detailed discussion about complexity for our algorithm whenAis nonunitary.\\nQubit resources. The number of total ancillary qubits is\\n1+k+klogL, where Lis the number of unitary operators A\\ni\\nwhen Ais decomposed into A=L\\ni=1iAi. The qubit number\\nof the work system is log N. Hence, the total qubit resource in\\nour algorithm is log N+klogL+k+1.\\nGate complexity. The analysis is the same as that for\\nthe case of unitary Ain the main text. In the encod-\\ning part, we need O(log2 N) steps to prepare the state\\nC|0|x(0)+D|1|b. The controlled operators VS1andVS2\\ncan be regarded as two general 2k+12k+1unitary matri-\\nces. It can be decomposed into O((k+1)34k+1) elementary\\ngates via QR decomposition [ 33]. Each operation VTcan be', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='decomposed into O((log L)3L2)O(L2) elementary gates.\\nHence, we need O(log2 N+(k+1)34k+1+k(logL)3L2)\\nO(logN+k34k+kL2) steps to realize the encoding part.\\nIn the middle part, the controlled operations Ucan be de-\\ncomposed into O(kL(logL+1) log N)O(kLlogLlogN)\\nbasic gates [ 34]. The decoding part has the same gate com-\\nplexity compared to the encoding. So for nonunitary A, our\\nalgorithm requires O(kLlogLlogN+k34k+kL2) steps to\\nobtain the solution.\\nFrom the above analysis, we see that the gate complexity\\nmainly relies on the preparation of |1. Actually, the state\\n|1can be prepared by using the qRAM method [ 30]. qRAM\\nclaims the gate complexity for preparing an arbitrary P-\\ndimensional state is O(logP) after the quantum memory cell', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='is established. Hence, we can also analyze the gate complexityfor the qRAM method.\\nUnitary A. The dimensions of the work system, rst an-\\ncillary register, and second ancillary register are N,k+1,and 2, respectively. The dimension of the whole system is\\n2N(k+1). Thus, the gate complexity for preparing state\\n|\\n1isO(log(2 N(k+1))). The total gate complexity will be\\nreduced to O(klogklogN+logkN)O(klogklogN).\\nNonunitary A. The dimensions of the work system,\\nrst ancillary register, second ancillary register, and thirdancillary register are N,2 ,2\\nk, and kL, respectively. The\\ndimension of the whole system is N2k+1kL.T h eg a t e\\ncomplexity to prepare |1isO(log( N2k+1kL)). The total\\ngate complexity will be reduced to O(kLlogLlogN+', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='gate complexity will be reduced to O(kLlogLlogN+\\nlog(N2k+1kL))=O(kLlogLlogN+logN+(k+1)+\\nlogk+L)O(kLlogLlogN).\\nWe summarize the qubit resource and gate complexity of\\nour algorithm in Table II. Clearly, the performance of our\\nalgorithm depends on both kandL.I f4korLis polynomial\\ninN, our algorithm may not outperform classical algorithms\\n(polynomial speedup is still possible). This is very similarduring the analysis of complexity in the HHL algorithm. Forthe situations when 4\\nkandLare both polylogarithmic in N,\\nour algorithm achieves an exponential speedup. Recall thatthe Taylor order kdetermines the precision of the solution by\\nk=ln(C\\n0/); that is, kimproves the precision exponentially.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='Therefore, in most cases, a fairly small kis sufcient for\\napproximating a solution with remarkable precision, and wecan omit its contribution to the complexity.\\nIn summary, in most (at least certain) cases, we only need\\nto consider the system size Nwhen analyzing the complexity\\nof our algorithm. The complexity scales in O(logN).\\nNext we discuss the success probability of solving LDEs\\nwith our algorithms. The solution of an LDE after the k-order\\nTaylor expansion can be written as\\nx(t)k\\nm=0(Mt)m\\nm!x(0)+k\\nn=1Mn1tn\\nn!b. (C1)\\nNow let us dene a constant number G,\\nG=max{x(0)(Mt)k,b(Mt)k},\\nifMt>1,M>1,\\nG=max{x(0)(Mt)kt,b(Mt)kt},\\nifMt>1,M<1,\\nG=max{x(0),b},ifMt1,M>1,\\nG=max{x(0)/M,b/M},', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='G=max{x(0)/M,b/M},\\nifMt1,M<1. (C2)\\nWe divide both sides of the equation by this G. The new\\nsolution, x(t)=x(t)/G, is the same as the original solution\\nx(t) up to a constant. In terms of the quantum state, x(t) has\\nthe form\\n|x(t)1\\nN2(k\\nm=0x(0)(MAt)m\\nGm!|x(0) (C3)\\n+k\\nn=1b(MA)n1tn\\nGn!|b), (C4)\\n032307-9', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 8}), Document(page_content='TAO XIN et al. PHYSICAL REVIEW A 101, 032307 (2020)\\nTABLE II. Required qubit resources and gate complexity in our algorithm. Nandkare the dimensions of the work system and Taylor\\norder, respectively. Lis the number of unitary operations Aiwhen we decompose nonunitary AintoA=L\\ni=1iAi. It shows that our algorithm\\nexhibits an exponential speedup over its classical counterpart in certain circumstances.\\nCase Unitary A Nonunitary A\\nQubit 1 +log(k+1)+logN logN+klogL+k+1\\nGate O(klogklogN+logN+k2) O(kLlogLlogN+k34k+kL2)\\nGate (qRAM) O(klogklogN) O(kLlogLlogN)\\nwhere N2=k\\nm=0Cm+k\\nn=1Dn with Cm=\\nx(0)(Mt)m/Gm! and Dn=b(M)n1tn/Gn!.\\nHence, the success probability to obtain the solution is\\nP=1\\nN41\\nG2k\\nm=0x(0)(MAt)m\\nm!|x(0) (C5)\\n+k', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 9}), Document(page_content='P=1\\nN41\\nG2k\\nm=0x(0)(MAt)m\\nm!|x(0) (C5)\\n+k\\nn=1b(MA)n1tn\\nn!|b2, (C6)\\nwhere Gis the constant number dened by Eq. ( C2).\\n(i) For the term1\\nN4, we know\\nN2=k\\nm=0Cm+k\\nn=1Dn (C7)\\n=k\\nm=0x(0)(Mt)m\\nGm!+k\\nn=1b(M)n1tn\\nGn!(C8)\\nk\\nm=01\\nm!+k\\nn=11\\nn!e+e1=2e1. (C9)\\nHence,\\n1\\nN41\\n(2e1)2. (C10)\\n(ii) Now consider the term\\nS=k\\nm=0x(0)(MAt)m\\nm!|x(0)\\n+k\\nn=1b(MA)n1tn\\nn!|b2\\neMAt|x(0)x0+ b(eMAtI)(MA)1|b2.\\nFirst, let us assume the Mis anti-Hermitian. Then\\nS=x(0)2+2bx0b|(eMAtI)(MA)1|x(0)\\n+b2(eMAtI)(MA)1|b2.\\nx(0)22bx0\\nM(eMAtI)A1|b\\n+b2\\nM2(eMAtI)A1|b2.\\nWhen x(0)||b\\n2M(eMAtI)A1|b, we can get S', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 9}), Document(page_content='2M(eMAtI)A1|b, we can get S\\nx(0)2. It means the success probability of our algorithm hasthe lower boundary,\\nPx(0)2\\n(2e1)2G2. (C11)\\nIfMis not anti-Hermitian, we can reconstruct an anti-\\nHermitian operator M,\\nM=(0 M\\nM0)\\n, (C12)\\nand then solve the LDE. Analysis of the success probability is\\nthe same as that of the anti-Hermitian Mcase. Hence, there\\nis no success probability problem in our algorithm as long asx(0)\\nb\\n2M(eMAtI)A1|b.\\nOn the other hand, it does not mean that the success\\nprobability of our algorithm must be exponentially small ifx(0)\\nb\\n2M(eMAtI)A1|b. For instance, when b=\\n0,Pis reduced tox(0)2\\nN4G2, which is also independent of system\\nsize.\\nAPPENDIX D: AN ALTERNATIVE APPROACH OF', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 9}), Document(page_content='size.\\nAPPENDIX D: AN ALTERNATIVE APPROACH OF\\nOUR ALGORITHM\\nWhen the matrix Ais nonunitary, we provide an alternative\\napproach to solve LDEs. The solution can be written as\\nx(t)k\\nm=0x(0)(MAt)m\\nm!|x(0)\\n+k\\nn=1b(MA)n1tn\\nn!|b, (D1)\\nwhere Ais a normalized matrix satisfying A1. Then, A=\\nB+iCwhere BandCare the real and imaginary parts with\\nB=1\\n2(A+A),C=1\\n2i(AA). (D2)\\nIt is known that any real matrix can be decomposed into the\\nlinear combination of two unitary matrices. Hence,\\nB=1/2(F1+F2),C=1/2(F3+F4), (D3)\\nwhere the matrices F1,F2,F3, and F4are all unitary. Their\\ndenitions are\\nF1=B+i\\nIB2,F2=Bi\\nIB2,\\nF3=C+i\\nIC2,F4=Ci\\nIC2, (D4)\\nrespectively. Then, we can obtain the relationship between the\\nmatrices AandFis:\\nA=1', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 9}), Document(page_content='matrices AandFis:\\nA=1\\n2(F1+F2)+i\\n2(F3+F4). (D5)\\n032307-10', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 9}), Document(page_content='QUANTUM ALGORITHM FOR SOLVING LINEAR  PHYSICAL REVIEW A 101, 032307 (2020)\\nIf the coefcient iis absorbed into F3andF4,\\nF3=iC\\nIC2,F4=iC+\\nIC2, (D6)\\nwe have\\nA=1\\n2(F1+F2+F3+F4). (D7)\\nThe former is a linear combination of only four unitary\\nmatrices. In this situation, the solution x(t) can be written as\\nx(t)k\\nm=0x(0)(4\\ni=1M\\n2Fit)m\\nm!|x(0)\\n+k\\nn=1b(4\\ni=1M\\n2Fi)n1tn\\nn!|b. (D8)\\nIt shows that the number of unitary operators acting on |x(0)\\nis less than4k+11\\n3and the number of unitary operators acting\\non|bis less than4k1\\n3. Thus, the number of required ancilla\\nqubits is about log2(4k+11\\n3)+12k. The solution |x(t)can\\nbe further expressed as\\nx(t)4k+11\\n3\\nm=1CmUm|x(0)+4k1\\n3\\nn=1DnUn|b. (D9)\\nThe parameters CmandDnsatisfy', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='3\\nn=1DnUn|b. (D9)\\nThe parameters CmandDnsatisfy\\nCm={x(0),m=1\\nx(0)(Mt/2)j\\nj!log4(m1)j,j1,2,..., k,\\nDn={bt, n=1\\nb(Mt/2)jt\\nj!log4(n1)j,j1,2,..., k1.\\nSimilarly, by dening C=CmandD=Dn,w e\\nobtain |x(t):\\nC2( 4k+11\\n3\\nm=1CmUm)\\nC2|x(0)+D2( 4k1\\n3\\nn=1DnUn)\\nD2|b.\\nThis alternative approach provides a new way to realize the\\nsolution of any type of LDE.\\nAPPENDIX E: EXPERIMENTAL PROTOCOL\\nIn experiment, the parameters of the target LDE are chosen\\nas follows. Mis chosen as M=II+2Ix. Starting\\nfrom the initial state |, we encode the vector |x(0)by\\napplying a two-qubit operation Uxon|, and the offset\\nvector |bby applying an additional rotation Ubon|.M o r e\\nspecically,\\n|=RA\\ny()RB\\ny()|00,|x(0)=Ux|,|b=Ub|,', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='|=RA\\ny()RB\\ny()|00,|x(0)=Ux|,|b=Ub|,\\nwhere Rj\\ny() denotes a local rotation Rj\\ny()=eij\\ny/2acting\\non qubit jwith angle about the yaxis. The order kin\\nthe Taylor expansion directly determines the accuracy of theapproximate solution x(t). As shown in Fig. 3, we present\\na detailed quantum circuit with four qubits for realizing thesolution x(t).CandDin operations VandWare dened as\\nC=\\nC1+C2,D=\\nD1+D2. (E1)Operations VS1andVS2are chosen as\\nVS1=1\\nC(C1NC2N)\\n,VS2=1\\nD(D1ND2N)\\n.(E2)\\nHere,\\nC1=1+t+5t2\\n2+13t3\\n6+41t4\\n24,\\nC2=2t+2t2+7t3\\n3+5t4\\n3,\\nD1=t+t2\\n2+5t3\\n6+13t4\\n24,D2=t2+2t3\\n3+7t4\\n12.\\nNs are arbitrary elements that make VS1andVS2unitary,\\nwhich can be determined using the Gram-Schmidt method.The other operations are W\\nS1=V', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='S1=V\\nS1and WS2=V\\nS2.T h e\\ncontrolled operation Ucis simplied to the controlled- NOT\\noperation Uc=I(|00|I+|11|x)I.\\nAPPENDIX F: QUANTUM STATE TOMOGRAPHY\\nIn NMR, the measurement is realized by detecting the free-', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='induction decay (FID) signal. When the spins in the detectingcoil remove to the thermal equilibrium, the electric current inthe coil will create and can be detected by the NMR detectorand a time-domain FID signal is induced. We perform Fouriertransformation on the FID signal to extract the information ofspins including the oscillating frequencies and the amplitudesand phases of the transverse magnetization. Hence, we canprocess the experimental spectra such as the tting to measurethe values of the observables. The NMR platform can onlymeasure the expectations of the single-coherent operators; forexample, the observed qubit is the transverse component \\nxor\\nyand the remaining qubits are all zorIwith Pauli matrices', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='x,y, andz. It means that we can also measure other oper-\\nators by some designed readout pulses before the FID signalacquisition and then realize quantum state tomography (QST).For a four-qubit quantum state , it can be decomposed in the\\ncomplete Pauli basis,\\n=\\n3\\ni,j,k,l=0ijklijkl,\\n0=I,1=x,2=y,3=z.ijklis the expectation of\\nthe operator ijkl.I ti s ijkl=Tr(ijkl). QST is a\\nway to determine all the unknown coefcients ijklin the\\nstate. Except for single-coherent operators like xzzz,\\nwe can also measure the high-coherent operators with theassistance of the readout pulses which are /2 rotations on\\nthe qubits. For instance, we need a rotation exp( i/4\\n2\\nx\\ni/43\\nxi/44', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='2\\nx\\ni/43\\nxi/44\\nx) on nonobserved qubits to transfer a de-\\nsired operator xyyyto the detectable single-coherent oper-\\natorxzzz. Obviously, we can design some readout pulses\\nto measure all the coefcients ijklin the QST.\\nIn experiments, these readout pulses are as well realized\\nby the optimized shaped pulses with a numerical delityof about 99.8%. As a result, the nal density matrices offour repeated experiments for every are reconstructed\\nas\\nexptand the average delity 94.64% is obtained. Fig-\\nure7presents the comparison between the reconstructed and\\n032307-11', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 10}), Document(page_content='TAO XIN et al. PHYSICAL REVIEW A 101, 032307 (2020)\\nFIG. 7. The real and imaginary parts of the density matrices exptandthfor ve s. The rst and second rows present the real and\\nimaginary parts of the reconstructed density matrices expt, respectively. The third and fourth rows show the the real and imaginary parts of the\\nideal density matrices th. The average delity between exptandthfor all s is about 94.64%.\\nexpected density matrices for every . The experimental\\nresults have a great agreement with the theoretical density ma-trices and reveal the quantum circuit is precisely implementedin experiments.\\nAPPENDIX G: ERROR ANALYSIS IN EXPERIMENTS\\nThe indelity of the nal density matrix expt(about', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 11}), Document(page_content='5.36%) is attributed to the imperfections of the initial statepreparation, the imprecisions and inhomogeneity of the op-timized pulses, the decoherence effect, and the readout errorin tomography. First, there is about 1.07% error related to theindelity of the initial state preparation after state tomography.Second, the shaped pulses have distortions in practice as thepulse generator has about 5% uctuation in amplitude. Oursimulation gives on average 0.84% error to the indelity of\\nexpt.\\nThe decoherence effect is usually the main error source in\\ncurrent quantum computation. It always makes the dynamicalevolution deviate from the ideal dynamics. To evaluate theinuence of decoherence on our experimental results, we', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 11}), Document(page_content='rst suppose a simple decoherence model where each qubitundergoes an individual relaxation channel after each slice inthe shaped pulses, and then we simulate the dynamics of the\\nTABLE III. Numerical estimation of errors. For every value of\\n, we simulate the indelities FPPS\\n,Finhomo\\n ,Fdecoh\\n,a n d Ftomo\\ncaused\\nby the imperfections of the PPS preparation, the inhomogeneity of\\nthe optimized pulses, the decoherence effect, and the error in state\\ntomography, respectively.\\n 0.1 0.2 0.3 0.4 0.5\\nFPPS\\n 1.070% 1.070% 1.070% 1.070% 1.070%\\nFinhomo\\n 0.859% 0.933% 0.948% 0.864% 0.604%\\nFdecoh\\n 1.272% 1.368% 1.258% 1.163% 0.869%\\nFtomo\\n 1.008% 0.960% 1.056% 1.277% 1.841%\\nFtotal\\n 4.209% 4.331% 4.332% 4.374% 4.384%\\n032307-12', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 11}), Document(page_content='QUANTUM ALGORITHM FOR SOLVING LINEAR  PHYSICAL REVIEW A 101, 032307 (2020)\\nshaped pulses including the decoherence effect for our qubits.\\nIn detail, the time propagator including decoherence modelcan be described as\\nC=C\\nMCM1CmC2C1, (G1)\\nwhere Cmacting on the density matrix means Cm()=\\neiHmeiHm.Hmis the total Hamiltonian of the mth slice and\\nis the duration of each slice. is the combination of the\\nrelaxation channel for each qubit. When a density matrix is\\nfed into such a channel, is changed to\\n()=4321(). (G2)Here, imeans the amplitude damping and phase damping\\nchannel of the ith qubit. According to the above model, the\\nerror caused by the decoherence effect is about 1.19%.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='Another potential error source is the measurement error.\\nThis is usually combined with the spectra tting inaccuracyand is difcult to address. We estimate it by adding a uctu-ation on the measured values of the coefcients (Pauli basis).This error is simulated to be about 1.23% on average.\\nAssuming all errors are additive, the total error estimation\\ngives on average 4.33% (see Table III), which is about 1%\\nsmaller than the indelity of \\nexpt. As the difference is quite\\nsmall, our error estimation is consistent with the experimentalresults.\\n[1] D. Kothe et al. , Science at the petascale 2009: Pioneering\\napplications point the way, National Center for ComputationalSciences (2009), http://www.olcf.ornl.gov/wp-content/uploads/', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='2010/03/PetaDocLowRes2-9-10.pdf (accessed 30 September,\\n2013).\\n[2] P. W. Shor, SIAM Rev. 41,303(1999 ).\\n[3] D. R. Simon, SIAM J. Comput. 26,1474 (1997 ).\\n[4] L. K. Grover, P h y s .R e v .L e t t . 79,4709 (1997 ).\\n[5] A. W. Harrow, A. Hassidim, and S. Lloyd, P h y s .R e v .L e t t . 103,\\n150502 (2009 ).\\n[6] Y . Suba s, R. D. Somma, and D. Orsucci, Phys. Rev. Lett. 122,\\n060504 (2019 ).\\n[7] S. Barz, I. Kassal, M. Ringbauer, Y . O. Lipp, B. Daki c, A.\\nAspuru-Guzik, and P. Walther, Sci. Rep. 4,6115 (2014 ).\\n[8] X.-D. Cai, C. Weedbrook, Z.-E. Su, M.-C. Chen, M. Gu, M.-J.\\nZhu, L. Li, N.-L. Liu, C.-Y . Lu, and J.-W. Pan, Phys. Rev. Lett.\\n110,230501 (2013 ).\\n[9] J. Pan, Y . Cao, X. Yao, Z. Li, C. Ju, H. Chen, X. Peng, S. Kais,', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='and J. Du, P h y s .R e v .A 89,022313 (2014 ).\\n[10] J. Wen, X. Kong, S. Wei, B. Wang, T. Xin, and G. Long, Phys.\\nRev. A 99,012320 (2019 ).\\n[11] Y . Zheng, C. Song, M.-C. Chen, B. Xia, W. Liu, Q. Guo, L.\\nZhang, D. Xu, H. Deng, K. Huang et al. ,P h y s .R e v .L e t t . 118,\\n210504 (2017 ).\\n[12] S. K. Leyton and T. J. Osborne, arXiv:0812.4423 .\\n[13] D. W. Berry, J. Phys. A: Math. Theor. 47,105301 (2014 ).\\n[14] D. W. Berry, A. M. Childs, A. Ostrander, and G. Wang,\\nCommun. Math. Phys. 356,1057 (2017 ).\\n[15] T. Xin, B.-X. Wang, K.-R. Li, X.-Y . Kong, S.-J. Wei, T. Wang,\\nD. Ruan, and G.-L. Long, Chin. Phys. B 27,020308 (2018 ).\\n[16] I. L. Chuang, N. Gershenfeld, and M. Kubinec, P h y s .R e v .L e t t .\\n80,3408 (1998 ).', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='80,3408 (1998 ).\\n[17] J. A. Jones, M. Mosca, and R. H. Hansen, Nature (London) 393,\\n344(1998 ).\\n[18] L. M. Vandersypen, M. Steffen, G. Breyta, C. S. Yannoni, M. H.\\nSherwood, and I. L. Chuang, Nature (London) 414,883(2001 ).\\n[19] X. Peng, Z. Liao, N. Xu, G. Qin, X. Zhou, D. Suter, and J. Du,\\nP h y s .R e v .L e t t . 101,220405 (2008 ).\\n[20] I. L. Chuang, L. M. Vandersypen, X. Zhou, D. W. Leung, and\\nS. Lloyd, Nature (London) 393,143(1998 ).\\n[21] L. M. K. Vandersypen, M. Steffen, G. Breyta, C. S. Yannoni,\\nR. Cleve, and I. L. Chuang, P h y s .R e v .L e t t . 85,5452\\n(2000 ).\\n[22] J. Du, N. Xu, X. Peng, P. Wang, S. Wu, and D. Lu, Phys. Rev.\\nLett.104,030502 (2010 ).[23] G. Feng, G. Xu, and G. Long, P h y s .R e v .L e t t . 110,190501\\n(2013 ).', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='(2013 ).\\n[ 2 4 ]Z .L i ,X .L i u ,N .X u ,a n dJ .D u , P h y s .R e v .L e t t . 114,140504\\n(2015 ).\\n[25] C. Moler and C. Van Loan, SIAM Rev. 45,3(2003 ).\\n[26] L. Gui-Lu, Commun. Theor. Phys. 45,825(2006 ).\\n[27] S. Gudder, Quantum Inf. Process. 6,37(2007 ).\\n[28] A. M. Childs and N. Wiebe, Quantum Inf. Comput. 12,901\\n(2012 ).\\n[29] S.-J. Wei and G.-L. Long, Quantum Inf. Process. 15,1189\\n(2016 ).\\n[30] V . Giovannetti, S. Lloyd, and L. Maccone, Phys. Rev. Lett. 100,\\n160501 (2008 ).\\n[31] V . Giovannetti, S. Lloyd, and L. Maccone, P h y s .R e v .A 78,\\n052310 (2008 ).\\n[32] J. Biamonte, P. Wittek, N. Pancotti, P. Rebentrost, N. Wiebe,\\nand S. Lloyd, Nature (London) 549,195(2017 ).\\n[33] G. H. Golub and C. F. Van Loan, Matrix Computations (Johns', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='Hopkins University Press, Baltimore, 2012), V ol. 3.\\n[34] T. Xin, S.-J. Wei, J. S. Pedernales, E. Solano, and G.-L. Long,\\nPhys. Rev. A 96,062303 (2017 ).\\n[35] D. Lu, T. Xin, N. Yu, Z. Ji, J. Chen, G. Long, J. Baugh, X.\\nPeng, B. Zeng, and R. Laamme, Phys. Rev. Lett. 116,230501\\n(2016 ).\\n[36] J. A. Jones, V . Vedral, A. Ekert, and G. Castagnoli, Nature\\n(London) 403,869(2000 ).\\n[37] T. Xin, S. Huang, S. Lu, K. Li, Z. Luo, Z. Yin, J. Li, D. Lu, G.\\nLong, and B. Zeng, Sci. Bull. 63,17(2018 ).\\n[38] E. Knill, I. Chuang, and R. Laamme, P h y s .R e v .A 57,3348\\n(1998 ).\\n[39] D. G. Cory, A. F. Fahmy, and T. F. Havel, Proc. Natl. Acad. Sci.\\nUSA 94,1634 (1997 ).\\n[40] C. A. Ryan, C. Negrevergne, M. Laforest, E. Knill, and R.', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12}), Document(page_content='Laamme, Phys. Rev. A 78,012328 (2008 ).\\n[41] N. Khaneja, T. Reiss, C. Kehlet, T. Schulte-Herbrggen, and\\nS. J. Glaser, J. Magn. Reson. 172,296(2005 ).\\n[42] O. Moussa, M. P. da Silva, C. A. Ryan, and R. Laamme, Phys.\\nRev. Lett. 109,070504 (2012 ).\\n[43] J.-S. Lee, Phys. Lett. A 305,349(2002 ).\\n[44] G. M. Leskowitz and L. J. Mueller, P h y s .R e v .A 69,052302\\n(2004 ).\\n[45] D. G. Kleinbaum and M. Klein, Logistic Regression (Springer,\\nBerlin, 2010), pp. 103127.\\n[ 4 6 ]C .S h a o ,Y .L i ,a n dH .L i , J. Syst. Sci. Complexity 32,375\\n(2019 ).\\n032307-13', metadata={'source': '/share/lab4/ych/papers/paper5.pdf', 'page': 12})]\n",
      "[Document(page_content='Hindawi Publishing Corporation\\nAbstract and Applied Analysis\\nV olume 2007, Article ID 23282, 6pages\\ndoi:10.1155/2007/23282\\nResearch Article\\nGeneralized Stability of C-Ternary Quadratic Mappings\\nChoonkil Park and Jianlian Cui\\nReceived 10 September 2006; Revised 22 January 2007; Accepted 15 February 2007\\nRecommended by Bruce D. Calvert\\nWe prove the generalized stability of C-ternary quadratic mappings in C-ternary rings\\nfor the quadratic functional equation f(x+y)+f(xy)=2f(x)+2f(y).\\nCopyright  2007 C. Park and J. Cui. This is an open access article distributed under the\\nCreative Commons Attribution License, which permits unrestricted use, distribution,\\nand reproduction in any medium, provided the original work is properly cited.', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 0}), Document(page_content='1. Introduction and preliminaries\\nAC-ternary ring is a complex Banach space A, equipped with a ternary product ( x,y,z)\\n[x,y,z]o fA3intoA, which is C-linear in the outer variables, conjugate C-linear in\\nthe middle variable, and associative in the sense that [ x,y,[z,w,v]]=[x,[w,z,y],v]=\\n[[x,y,z],w,v], and satises [x,y,z]xyzand[x,x,x]=x3(see [ 1]).\\nIf aC-ternary ring ( A,[,,]) has an identity, that is, an element eAsuch that\\nx=[x,e,e]=[e,e,x]f o ra l lxA, then it is routine to verify that A, endowed with x\\ny:=[x,e,y]a n dx:=[e,x,e], is a unital C-algebra. Conversely, if ( A,) is a unital C-\\nalgebra, then [ x,y,z]:=xyzmakesAinto aC-ternary ring (see [ 2]).', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 0}), Document(page_content='Ulam [ 3] gave a talk before the Mathematics Club of the University of Wisconsin in\\nwhich he discussed a number of unsolved problems, containing the stability problem ofhomomorphisms. Hyers [ 4] proved the stability problem of additive mappings in Banach\\nspaces. Rassias [ 5] provided a generalization of Hyers theorem which allows the Cauchy\\ndierence to be unbounded :l e tf:E\\nEbe a mapping from a normed vector space Einto\\naB a n a c hs p a c e Esubject to the inequality\\n\\ued79\\ued79f(x+y)f(x)f(y)\\ued79\\ued79(\\nxp+yp)(1.1)\\nfor allx,yE,w h e r eandpare constants with >0a n dp< 1. Inequality ( 1.1)p r o -\\nvided a lot of inuence in the development of a generalization of the Hyers-Ulam stability', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 0}), Document(page_content='2 Abstract and Applied Analysis\\nconcept. G avrut a [6] provided a further generalization of Hyers-Ulam theorem (see [ 7,\\n8]).\\nA square norm on an inner product space satises the important parallelogram equal-\\nity\\nx+y2+xy2=2x2+2y2. (1.2)\\nThe functional equation\\nf(x+y)+f(xy)=2f(x)+2f(y) (1.3)\\nis called the quadratic functional equation whose solution is said to be a quadratic map-\\nping . A generalized stability problem for the quadratic functional equation was\\nproved by Skof [ 9]f o rm a p p i n g s f:E1E2,w h e r eE1is a normed space and E2is a\\nBanach space. Cholewa [ 10] noticed that the theorem of Skof is still true if the relevant\\ndomainE1is replaced by an Abelian group. Czerwik [ 11] proved the generalized stabil-', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 1}), Document(page_content='ity of the quadratic functional equation, and Park [ 12]p r o v e dt h eg e n e r a l i z e ds t a b i l i t yo f\\nthe quadratic functional equation in Banach modules over a C-algebra. Jun and Lee [ 13]\\nproved the further generalized stability of a Pexiderized quadratic functional equation\\nf(x+y)+g(xy)=2h(x)+2k(y). (1.4)\\nRecently, a xed point approach to the stability of Pexiderized quadratic equation was\\nestablished by Mirzavaziri and Moslehian [ 14].\\nThroughout this paper, assume that Ais aC-ternary ring with norm Aand that\\nBis aC-ternary ring with norm B.\\nA quadratic mapping Q:ABis called a C-ternary quadratic mapping if\\nQ([x,y,z])\\n=[Q(x),Q(y),Q(z)](1.5)\\nfor allx,y,zA.', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 1}), Document(page_content='Q([x,y,z])\\n=[Q(x),Q(y),Q(z)](1.5)\\nfor allx,y,zA.\\nExample 1.1. Let (A,[,,]) be aC-ternary ring derived from a unital commutative\\nC-algebraA,a n dl e tQ:AAsatisfyQ(x)=x2for allxA. It is easy to show that the\\nmapping Q:AAis aC-ternary quadratic mapping.\\nIn this paper, we prove the further generalized stability of C-ternary quadratic map-\\npings inC-ternary rings.\\n2. Stability of C-ternary quadratic mappings\\nWe prove the further generalized stability of C-ternary quadratic mappings in C-\\nternary rings for the quadratic functional equation\\nQ(x+y)+Q(xy)=2Q(x)+2Q(y). (2.1)', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 1}), Document(page_content='C. Park and J. Cui 3\\nTheorem 2.1. Letf:ABbe a mapping for which there exists a function :A3[0,)\\nsuch that\\n\\nj=043j(x\\n2j,y\\n2j,z\\n2j)\\n<, (2.2)\\n\\ued79\\ued79f(x+y)+f(xy)2f(x)2f(y)\\ued79\\ued79B(x,y,0), (2.3)\\n\\ued79\\ued79f([x,y,z])\\n[f(x),f(y),f(z)]\\ued79\\ued79B(x,y,z) (2.4)\\nfor allx,y,zA. Then there exists a unique C-ternary quadratic mapping Q:ABsuch\\nthat\\n\\ued79\\ued79f(x)Q(x)\\ued79\\ued79B(x\\n2,x\\n2,0)\\n(2.5)\\nfor allxA.H e r e ,\\n(x,y,z):=\\nj=04j(x\\n2j,y\\n2j,z\\n2j)\\n(2.6)\\nfor allx,y,zA.\\nProof. If follows from ( 2.3)t h a tf(0)=0. Letting y=xin (2.3), we get\\n\\ued79\\ued79f(2x)4f(x)\\ued79\\ued79B(x,x,0) (2.7)\\nfor allxA.S o\\n\\ued79\\ued79\\ued79\\ued79f(x)4f(x\\n2)\\ued79\\ued79\\ued79\\ued79\\nB(x\\n2,x\\n2,0)\\n(2.8)\\nfor allxA.H e n c e ,\\n\\ued79\\ued79\\ued79\\ued794lf(x\\n2l)\\n4mf(x\\n2m)\\ued79\\ued79\\ued79\\ued79\\nBm1\\nj=l\\ued79\\ued79\\ued79\\ued794jf(x\\n2j)\\n4j+1f(x\\n2j+1)\\ued79\\ued79\\ued79\\ued79\\nBm1\\nj=l4j(x\\n2j+1,x\\n2j+1,0)\\n(2.9)', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 2}), Document(page_content='2j+1)\\ued79\\ued79\\ued79\\ued79\\nBm1\\nj=l4j(x\\n2j+1,x\\n2j+1,0)\\n(2.9)\\nfor all nonnegative integers mandlwithm>l and allxA.I tf o l l o w sf r o m( 2.9)t h a t\\nthe sequence {4nf(x/2n)}is a Cauchy sequence for all xA.S i n c eBis complete, the\\nsequence{4nf(x/2n)}converges. So one can dene the mapping Q:ABby\\nQ(x):=limn4nf(x\\n2n)\\n(2.10)\\nfor allxA.M o r e o v e r ,l e t t i n g l=0 and passing the limit m in (2.9), we get ( 2.5).', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 2}), Document(page_content='4 Abstract and Applied Analysis\\nIt follows from ( 2.3)t h a t\\n\\ued79\\ued79Q(x+y)+Q(xy)2Q(x)2Q(y)\\ued79\\ued79B\\n=limn4n\\ued79\\ued79\\ued79\\ued79f(x+y\\n2n)\\n+f(xy\\n2n)\\n2f(x\\n2n)\\n2f(y\\n2n)\\ued79\\ued79\\ued79\\ued79\\nB\\nlimn4n(x\\n2n,y\\n2n,0)\\n=0(2.11)\\nfor allx,yA.S o\\nQ(x+y)+Q(xy)=2Q(x)+2Q(z) (2.12)\\nfor allx,yA.\\nIt follows from ( 2.4) and the continuity of the ternary product that\\n\\ued79\\ued79Q([x,y,z])\\n[Q(x),Q(y),Q(z)]\\ued79\\ued79B\\n=limn43n\\ued79\\ued79\\ued79\\ued79f([x,y,z]\\n23n)\\n[\\nf(x\\n2n)\\n,f(y\\n2n)\\n,f(z\\n2n)]\\ued79\\ued79\\ued79\\ued79\\nB\\nlimn43n(x\\n2n,y\\n2n,z\\n2n)\\n=0(2.13)\\nfor allx,y,zA.S o\\nQ([x,y,z])\\n=[Q(x),Q(y),Q(z)](2.14)\\nfor allx,y,zA.\\nNow, letT:ABbe another quadratic mapping satisfying ( 2.5). Then we have\\n\\ued79\\ued79Q(x)T(x)\\ued79\\ued79B=4n\\ued79\\ued79\\ued79\\ued79Q(x\\n2n)\\nT(x\\n2n)\\ued79\\ued79\\ued79\\ued79\\nB\\n4n(\\ued79\\ued79\\ued79\\ued79Q(x\\n2n)\\nf(x\\n2n)\\ued79\\ued79\\ued79\\ued79\\nB+\\ued79\\ued79\\ued79\\ued79T(x\\n2n)\\nf(x\\n2n)\\ued79\\ued79\\ued79\\ued79\\nB)\\n24n(x\\n2n,x\\n2n,0)\\n,(2.15)', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 3}), Document(page_content='2n)\\nf(x\\n2n)\\ued79\\ued79\\ued79\\ued79\\nB)\\n24n(x\\n2n,x\\n2n,0)\\n,(2.15)\\nwhich tends to zero as n for allxA. So we can conclude that Q(x)=T(x)f o r\\nallxA. This proves the uniqueness of Q. Thus, the mapping Q:ABis a unique\\nC-ternary quadratic mapping satisfying ( 2.5). \\nTheorem 2.2. Letf:ABbe a mapping for which there exists a function :A3[0,)\\nsatisfying ( 2.3)a n d( 2.4) such that\\n(x,y,z):=\\nj=01\\n4j(2jx,2jy,2jz)< (2.16)', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 3}), Document(page_content='C. Park and J. Cui 5\\nfor allx,y,zA. Then there exists a unique C-ternary quadratic mapping Q:ABsuch\\nthat\\n\\ued79\\ued79f(x)Q(x)\\ued79\\ued79B1\\n4(x,x,0) (2.17)\\nfor allxA.\\nProof. It follows from ( 2.7)t h a t\\n\\ued79\\ued79\\ued79\\ued79f(x)1\\n4f(2x)\\ued79\\ued79\\ued79\\ued79\\nB1\\n4(x,x,0) (2.18)\\nfor allxA.S o\\n\\ued79\\ued79\\ued79\\ued791\\n4lf(2lx)\\n1\\n4mf(2mx)\\ued79\\ued79\\ued79\\ued79\\nBm1\\nj=l\\ued79\\ued79\\ued79\\ued791\\n4jf(2jx)\\n1\\n4j+1f(2j+1x)\\ued79\\ued79\\ued79\\ued79\\nBm1\\nj=l1\\n4j+1(2jx,2jx,0)\\n(2.19)\\nfor all nonnegative integers mandlwithm>l and allxA.I tf o l l o w sf r o m( 2.19 )t h a t\\nthe sequence {(1/4n)f(2nx)}is a Cauchy sequence for all xA.S i n c eBis complete, the\\nsequence{(1/4n)f(2nx)}converges. So one can dene the mapping Q:ABby\\nQ(x):=limn1\\n4nf(2nx)(2.20)\\nfor allxA.M o r e o v e r ,l e t t i n g l=0 and passing the limit m in (2.19 ), we get ( 2.17 ).', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 4}), Document(page_content='It follows from ( 2.4) and the continuity of the ternary product that\\n\\ued79\\ued79Q([x,y,z])\\n[Q(x),Q(y),Q(z)]\\ued79\\ued79B\\n=limn1\\n43n\\ued79\\ued79f(23n[x,y,z])\\n[f(2nx),f(2ny),f(2nz)]\\ued79\\ued79B\\nlimn1\\n43n(2nx,2ny,2nz)\\nlimn1\\n4n(2nx,2ny,2nz)\\n=0(2.21)\\nfor allx,y,zA.S o\\nQ([x,y,z])\\n=[Q(x),Q(y),Q(z)](2.22)\\nfor allx,y,zA.\\nThe rest of the proof is similar to the proof of Theorem 2.1 . \\nRemark 2.3. For a Pexiderized quadratic functional equation\\nf(x+y)+g(xy)=2h(x)+2k(y), (2.23)\\none can obtain similar results to Theorems 2.1and 2.2.', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 4}), Document(page_content='6 Abstract and Applied Analysis\\nAcknowledgments\\nThe rst author was supported by Grant no. F01-2006-000-10111-0 from the Korea Sci-\\nence and Engineering Foundation and the second author was supported by National Nat-\\nural Science Foundation of China (no.10501029), Tsinghua Basic Research Foundation(JCpy2005056), and the Specialized Research Fund for Doctoral Program of Higher Ed-ucation.\\nReferences\\n[1] H. Zettl,  A characterization of ternary rings of operators,  Advances in Mathematics , vol. 48,\\nno. 2, pp. 117143, 1983.\\n[2] M. S. Moslehian,  Almost derivations on C-ternary rings,  Bulletin of the Belgian Mathematical\\nSociety Simon Stevin , vol. 14, pp. 135142, 2007.', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 5}), Document(page_content='[ 3 ] S .M .U l a m , A Collection of Mathematical Problems , Interscience T racts in Pure and Applied\\nMathematics, no. 8, Interscience Publishers, New Y ork, NY , USA, 1960.\\n[4] D. H. Hyers, On the stability of the linear functional equation,  Proceedings of the National\\nAcademy of Sciences of the United States of America , vol. 27, no. 4, pp. 222224, 1941.\\n[5] Th. M. Rassias, On the stability of the linear mapping in Banach spaces,  Proceedings of the\\nAmerican Mathematical Society , vol. 72, no. 2, pp. 297300, 1978.\\n[6] P . G avrut a,  A generalization of the Hyers-Ulam-Rassias stability of approximately additive\\nmappings,  Journal of Mathematical Analysis and Applications , vol. 184, no. 3, pp. 431436,\\n1994.', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 5}), Document(page_content='1994.\\n[7] C. Park, Isomorphisms between C-ternary algebras,  Journal of Mathematical Physics , vol. 47,\\nno. 10, Article ID 103512, 12 pages, 2006.\\n[8] C. Park, Isomorphisms between C-ternary algebras,  Journal of Mathematical Analysis and\\nApplications , vol. 327, no. 1, pp. 101115, 2007.\\n[9] F . Skof, Propriet `a locali e approssimazione di operatori,  Rendiconti del Seminario Matematico\\ne Fisico di Milano , vol. 53, pp. 113129, 1983.\\n[10] P . W. Cholewa, Remarks on the stability of functional equations,  Aequationes Mathematicae ,\\nvol. 27, no. 1, pp. 7686, 1984.\\n[11] St. Czerwik, On the stability of the quadratic mapping in normed spaces,  Abhandlungen aus', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 5}), Document(page_content='dem Mathematischen Seminar der Universit at Hamburg , vol. 62, pp. 5964, 1992.\\n[12] C. Park, On the stability of the quadratic mapping in Banach modules,  Journal of Mathematical\\nAnalysis and Applications , vol. 276, no. 1, pp. 135144, 2002.\\n[13] K.-W. Jun and Y .-H. Lee, On the Hyers-Ulam-Rassias stability of a Pexiderized quadratic in-\\nequality,  Mathematical Inequalities & Applications , vol. 4, no. 1, pp. 93118, 2001.\\n[14] M. Mirzavaziri and M. S. Moslehian,  A xed point approach to stability of a quadratic equa-\\ntion,  Bulletin of the Brazilian Mathematical Society. New Series , vol. 37, no. 3, pp. 361376, 2006.\\nChoonkil Park: Department of Mathematics, Hanyang University, Seoul 133-791, South Korea', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 5}), Document(page_content='Email address :baak@hanyang.ac.kr\\nJianlian Cui: Department of Mathematical Sciences, Tsinghua University, Beijing 100084, China\\nEmail address :jcui@math.tsinghua.edu.cn', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 5}), Document(page_content='Submit your manuscripts at\\nhttp://www.hindawi.com\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014MathematicsJournal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Mathematical Problems \\nin Engineering\\nHindawi Publishing Corporation\\nhttp://www.hindawi.comDifferential EquationsInternational Journal of\\nVolume 2014\\nApplied MathematicsJournal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014\\nProbability and Statistics\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Journal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Mathematical PhysicsAdvances in\\nComplex AnalysisJournal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 6}), Document(page_content='http://www.hindawi.com Volume 2014\\nOptimizationJournal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014\\nCombinatorics\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014International Journal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Operations ResearchAdvances in\\nJournal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Function Spaces\\nAbstract and  \\nApplied Analysis\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014\\nInternational \\nJournal of Mathematics and Mathematical Sciences\\nHindawi Publishing Corporationhttp://www.hindawi.com Volume 2014\\nThe Scientific  \\nWorld Journal\\nHindawi Publishing Corporation \\nhttp://www.hindawi.com Volume 2014', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 6}), Document(page_content='http://www.hindawi.com Volume 2014\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Algebra\\nDiscrete Dynamics in \\nNature and Society\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Decision SciencesAdvances in\\nDiscrete MathematicsJournal of\\nHindawi Publishing Corporation\\nhttp://www.hindawi.comVolume 2014\\nHindawi Publishing Corporation\\nhttp://www.hindawi.com Volume 2014Stochastic AnalysisInternational Journal of', metadata={'source': '/share/lab4/ych/papers/paper6.pdf', 'page': 6})]\n",
      "[Document(page_content='Quantum Path Integral Inspired Query Se quence Suggestion for User Search Task \\nSimplification* \\nBaojun Yue1,2     Jun Yan2     Heng Liang1     Ning Liu2     Lei Ji2     Fengshan Bai1     Zheng Chen2 \\n1Department of Mathematical Science \\nTsinghua University \\nHaidian District, Beijing, P.R.China, 100084 \\nybj07@mails.tsinghua.edu.cn 2Microsoft Research Asia 5F \\nSigma Center, 49 Zhichun Road \\nHaidian District, Beijing, P.R.China, 100190 \\n{junyan, ningl, leiji, zhengc} @microsoft.com  \\n \\nAbstract Query suggestion algorithms, which aim to suggest a \\nset of similar but independent queries to users, have been \\nwidely studied to simplify user searches. However, in many \\ncases, the users will accomplish their search tasks through a', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='sequence of search behaviors instead of by one single query, \\nwhich may make the classical query suggestion algorithms fail \\nto satisfy end users in terms of task completion. In this paper, \\nwe propose a quantum path integral inspired algorithm for \\npersonalized user search behavior prediction, through which \\nwe can provide sequential query suggestions to assist the users \\ncomplete their search tasks step by step. In detail, we consider \\nthe sequential search behavior of a user as a trajectory of a \\nparticle that moves in a query space. The query space is \\nrepresented by a graph with each node is a query, which is \\nnamed as query-path graph. Inspired by the quantum \\ntheorems, each edge in query-path graph is represented by', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='both amplitude and phase respectively. Using this graph, we \\nmodify the quantum path integral algorithm to predict a users \\nfollow-up trajectory based on her behavioral history in this \\ngraph. We empirically show that the proposed algorithm can \\nwell predict the user search behavior and outperform classical \\nquery suggestion algorithms for user search task completion \\nusing the search log of a commercial search engine \\nKeywords- user search session; quantum path ingegral; \\nsearch log; query suggestion; personalization \\nI.  INTRODUCTION  \\nWith the exponential growth of search engine log data, \\nwhich records all interaction information between users and \\nsearch engines, the online recommendation algorithms such', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='as query suggestion algorithms [5, 8, 11, 12, and 23] have \\nbeen widely studied for easing user searches through mining \\nthe user search log data. Most of previous online \\nrecommendation algorithms only suggest relevant but \\nisolated items such as queries and web sites to end users. \\nHowever, many search engine users usually have \\ncomplicated search tasks, such as plan a travel, buy a \\ndigital camera etc., implied in their search queries. These \\ntasks generally need sequences of search behaviors instead of \\nusing a single query to finish. Thus simply recommending \\nisolated items to users may not adequately satisfy users \\nrequirements in terms of task completion. For example,', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='when a user wants to travel to Seattle, she may have several \\nthings to do, such as booking tickets, booking hotel, renting a \\ncar, checking weather of Seattle, understanding attractions of  Seattle and so on. Since this task could not be completed in \\none step using only one group of similar queries, it is desired \\nto provide a method recommending a sequence of queries \\nwith logical relatedness such as Booking tickets to Seattle, \\nbooking hotels in Seattle, Seattle weather etc. so as to \\nmake her search task easier.   \\nThe goal of the paper is to find the logical user query \\nsequence from search engine log data. Instead of suggesting \\nsome similar but isolated queries as previous studies [5, 18,', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='and 21], we hope to provide personalized sequential queries \\nrecommendation. This makes users to complete their \\ncomplicated search tasks more efficiently. To do this, the key \\nchallenge is that it is hard to model the sequential relatedness \\nbetween queries. In detail, the classical query suggestion \\nalgorithms generally use one probability score to measure the \\nrelatedness between two queries [25]. However, there are \\nalways a set of factors that affects the query relatedness, \\nwhich is hard to be modeled by one single measure [15]. In \\naddition, the relatedness could not be transmitted in a query \\nsequence. For example, even though it is observed that query \\nbooking tickets is followed by trip to Seattle with high', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='probability and the query Seattle movie theater show time \\nlist is followed by the query booking tickets with high \\nprobability, it is not guaranteed that the sequence trip to \\nSeattle \\n  booking tickets \\n  Seattle movie theater show \\ntime list is a good sequence to be recommended to the user. \\nMost of classical solutions [5, 8, 11, 12, 15, 18, and 21] for \\nsequential data prediction fail in this application scenario due \\nto these challenges.  \\nWe notice that there is some nature relationship between \\nquery sequence suggestion and quantum path integral \\nmethod, which is helpful to address the above challenges. \\nThe quantum path integral is a very powerful mathematical \\ntool in quantum mechanics introduced by Feynman [9], and', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='it is used to model the moving of microscopic particles. Its \\nkey idea is introducing a complex function with amplitude \\nand phase, instead of one single score, to represent the \\nrelationship between two points. We propose to leverage the \\nmethodology to model the user sequential search behavior \\nand suggest sequential queries with logical to users for task \\ncompletion. Inspired by the idea of quantum path integral, \\nwe consider sequential relationship between queries from \\ntwo aspects. One is the path correlation, which corresponds \\nto amplitude; the other is the semantic content, which \\ncorresponds to phase. A sequence of queries with logical \\n*The work was done when the first author was intern at      \\nMicrosoft Research Asia', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='Microsoft Research Asia \\n2010 IEEE International Conference on Data Mining Workshops\\n978-0-7695-4257-7/10 $26.00  2010 IEEE\\nDOI 10.1109/ICDMW.2010.61647\\n2010 IEEE International Conference on Data Mining Workshops\\n978-0-7695-4257-7/10 $26.00  2010 IEEE\\nDOI 10.1109/ICDMW.2010.61647\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 0}), Document(page_content='relatedness should have both high path correlation (large \\namplitude) and consistent semantic context (small angle \\nbetween phases). \\nIn this paper we leverage the quantum path integral to the \\nscenario of personalized sequential queries recommendation. \\nFirstly a graph named query-path graph is built as the space \\nin path integral. To build this graph, massive log data is \\nmined to define the edges between two queries and obtain \\nthe corresponding amplitude and phase of this edge. In \\naddition, we introduce a schema to calculate the likelihood \\nprobability of a path. Secondly, in order to predict the \\nfollow-up trajectory, we introduce a two-layer optimization \\nalgorithm based on the history of an end user in the graph.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='Considering the complexity of the optimization algorithm, a \\nnumerical simulation algorithm based on Sequence Monte \\nCarlo sampling [8] is proposed. At last, we present a \\npersonalized sequential queries recommendation system \\nbased on the optimal path we predicted.       \\nThe rest of the paper is organized as follows. In Section \\nII, we survey the related works. In Section III, the problem is \\nformulated mathematically. In Section IV, we introduce the \\nmethodology to build the query-path graph and predict user \\nsearch behavior in this graph, and then based on the \\npredicted path we present the personalized sequential queries \\nrecommendation system. Then in Section V, we show the \\nexperimental results. Finally in Section VI, we draw the', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='conclusions and discuss the future works. \\nII. RELATED WORK \\nQuery suggestion has attracted much attention in the past \\ndecades [5, 8, 11, 12, and 23]. Much research efforts have \\nbeen paid to the problem of how to discover effective metrics \\nto measure the relationship between queries. Wen et al. [25] \\nidentify four different types of query distances, based on \\nwhich they propose their clustering method for query \\nrecommendation. Zhang et al [27] firstly present a model to \\nconsider the users sequential search behavior and introduce \\na dumping factor to measure the similarity between two \\nqueries. Fonseca et al. [11] introduce a method to discover \\nrelated queries based on association rules. From a different', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='view point, Goldberg et al. [12], Wang et al. [24] and Xue et \\nal. [26] propose Collaborative Filtering (CF) solutions to \\nprovide item recommendations. However these CF variations \\nfocus on item recommendations, not providing sequential \\npredictions to end users. Based on the document-click data, \\nMei et al. [18] use the hitting time to infer relevant queries \\nbased on random walk. And Cao et al. [5] combine the \\ndocument-click and session co-occurrence to describe the \\nquery similarity with a multi-dimension vector and built a \\nmulti-stage Markov chain for query expansion. Similarly, \\nSadikov et al. [21] also merge the document-click and \\nsession co-occurrence information to generate a clustering', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='technique to provide related queries. Notice the fact that \\nmany search engine users generally have complicated search \\ntasks that require multiple queries to complete; and most \\nclassical query suggestion algorithms that have focused on \\nsingle-step recommendation rather than multi-step sequence \\nsuggestion will fail to help users in terms of task completion. \\nIn this paper, we propose a two-step method to suggest query sequences for user search task completion. The first step is to \\ngenerate a query relation graph mining from user search log. \\nThe second one is user query prediction based on the query \\ngraph.  \\nThough some stream prediction models [16] employ the \\nassociation between frequent episodes and Hidden Markov', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='Models (HMMs) to predict future occurrences of target \\nevents, they are not designed to distinguish intentions for \\nvarious user groups and thus they are not personalized \\nsolutions. Another group of related work is the Markov \\nRandom walk model, which has been used in various \\napplications by calculating transition probabilities on top of a \\nlinked graph [4, 7, 13, 22, and 28]. Baeza-Yates [2] \\nintroduces five different types of graphs, namely, word graph, \\nsession graph, URL cover graph, URL link graph and link \\ngraph. Levene and Loizou [17] describe a Hypertext \\nProbabilistic Automata graph which concentrated on the \\nuser browsing behavior inside a Web site rather than \\nquerying behavior. Boldi et al [3] build a query-flow graph', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='to generate query suggestions with the session co-occurrence \\ndata. However these studies have not been used to provide \\nsequential suggestions on the linked graph. Differently our \\nprediction is based on a query graph inspired with quantum \\npath integral and we optimize the whole path to guarantee \\nthe path has logical relatedness; and our prediction result is \\nnot several isolated queries, but a sequence of queries with \\nlogical to simplify the user search tasks. \\nIII. PROBLEM FORMULATION  \\nNowadays, many commercial search engines can well \\nprovide relevant search results to end users according to their \\nsearch queries in terms of keyword matching. However, \\nmany search engine users may have the requirement to', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='search complicated tasks, such as plan a travel, find a job \\netc., implied in their search queries. It is underexplored that \\nhow to help users to complete their complicated search tasks \\neasily through query suggestions in search engines. Revisit \\nthe example mentioned in Section I, the user search sequence \\nin this case contain booking tickets to Seattle, booking \\nhotel in Seattle, weather forecast in Seattle etc. and these \\nqueries are what we aim to suggest to the user for easing her \\ntask completion. To achieve this goal, we aim to predict what \\nthe user will search for completing a task based on what the \\nuser has already searched and clicked. Inspired by the works \\n[2, 14 and 20], in which a sequence of logical queries is', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='referred with the terms similar information need, mission \\nand logical session, we define a similar concept user \\nsearch path  as a sequence of queries issued by the same \\nparticular user, which are used to complete follow-up step \\ntasks of this user. Thus the problem to be addressed in this \\npaper is given one or more queries of the same user in \\nsequence,  how to effectively predict the sequence of follow-\\nup queries by this user with logical relatedness to suggest to \\nthis user for her search task completion?   \\nIn this paper, we use the search click-through log of a \\ncommonly used commercial search engine for empirical \\nstudies and our notations are mainly influenced by Boldi et', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='al. [3]. Mathematically, the user search log for us to study is \\na set of user behavioral records  \\u0bdc\\u0bdc\\u0bdc\\u0bdc\\u0bdcwhere \\u0bdcis a \\n648\\n648\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 1}), Document(page_content='unique identifier of the user who submitted query \\u0bdc at \\ntime\\u0bdc. \\u0bdc is the set of all search result pages using query \\u0bdc \\nwhile \\u0bdc is the set of clicked ones in this record among all the \\npages in \\u0bdc. Based on this user search log data, a user search \\nsession is a sequence of search queries with clicked \\ndocuments by the same user within a specific time interval, \\ni.e.  \\n                           \\u0bdc\\u0bdc\\u0bdc\\u0bdc\\u0bdc\\u0bde\\u0be1     (1)\\n \\nwhere n stands for the length of this user session. Note we \\nrequire \\u0bdc\\u0bdc\\u0bdc\\u0cd9and\\u0bdc\\u0bdc, where  is \\nthe pre-set timeout threshold for session segmentation. In \\nthis work, we set 3 0  minutes for all the empirical \\nstudies [1].  \\n  Inspired by the quantum path integral theorems, we', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='consider all the queries in the log data as a query space; \\nand for a particular user\\u0bdc, we consider her as a particle \\ntransfers in the space. For a session of this of user\\u0bdc, \\nthe query sequence \\u0bdc\\u0bdc,\\u0bdc\\u0cd9is a trajectory in \\nspace. Assume we are given a prior logical transfer \\ntrajectory \\u0be0\\u0be0\\u0b34of a particular user, then \\nour problem is to predict the follow-up trajectory of this user \\nbased on  in . Mathematically, our problem can be \\nformalized as follows:    \\n                                      max \\u0be3\\n\\u0be3    (2)\\nwhere\\u0b34\\u0bdfand is a given positive integer. \\n \\u0be0\\u0be0,\\u0b34,\\u0bdf ;\\u074c is the \\nlikelihood probability. For each pair  \\u0bdc\\u0bdc,\\n, , \\u0bdc\\u0bdcIn the application of', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content=', , \\u0bdc\\u0bdcIn the application of \\npersonalized query recommendation to simplify user search \\ntasks, we recommend the sequence of queries \\n\\u0b34\\u0bdfto the end user. \\nIV. PREDICT USER SEARCH BEHAVIOR  \\nTo solve the problem formulated in Section III, there are \\ntwo sub-problems we need to address. Firstly, we should \\ndefine the space  in which each user could be considered \\nas a particle and each user query sequence could be \\nconsidered as a trajectory. Secondly, we should optimally \\npredict the follow-up trajectory  in  given the search \\nquery sequence. Accordingly, we divide our solution to \\naddress this problem into two steps. In Subsection A, we \\npropose to define a space to accommodate the user search', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='behaviors. Since the movement of particle, i.e. a user, in  \\nis discrete, the space could be considered as a graph, with \\neach node is a query and in this paper we name this space as \\nquery-path graph. In Subsection B, we propose to optimize \\nthe followed sequence of queries  in (2) to predict the \\nfollow-up behavior of a user. Finally, in Subsection C, we \\nintroduce how to use the prediction results to make the \\nsequential query suggestion to help users to complete their \\nsearch tasks. \\nA. Building Query-Path Graph \\n     In this subsection we introduce our approach for building \\nthe query-path graph. 1) Path Integral and Query-path graph \\nQuantum Path integral was firstly proposed in 1948 by', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='Richard Feynman [9]. Mathematically, path integral is a \\nfunctional integral while the integral variable is paths. For a \\ngiven space and two given points , we denote a \\npath from to as \\u0bd4,\\u0bd5, where is the time. With the \\ntime slicing process [9], the probability amplitude ,  is \\nproportional to a multiply integral. And the probability of a \\nparticle transfer from  to is considered as  |, |, \\nwhere ,  is a complex function which has amplitude \\nand phase. In the spacefor a given trajectory and its \\ninfinite approximation: \\n          \\u0b34\\u0b34,xtx t3) \\nwhere \\u0b34\\u0b34and\\u0be1\\u0be1If we consider a \\ndiscrete system, this probability can be reformulated as: \\n \\n     \\u074c, ,\\u0be1\\u0be1|\\u0bdc\\u0bdc\\u0be1', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='\\u074c, ,\\u0be1\\u0be1|\\u0bdc\\u0bdc\\u0be1\\n\\u0bdc\\u0b34 |  (4)\\n \\nThe view of amplitude, phase and (4) are the major \\nproperties we leverage from quantum path integral to build \\nour query-path graph and optimize the user search path. \\n The query-path graph in our query sequence prediction \\nproblem plays a role that equivalent to the space in \\nquantum path integral theorem. It is the query space the user \\ninteracts with the search engine. Mathematically, we build a \\ndirected query-path graph \\u0be4\\u0be3,,  as follows: \\n The set of nodes iswhere is the full set of \\nqueries used in the search engine; \\n the set of all the directed edges between \\nnode pairs; \\n  0, 1  is the function to describe an edge.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='Note in the quantum path integral theorems, each path \\ncorresponds to a complex value, which consists of amplitude \\nand phase, instead of a single statistical score. Then in the \\nquery path graph, also contains two parts, amplitude and \\nphase. Amplitude is used to describe the strength of the link \\nrelatedness between the two nodes of an edge; and phase is \\nused to represent the semantic content of the edge.  \\nIn the query-path graph, a n-step path  is a sequence of \\ndistinct queries \\u0b34\\u0be1and for each pairwise \\nof\\u0bdc,\\u0bdc, \\u0bdc\\u0bdc.For this path, an amplitude and \\nphase can be defined to model the relatedness \\nbetween\\u0bdc and \\u0bdc. Difference applications may lead to \\ndifferent schema to generate the 0, 1 , and in this', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='paper we introduce a schema as follows: \\n\\n     \\n(5) \\nwhere  is a vector about the amplitude;  is a vector \\nabout the phase. The likelihood probability of a path \\n\\u0b34\\u0be1is defined as: \\n \\n\\u074c\\u0bc4 \\n\\u0cd9\\u0bdc\\u0bdc\\u0be1\\n\\u0bdc\\u0b34 \\u1249\\n\\n\\u0bd8\\u0be5\\u0be0 \\n \\n\\u0bdc \\u0bc4\\u0be4 ,\\u0be4\\u0cc5\\u0bc4\\u0be4\\u0cd4,\\u0be4\\u0cd4\\n|\\u0bc4\\u0be4 ,\\u0be4||\\u0bc4\\u0be4\\u0cd4,\\u0be4\\u0cd4|\\u0bdc\\n\\u0bde \\u0be1\\n\\u0bdc \\n\\u0bd8\\u0be5\\u0be0   \\n \\n \\n(6) \\n649\\n649\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 2}), Document(page_content='where  is a vector with all the elements is 1;\\u0bc4is the \\ndimension of ; || is the 2-norm of a vector. Term2 can \\nbe considered as the average over all the cosine of the angle \\nbetween the phases of \\u0bdc\\u0bdc and the \\u0bde\\u0bde in \\nthe whole path. Only both the term1 (the product of \\namplitude) and the term2 are large, the \\u074c will be large. \\nThis means that if a path has large likelihood probability \\nthen it should have both high link correlation and high \\nconsistent semantic context along the whole path. \\n2) Build Query-path graph based on log data \\nWe first extract the set of user search sessions \\n,\\u0be1 from the search log of a commercial search \\nengine.  For two given queries andthere is an edge', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content=', if and only if there exists at least one session in \\nwithin which appeared just afterIt is to say that: \\n \\n  , \\u05cc\\u0bde\\u0bdc\\u0bde \\u0bdc\\u0bde. \\nAmplitude : We let amplitude corresponds to the strength of \\nthe link relatedness between two nodes of an edge. We \\nemploy the Jaccard similarity coefficient [25], Dice- \\ncoefficient [23], and Levenshtein Distance [19] to \\ndescribe. Jaccard similarity coefficient measures \\nsimilarity between two sets, and is defined as the size of the \\nintersection divided by the size of the union of the two sets. \\nDice-coefficient is a similarity measure related to the Jaccard \\nsimilarity coefficient. Levenshtein Distance is a metric for \\nmeasuring the amount of difference between two sequences.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='In our paper we use it to measure the difference between two \\nqueries while we consider a query as a sequence of \\ncharacters. All these metrics can be calculated from the \\ndocument-click data and the queries content directly.  \\nTo measure the strength of relatedness between two \\nqueries, we also choose several terms generated from session \\nco-occurrence data, such as the co-occurrence frequency of \\nqueries and [3]; the average of exponential of distance \\nbetween  and in the sessions both of them appeared. For \\nbrevity we summarized these metrics in Table I, where \\n,  means the number of times query is followed by \\nquery in a session.\\u074c,  is when in the session \\n\\u0bdc and \\u0bdc\\u0bde.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='\\u0bdc and \\u0bdc\\u0bde.  \\nPhase : We let phase corresponds to the semantic content of \\nan edge. For an edge ,  in the query-path graph, we \\ncollect all the queries\\u0bdc,\\u0bdc, \\u0bdc\\u0bde and \\u0bdc\\u0bde  in all the \\nsessions in which \\u0bdc and  \\u0bdc\\u0bde for some and \\n\\u0d521 . We note all these\\u0bdc,\\u0bdc,\\u0bdc\\u0bde ,\\u0bdc\\u0bde  and , \\nas , . Then we create a word spaces  on all the \\ndistinct queries in the query-path graph. A vector ,  is \\ndefined as follows: \\nTABLE I.  TERMS WE USED TO DESCRIBE A SEARCH QUERY PATH  \\nTerm in \\u0877\\u0ada Summarize\\nTerm1 Jaccard similarity coefficient\\nTerm2 Dice-coefficient\\nTerm3 Levenshtein Distance\\nTerm4 , \\nTerm5 , \\nTerm6 \\u074c\\u074c ,   \\n, \\u0bdc\\n\\u0bdc\\n\\u0cd4, ,\\u074b \\u0bdc, \\n   \\n7)', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='\\u0cd4, ,\\u074b \\u0bdc, \\n   \\n7) \\nwhere , \\u0bdc is the ith term of , ; \\u0bdc is the ith word \\nin spaceand  \\u0bdc is the number of \\u0bdc appeared in \\n,  and \\u0cd4,1 if and only if \\u0bdc, , else \\n0. The ,  is a very high dimension sparsity matrix and \\nwe employ the Latent Semantic Index [8], which has been \\nwidely used for semantic analysis, to reduce the dimension to \\n1000 and we note the mapping of ,  in this lower \\ndimension space as ,  which describe the phase of \\n, . Based on the  and  we can build a query-path \\ngraph for sequential query suggestion. \\nB. Optimize User Search Path \\nIn the graph\\u0be4\\x1f,, , a user may transfer from', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='one query to another when there is an edge between these \\ntwo queries. Given a prior logical search session  of one \\nparticular user, the optimization problem is presented in (2). \\nActually in such a graph \\u0be4\\u0be3 its hard to find the global \\noptimal  because the complexity to find all the paths \\nstarting from a query is proportional to the exponential of the \\nnumber of paths in the query-path graph and the given path \\nlength of .  \\nIn our paper we proposed an efficient approximate \\nalgorithm. Assume a threshold is given to represent the \\nminimum confidence we can accept for the predict search \\npath.  For ease to reference we note the length of  \\nas, and when\\u0b34\\u0be1The', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='as, and when\\u0b34\\u0be1The \\nproblem to find the optimal search path  can be formulated \\nas a two-layer optimization problem as follows: \\n \\n:   \\n\\u0be1  \\u0be3\\n\\u0be3        \\nm a x\\n\\u0cba  \\n(8) \\n:   \\n                    | \\n \\n                   m a x\\n\\u0cba\\u0cba\\u074c|  \\n(9) \\nIn our paper we proposed an efficient numerical simulation \\nsolution based on Sequence Monte Carlo Sampling (SMC) \\n[8]. In detail of our problem, assume we have been given  \\nand we have simulate a step follow-up path  \\u0b34\\u0bde ,\\nthen we aim to simulate the \\u0d451  query based on  \\nand \\u0b34\\u0bdeTo efficiently simulate the user behavior, \\nwe consider a two-step simulation process based on SMC.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='SMC Simulation : For a node we note the child nodes \\nof as. For each, we also collect all the \\nchild nodes of  as. For each we define \\nan index as: \\n                         , \\n\\u074c\\u0bc4,  (10)\\n650\\n650\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 3}), Document(page_content='where \\u074c\\u0bc4, \\u0bbc \\u0bbc\\u0be4  is normalized \\nfactor. Mathematically the ,  in (10) is a probability \\ndistribution function with respect all possible and, and \\nw e  d e n o t e  i t  a s. Consider the (2), the condition \\nprobability \\u074c\\u074c   can be calculated as follows: \\n              \\u0be3\\n\\u0be3\\u0be3\\n\\u0be3 (11)\\nwhere\\u0be0\\u0be0\\u0b34and\\u0b34\\u0bdf ;\\u074c\\u0bc4 \\nis the likelihood probability defined in (6). The simulation \\nprocess is Fig.1.  \\nThe complexity of this simulation algorithm is less than \\nONl o gN  if we calculate the distribution function fq \\noffline and the maximum length of  SN  (actually this \\nassumption always holds because we take Nmore than 10', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='magnitude while the length of  S is only 10 magnitude). \\nOur algorithm can be scaled up easily and thus is feasible to \\nreal world applications. \\nC. Personalized Query Sequence Suggestion \\nIn this section we describe the details of a personalized \\nquery recommendation system. For an end user, we extract \\nthe prior history firstly.  Because sometimes the users \\nprocess more than one task in a session, and if we use the \\nsession data directly, the predict result will be affected with \\nthe irrelevant information. This topic is interesting and hard \\nto solve. In the work [3] they have proposed some \\nmeaningful solutions. In our paper we take a solution to \\nsolve this problem based on the principle to optimize the user', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='Input: \\u0be4\\u0be3,,   \\nOutput:  \\nParameter:  Sample times and threshold  \\nSimulation: \\n \\u074b  \\n   Initialization : \\u0bdc\\u0b34 ,1 . \\n   do while pK\\u0bdcSpKS\\u0d50   \\n1. Choose \\u0bde\\u0bde and \\u0bde\\u0bde with \\nrespect\\u0bde. \\n2. Update \\u0bdc as: \\u0bdc\\u0bdc\\u0bde\\u0bde \\n3.  \\u074c\\u0bc4\\u0bdc\\u074c\\u0bc4\\u0d50  \\n   \\u0d452 ; \\n     \\u074b\\u074b1. \\n :\\n   \\u074c   \\u0bc4\\u0bdc\\n\\u0bde\\u074c\\u0bc4                   \\n          :\\u0bdc\\n\\u0bde   . \\n                       \\u0bdc\\n\\u0bde\\u0bde    \\n    \\u0d45\\u0d45 ; \\n  \\n \\n \\nChoose the paths with the longest length, and then pick the path with the \\nlargest \\u074c\\u0bc4\\u074c\\u0bc4   as   \\n \\nFigure 1.  2-step SMC numerical simulation solution. search path in the query-path graph. For a prior history', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='before the query \\u0b34 of one particular user, firstly we remove \\nall the queries have no path connected with\\u0b34 within several \\nsteps (we take it 5 steps), and in the remaining queries we \\nreorder them in accordance with the various possible \\npermutations. For each possible permutation in graph \\u0be4\\u0be3 \\nwe calculate the \\u074c\\u0bde in (6). Then we find the permutation \\nwhich has the maximum value and consider this permutation \\nas. At last we numerical simulate to optimize  based on \\nthe algorithm in Fig.1 and consider it as the sequential \\nsuggested queries. \\nV. EXPERIMENTS  \\nIn this section, we empirically show the power of our \\nproposed solution in predicting and suggesting query \\nsequences to users to help them complete their search tasks.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='In Subsection A, we introduce the experimental \\nconfiguration, which includes dataset, baseline algorithms, \\nevaluation metrics etc. In Subsection B, we show the \\nexperimental results with sensitivity analysis to parameters. \\nIn Subsection C, we use a set of case studies to intuitively \\nshow the effectiveness of our proposed solution. \\nA. Experimental Settings \\nDataset: In this work, we extract one month click-through \\nlog from a commonly used commercial search engine. We \\nuse the unique user ID to distinguish different users and we \\nhave no other user information available in the data to avoid \\nthe privacy issues. We filter out all the queries with traffic \\nsmaller than 2 and filter out all the users with smaller than 5', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='queries. We extract user search sessions from this dataset and \\nuse the 30 minutes time out rule to segment sessions. Finally, \\nwe collected about 10 million user search sessions with 3.5 \\nmillion different clicked Web pages and 0.48 million unique \\nqueries. Using the session data, we have 4.7 million edges \\nafter building the query-path graph.  \\nEvaluation metrics: In the experiments, we aim to measure \\nthe results from two different perspectives. Firstly, we show \\nhow accurate we can predict the users search behaviors. \\nAfter that, based on the prediction results, we want to show \\nhow much help the sequential query suggestion can help \\nusers to complete their search tasks. Thus in the first', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='experiment, the evaluation metrics are the classical Precision \\n(Pre), Recall (Rec) and F-score, where: \\n \\u0be3\\n\\u0be3\\u0bd9\\u0be3     \\u0be3\\n\\u0be3\\u0bd9\\u0be1    \\u0bc9\\u0be5\\u0bd8\\u0bd8\\u0bd6\\n\\u0bc9\\u0be5\\u0bd8\\u0bd8\\u0bd6 (12)\\n \\nwhere \\u074cis true-positive cases, \\u074cis false-positive cases and \\nis false-negative cases. \\n     In addition, we ask volunteers to provide feedback on \\ntheir satisfaction to our sequential query suggestion results \\nthrough ratings; and the average user feedback rating is \\nconsidered as an evaluation metric to evaluate the \\nperformance of the suggested queries. \\n651\\n651\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 4}), Document(page_content='Baselines: We choose three classical algorithms as baselines, \\nwhich are the memory based Collaborative Filtering (CF) \\nalgorithm [24], query-flow graph [3] algorithm and Random \\nWalk algorithm [18] respectively. Notice that all these \\nbaselines only suggest a group of isolated queries, in order to \\nmake them comparable with our algorithm, we temporarily \\nremove the order information in our results when compare \\nthem together in results validation. \\nB. Personalize Query Recommendation \\n       In this subsection, we show the experimental results for \\nquery suggestion. Here, we implement two groups of \\nexperiments, which are the true user behaviors against the \\npredicted user search behaviors and user feedback rating to', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='the suggested query sequence to users.  \\n1) User Search Behavior Prediction \\n      In this experiment, for a user and a query issued by  \\nin a sessionwe compare the true behavior of after query \\nin and the suggested queries by our algorithm and the \\nbaselines. For each query belongs to the suggest queries, if \\nit appears in afterthen its a true-positive (\\u074ccase. If  \\ndoes not appear in afterthen its a false-positive (\\u074c )\\ncase; If a query appeared after in S but not belong to the \\nsuggest queries, then its a false-negative (case. \\nOtherwise, it is the true-negative (Based on those \\nstatements in (12) we can calculate the Pre, Rec and. For \\neach session, we choose a query in the middle of this session', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='as\\u0b34, and then we implement the personalized sequence \\nrecommendation algorithm. The experimental results are \\ngiven in Table II. From Table II we can observe that out \\nalgorithm has about 48%, 12% and 14% lift compare with \\nCF, query-flow and random walk separately in terms of F1 in \\naverage. All the algorithms performance poor in the user \\ntruly search behavior prediction because the user search \\nbehavior is always really very hard to model exactly.  \\n \\n2) User feedback rating \\n      We have asked 20 volunteers to help provide feedback \\nfor the sequential query suggestion results. Each volunteers \\nmay select to have one to five different search tasks, which \\nare plane a travel, buy digital camera, find local information,', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='search mathematical knowledge, and food recipes,  in their \\nown scenarios. We asked them to give the feedback to the \\nprovide suggestions by different algorithms for about 1,000 \\ndistinct input queries. For each query and the suggested \\nresults of different algorithms, we ask the volunteers to give \\na rate from 0 to 5 for the results where rate 5 means very \\nuseful for their task completion and 0 means useless at all. \\nThe larger the number, the more satisfied the user is. We use \\nthe average rating scores for each algorithm for comparison \\npurpose. The experimental result is in Table III. In this table, \\nwe can observe that our query-path algorithm has 11.18%, \\n6.78% and 3.85% improvement compare with CF, query-', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='flow and random walk separately.  \\n3) Sensitivity Analysis for Parameter Setting \\n     To analyze the performance of our proposed algorithm to \\nthe thresholdwe take different values of the threshold to \\n TABLE II.  USER SEARCH BEHAVIOR PREDICTION RESULTS  \\nAlgorithm Pre Rec F1\\nCF 0.118 0.012 0.327 0.017 0.173 0.015 \\nQuer y-flow 0.191 0.009 0.279 0.014 0.227 0.013 \\nRandom Walk 0.181 0.013 0.291 0.008 0.223 0.011 \\nQuery-path 0.216 0.011 0.315 0.007 0.256 0.009 \\n \\nTABLE III.  USER RATING TO THE SUGGEST QUERIES OF DIFFERENT \\nALGORITHMS  \\nAlgorithm Efficient  \\nCF 3.40.06 \\nQuery Flo w 3.54 0.08 \\nRandom Walk 3.64 0.05 \\nQuery Path 3.78 0.05 \\n \\nimplement the experiment in 1) of Subsection B. The', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='experiment result is given in Fig.2. This result shows that the \\nthreshold  is important for the performance of our \\nalgorithm. When we set 0 . 6  we can get the best \\nperformance in our work. \\nTo analyze the convergence of our algorithm in \\noptimizing the search path, we take different values of to \\nimplement the algorithm on about 0.1M queries.We calculate \\nthe global optimal solution  in offline mode with the \\nenumeration algorithm. For the simulation solution, \\nwe calculate the distance between  and  using \\nLongest Common Subsequence (LCS) [6] as follows:    \\n                       \\u0bc5\\u0bbc \\u0be4,\\u0be4\\n\\u0bc5\\u0bd8\\u0be1\\u0bdb \\u0be4  (13) \\nwhere , is the length of the longest common', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='subsequence;   is the length of the sequence. We \\ntake the average  over the 0.1M queries as \\nthe evaluation metric. The smaller the average \\n , the better the simulation solution. The \\nresult is given in Fig.3. \\n \\nFigure 2.  F1 value vs. threshold  .\\n  \\n \\nFigure 3.  Convergence of the Sequence Monte Carlo Sampling algorithm \\nto optimize the search path. \\n 00.10.20.3\\n0 0.2 0.4 0.6 0.8 1F1\\nthreshold \\n00.20.40.60.8\\n0 2000 4000 6000 8000 10000Average distance\\nsample size N\\n652\\n652\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 5}), Document(page_content='Figure 4.  The average of  with respect 100 times of \\nexperiments when take 5000 . \\nFrom Fig.3 we can identify that our simulation algorithm \\nconverge to the global optimal solutions. And when\\n5,000 , the average distance is 0.1. With the growth of  \\nafter 5,000, the average distance decreases slowly. \\nFurthermore, to identify the stability of our simulation \\nalgorithm, we hold 5,000  and run 100 times of this \\nexperiment. The result is in Fig.4. From this figure we can \\nsee that in our algorithm the average distance varies in a \\nsmall area near 0.1.  Statistically, we assume the average \\ndistance is 0.1 and use the t-test [10] to verify the statistical \\nsignificance of the results, the P-value is 0.489 ', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='\\u0b34.\\u0b34,\\u0b34\\u0b34 1 . 6 5  under the confidence 0.95, which means \\nthe variation of average distance in our algorithm is not \\nsignificant with 0.1. Then we can identify that our algorithm \\nis stability in a statistical viewpoint.   \\nC. Case Studies \\nSince the baseline algorithms used in this paper can only \\nsuggest independent query sets instead of query sequences, \\nwe remove the sequential information from the results of our \\nproposed algorithm for comparison purpose in previous \\nsections. In this subsection, we use the case studies to show \\nthe suggested query sequences with detail sequential \\ninformation.   \\nIn Table IV and Table V we give two cases to compare \\nthe results of CF, Query-flow, Random walk and our Query-', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='path algorithm. These cases show that we can suggest more \\nlogical relatedness sequential queries to help user simplify \\ntheir tasks. For example, in the case of  sports in Tampa  in \\nTable IV, we can suggest outdoors, health, restaurant and \\nhotel in Tampa, etc., we can also suggest related tasks about \\nSeattle based on the user search history. In the case of cheap \\ntickets in Table V, we can observe the marked improvement \\nof our recommendation system. In our suggested sequential \\nqueries, we not only suggest those queries highly related to \\ncheap tickets, we can also suggest the user to view the \\nmap, car rental, booking hotel, check weather, etc.. Even \\nthough the suggested queries of baselines are high related to', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='cheap tickets, always they only can help user to \\naccomplish the task to buy cheap tickets. In Table VI - VII \\nwe show more cases of our algorithm, from which we can \\nobserve the logical relatedness in the suggested sequential \\nqueries and our algorithm indeed depend on the user history. \\nVI. CONCLUSIONS  \\nIn this paper, we present a novel quantum path integral \\ninspired approach to provide personalized sequence of logical relatedness queries recommendation for end-users. \\nThe query-path graph is constructed using user search logs. \\nUsers search experience is improved by providing a \\nsequence of recommendations based on the graph. The \\nalgorithm is lightweight and can be ease to scale up.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='Experimental results show that our personalized \\nrecommendation system has good performance to simplify \\nthe users complicated search tasks. \\nIn future, we plan to investigate further approaches for \\nquery-path graph construction and user behavior prediction. \\nFor example, we will consider utilizing the whole framework \\nof quantum path integral to model the user search behavior. \\nMining more valuable terms to describe the amplitude and \\nphase of edges of the query-path graph will be considered \\nalso in future. We believe that the usefulness of quantum \\npath integral goes beyond this application in the Information \\nRetrieval area. \\nACKNOWLEDGMENT  \\nWe thank the anonymous reviews for their valuable', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='comments. This work is in part supported by a Microsoft \\nBing Search Grant. \\nREFERENCES  \\n[1] M. Arlitt. CharacterizingWeb User Sessions. In Proceedings of the \\nPerformance and Architecture of Web Servers Workshop, Santa \\nClara, CA, June 2000. \\n[2] R. Baeza-Yates. Graphs from search engine queries. In Theory and \\nPractice of Computer Science (SOFSEM), volume 4362 of LNCS, \\npages 18, Harrachov, Czech Republic, January 2007. Springer. \\n[3] P. Boldi, F. Castillo, C. Donato, D. Gionis, A. Gions, and S. Vigna. \\nThe query-flow graph: Model and applications. In Proceedings of the \\nACM 17th Conference on Information and Knowledge Management \\n(CIKM 2008). \\n[4] S. Brin and L. Page. The anatomy of a large-scale hypertextual web', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='search engine. In Proceedings of the Seventh International World \\nWide Web Conference, 1998. \\n[5] H.-H. Cao , D.-X. Jiang , J. Pei , Q. He , Z. Liao , E.-H. Chen, and H. \\nLi. Context-aware query suggestion by mining click-through and \\nsession data. In Proceeding of the 14th ACM SIGKDD international \\nconference on Knowledge discovery and data mining, August 24-27, \\n2008, Las Vegas, Nevada, USA. \\n[6] V. Chvtal and D. Sankoff. Longest common subsequences of two \\nrandom sequences. Journal of Applied Probability, 12:306315, 1975. \\n[7] N. Craswell and M. Szummer. Random walks on the click graph. In \\nProceedings of the 30th annual international ACM SIGIR conference, \\n2007, Amsterdam, the Netherlands.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='2007, Amsterdam, the Netherlands. \\n[8] S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer, and R. \\nHarshman. Indexing by latent semantic analysis. Journal of the \\nAmerican Society for Information Science. 41(6):391-407,1990. \\n[9] R .  P .  F e y n m a n  a n d  A .  R .  H i b b s .  P a t h  I n t e g r a l s  a n d  Q u a n t u m  \\nMechanics. McGraw-Hill, 1965, pp 1-40. \\n[10] B. Fisher and Joan. Guinness, Gosset, Fisher, and Small Samples. \\nStatistical Science 2 (1): 4552, 1987. \\n[11] B. M. Fonseca, P. B. Golgher, E. S. de Moura, and N. Ziviani. Using \\nassociation rules to discover search engines related queries. In \\nProceedings of the First Latin American Web Congress, Washington, \\nDC, USA, 2003. IEEE Computer Society.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='DC, USA, 2003. IEEE Computer Society. \\n[12] D. Goldberg, D. Nichols, M. Brain, and D.T. Oki. Using collaborative \\nfiltering to weave an information tapestry. Communications of the \\nACM 35 (12): 6170. \\n[13] T.H. Haveliwala. Topic-Sensitive PageRank: A context-sensitive \\nranking algorithm for web search. In Proceedings of the 11th 00.20.40.60.81\\n0 2 04 06 08 0 1 0 0Average Distance\\nExperiment Number\\n653\\n653\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 6}), Document(page_content='international conference on World Wide Web, May 07-11, 2002, \\nHonolulu, Hawaii, USA. \\n[14] R. Jones and K. L. Klinkner. Beyond the session timeout: automatic \\nhierarchical segmentation of search topics in query logs. In \\nConference on Information and Knowledge Management (CIKM). \\nACM Press, October 2008. \\n[15] C.T. Kevyn and J. Callan. Query expansion using random walk \\nmodels. In Proceedings of the 14th ACM international conference on \\nInformation and knowledge management, October 31-November 05, \\n2005, Bremen, Germany. \\n[16] S. Laxman, V. Tankasali, and R.W.White. Stream prediction using a \\ngenerative model based on frequent episodes in event sequences. In \\nProceeding of the 14th ACM SIGKDD international conference on', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='Knowledge discovery and data mining, August 24-27, 2008, Las \\nVegas, Nevada, USA. \\n[17] M. Levene and G. Loizou. A probabilistic approach to navigation in \\nhypertext. Inf. Sci., 114(1-4):165186, 1999. \\n[18] Q. Mei , D. Zhou, and K. Church. Query suggestion using hitting \\ntime. In Proceeding of the 17th ACM conference on Information and \\nknowledge management, October 26-30, 2008, Napa Valley, \\nCalifornia, USA. \\n[19] T. Okuda, E. Tanaka, and T. Kasai. A method for the correction of \\ngarbled words based on the Levenshtein metric. IEEE Trans. on \\nComputers, vol. C-25, no. 2, February1976, pp. 172-176 \\n[20] F. Radlinski and T. Joachims. Query chains: learning to rank from', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='implicit feedback. In KDD 05: Proceeding of the eleventh ACM SIGKDD international conference on Knowledge discovery in data \\nmining, pages 239248, New York, NY, USA, 2005. ACM Press. \\n[21] E. Sadikov, J. Madhavan, L. Wang, and A. Halevy. Clustering query \\nrefinements by user intent. In Proceeding of the 19th International \\nWorld Wide Web Conference, WWW 2010. \\n[22] J. Sakuma and S. Kobayashi. Link Analysis for Private Weighted \\nGraphs. In Proceedings of the 32nd international ACM SIGIR \\nconference (2009), page 235-242. \\n[23] G. Salton and M.J.  Mcgill. Introduction to Modern Information \\nRetrieval. McGraw-Hill New York, NY,  1983. \\n[24] J. Wang, A. de Vries, M. Reinders. A User-Item Relevance Model for', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='Log-Based Collaborative Filtering. LNCS3936 (January 2006), pp. \\n37-48. \\n[25] J.-R. Wen, J.-Y. Nie, and H.-J. Zhang. Clustering user queries of a \\nsearch engine. In Proceedings of the 10th international conference on \\nWorld Wide Web, pages 162168, New York, NY, USA, 2001. \\nACM. \\n[26] G.R. Xue, C. Lin, Q. Yang, W. Xi, H.-J. Zeng, Y. Yu, and Z. Chen. \\nScalable collaborative filtering using cluster-based smoothing. In \\nProceeding of the SIGIR, 2005 \\n[27] Z. Zhang and O. Nasraoui. Mining search engine query logs for query \\nrecommendation. In Proceedings of the 15th international conference \\non World Wide Web, pages 10391040, New York, NY, USA, 2006. \\nACM. \\n[28] G. Zoltn, H. Garcia-Molina, and J. Pedersen. Combating Web Spam', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='with TrustRank. In Proceedings of the 30th VLDB Conference, \\nToronto, Canada, 2004. \\nTABLE IV.  CASE OF QUERY =SPORTS IN TAMPA   \\nmuseum in Seattle  Seattle realtor business in Seattle sports in Tam pa \\nQuery-Path CF Query-flow Random Wal k \\noutdoors in Tampa  \\nhealth in Tampa  \\nrestaurant in Tampa  \\nTampa sports bars  \\nhotel in Tampa  \\ncar rental agency in Tampa  \\nTampa health market  \\nsports in Seattle  \\nhotel in Seattle  \\nfamous basketball club in Seattle; free online football games; \\nhealth in Tampa; \\nentertainment in Tampa; \\nTampa ballet; \\nfacebook login; \\nTampa hotels; \\nTampa optometrist \\n health in Tampa; \\noutdoors in Tampa; \\nTampa storm; \\nNeffs; \\nTampa west shore plaza shops; \\nColorado hotels;', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='Tampa west shore plaza shops; \\nColorado hotels; \\nTampa massage; hotel in Tampa; \\nTampa health market; \\nTampa seafood restaurants; \\nentertainment in Tampa; \\nTampa ballet; \\nTampa best westerns; \\nTampa storm; \\nTABLE V.  CASE OF QUERY = CHEAP TICKETS . \\nairline travel  Las Ve gas famous  chea p tickets  \\nQuery-Path CF Query-flow Random Wal k \\nUS airways  \\nUnited States map  \\nLas Vegas map  \\nrental car in Las Vegas  \\nweather in Las Vegas  \\nLas Vegas hotels  \\nsouth beach hotels; Alligent Air; \\nAmerican airlines.com; \\nCanada airports; \\nvacation location; \\ncheapair.com; \\ncheapest airline tickets; United airlines.com;\\nairplane tickets; \\ntravel city; \\nairline tickets; \\nexpedia; \\ncheap flights; airline tickets; \\nair fares;', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='cheap flights; airline tickets; \\nair fares; \\ncheap tickets reservations; \\nBahamas airlines; \\nbooking buddy; \\ncheap hotel deals; \\ncheap tickets discount codes; \\nTABLE VI.  CASE OF QUERY = BOOKING TICKETS .                         \\nlocal weather  movie  \\nbooking tickets liberty travel  continental \\nairlines  booking tickets \\nmovie times  \\nlocal movie theater show times  \\nlocal movie theater listing  \\nregal cinemas  \\ndear  john;  cheap tickets  \\nweather  report  \\nhotels  \\nbooking hotel  \\nshort term apartments rental; \\n \\n TABLE VII.  CASES OF QUERY =APPLE . \\ngrapes  currant  apple ipad blackberry apple \\napple pie recipe  \\nlemon  \\nbanana fruit   \\nlocal fruit market  \\ndinner party recipes; YouTube videos  \\niphones ', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7}), Document(page_content='iphones  \\nmusic download  \\nfree online games  \\nfree movie; \\n \\n654\\n654\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:20 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper7.pdf', 'page': 7})]\n",
      "[Document(page_content='PaperRank: A Ranking Model for Scientic Publications\\nMingcui Du, Fengshan Bai\\nDepartment of Mathematical Sciences\\nTsinghua University, Beijing, ChinaYushen Liu\\nTsinghua University, Beijing, China\\nAbstract\\nThe idea of HITS and PageRank models, which are well\\nknown in web mining, can be used in ranking scientic pub-\\nlications by noting the similarity of World Wide Web and\\nthe scientic citation networks. PaperRank, an extension of\\nHITS and PageRank model, is introduced in this paper to\\nevaluate the scientic publications. It retrieves the indirect\\nrelationships between papers using relativity measurements\\nin stead of the simple direct citations between papers. The\\nnew method provides more valuable knowledge by control-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='ling the relativity functions and weights. The experimental\\nresults on a large set of papers in biology show that the pro-\\nposed method can nd more authoritative papers than those\\napproaches based on the traditional methods. The Paper-\\nRank can be considered as an efcient complementary tool\\nfor ranking scientic publications.\\nKeywords: citation, ranking, web of science, PaperRank,\\nPageRank, HITS\\n1. Introduction\\nWith the rapid development of the Internet technology\\nand the growth of the scientic publications, the way that\\nwe use library has been changed a lot during the last decade.\\nWith so much digital information, a correct evaluation and\\neffective ltering of academic papers have received a perva-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='sive attention. But the importance or the ranking of a paper\\nis obscure. A reliable method to evaluate qualities of papers\\nis peer review by experts. Apparently, there is no way of\\nobtaining a fast and objective ranking for a huge amount of\\npapers. In all the rigorous scientic research papers, there\\nare always some papers or books that are cited as references\\nto supporting the concepts or ideas presented in them [9].\\nThese cited references are very valuable to lead the readers\\nand scholars to the sources of knowledge. Hence citations\\ngive credits to the works in the reference list. Citation in-\\ndices can be used to nd or select qualitative papers. The\\nCurrent address: Beijing Municipal Bureau of Statistics', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='Email address: fbai@math.tsinghua.edu.cnmost popular citation analysis method is probably the Sci-\\nence Citation Index (SCI).\\nCitation analysis is used in searching for materials and\\nanalyzing their merit [9]. A common method is to use ISI\\nJournal Impact Factors [9], which are simply the average ci-\\ntation frequency of articles published in the serial [4]. How-\\never, the impact factor only ranks journals and can hardly\\ngive a reasonable ranking for each individual paper. An-\\nother simple method is to count the number of cited papers,\\nand Gareld [10] suggested that citation data may be useful\\nas quantitative indicators of the impact of particular publi-\\ncations on the literature. It ranks research papers accord-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='ing to the number of direct citations received inside the ISI\\ndatabase [8]. However that a paper is cited more is not the\\nkey. The most important issue is that who cited. The num-\\nber of cited papers for a paper does not consider the status\\nand the prestige of a paper, and so it is easy for being af-\\nfected by some invalid citations.\\nExample 1 Consider a paper by MS Brown and JL Gold-\\nstein published in Science in 1986. Its citation numbers\\n(199) are not very high. However this work led its authors\\nto the Nobel Prizes in 1985!\\nLarry Page and Sergey Brin [18] developed the PageR-\\nank model for Google search engine [3], which can effec-\\ntively rank the web pages by considering both a high usage', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='and a collaborative notion of trust [18]. Readers may con-\\nsult [5, 12, 13, 17] for detailed expositions, and [16, 21] for\\ntechniques related. Kleinberg [11] developed another in-\\nteresting model for web mining, called HITS. Lempel and\\nMoran [14] combined the ideas of HITS and PageRank and\\npropose the SALSA algorithm. The web information re-\\ntrieval models, such as PageRank [18] and HITS [11], only\\nuse link structure. Similarly the scientic publications natu-\\nrally form a network based on the citation relationship. The\\nstandard PageRank and HITS models can be used in pa-\\nper ranking. They can do well for the direct relationships,\\nwhereas it fails to retrieve indirect citation, co-citation, and', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='co-reference, which are feasible in the world wide web\\ncircumstance. However, the interdependent relationships\\namong papers are much tiger than that in pages. Paper-to-\\n2009 World Congress on Computer Science and Information Engineering\\n978-0-7695-3507-4/08 $25.00  2008 IEEE\\nDOI 10.1109/CSIE.2009.479282\\n2009 World Congress on Computer Science and Information Engineering\\n978-0-7695-3507-4/08 $25.00  2008 IEEE\\nDOI 10.1109/CSIE.2009.479277\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:26 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 0}), Document(page_content='paper includes plenty of indirect citations, co-citation, and\\nco-reference that can not be ignored. Recently, Sidiropou-\\nlos et al. [19] also investigated a method for ranking scien-\\ntic publications by slightly improving PageRank, and the\\nmethod is also tested in the SCEAS system.\\nIn this paper, our goal is to identify the most central and\\ncorrelation papers for broad search topics in the context of\\nscientic papers as a whole. We propose a novel model\\nfor paper citation ranking and selection by using relativity\\nmeasurements , which associate both direct and indirect re-\\nlationships in scientic papers. It is called PaperRank .O u r\\nmethod can provide more valuable knowledge by control-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='ling the relativity function and weights. The relativity ma-\\ntrix reects the rule relationships between papers.\\n2. PaperRank model\\nWe can also regard any collection of scientic papers as\\na directed graph consisting of nodes and directed edges. In\\nthis graph, each node corresponds to a paper, and a directed\\nedge eijdenotes a citation from paper ito paper j. Suppose\\nthe focused graph of papers contains npapers. Based on the\\ngraph, let Gbe the n-by-nadjacency matrix, that is gij=1\\nif there is a citation to page jfrom paper iandgij=0\\notherwise. Furthermore, let eijin the subgraph denote the\\ndirected edge from paper ito paper j. We typically choose\\nits length (or weight) as 1. The out-degree of a paper iis', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='the number of references it has links to, and the in-degree\\nof paper iis the number of papers that have links to it.\\n2.1. Direct and indirect relationships\\nWe classify the relationships between papers as two\\nclasses. One class includes direct citation and cited, co-\\ncitation and co-reference. The other class includes indirect\\ncitation, indirect cited, indirect co-citation, and indirect co-\\nreference. We call the rst class the direct relationships, and\\ndistinctively call the second class the indirect relationships.\\nWe rst learn about two simplest direct relationships, i.e.\\ncitation and cited relationships. The direct citation relation-\\nship is dened that one paper cites the other paper (see Fig.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='1(a)). Contrastively, if one paper is cited by the other paper,\\nthe relationship is called cited (see Fig. 1(b)).\\nCo-citation and co-reference\\nBesides the above directly citing and cited references of pa-\\npers, we also consider two especial attributes: co-citation\\nand co-reference, which are fundamental metrics to charac-\\nterize the similarity between two documents [11]. If both\\npaper iand paper jare cited by paper k(see Fig. 1(c)), they\\ncan be said as co-citation. Contrastively, if both paper iand\\npaper jcite paper k(see Fig. 1(d)), they may be said asi j\\n(a) citationi j\\n(b) cited\\nki\\nj\\n(c) co-citationki\\nj\\n(d) co-reference\\nj i\\n(e) indirect citation\\nFigure 1. Examples for showing the citation,\\ncited, co-citation, co-reference, and indirect', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='cited, co-citation, co-reference, and indirect\\ncitation relationships between papers. (a) pa-\\npericites paper j; (b) paper iis cited by pa-\\nperj; (c) paper iand paper jare co-cited by\\npaper k; (d) paper iand paper jare the co-\\nreference of paper k; (e) paper icites indi-\\nrectly paper j.\\nco-reference. Let R1=( R1ij)denote the co-citation ma-\\ntrix. Then the co-citation between paper iand paper jcan\\nbe calculated as [7]:\\nR1=GTGI1, (1)\\nwhere I1is the diagonal matrix of in-degree and GTGis\\ncalled the authority matrix [11], Similarly, let R2=( R2ij)\\ndenote the co-reference matrix, and the co-reference be-\\ntween paper iand paper jcan be calculated as:\\nR2=GGTI2, (2)\\nwhere I2is the diagonal matrix of out-degree and GGTis', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='called the hub matrix [11].\\nIndirect citation\\nThe direct citation may not adequately reect the lineage\\nof scientic works. In some sense, the consideration in\\ncounting the indirect citations can overcome this problem.\\nSome information might be transferred in citation propaga-\\ntion process. For example, a citation from paper ito paper j\\nestablishes a semantic relation between the two documents.\\nIf we assume that these semantic relations are transitive,\\nthen citation from itokviajalso implies a semantic re-\\nlation. Before giving the indirect citation denition, we rst\\nreview the shortest path problem in the graph theory. The\\nshortest path between two nodes is the path with the mini-\\nmal sum of the weights of its constituent edges.\\n283\\n278', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='283\\n278\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:26 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 1}), Document(page_content='Denition 1 The indirect citation relationship in biblio-\\nmetrics is dened by the case in which one paper can reach\\nthe other paper along multi-edges of the shortest path of the\\ndirected graph of the citation adjacency matrix, In this di-\\nrected graph, the edge weight is assigned 1, and the shortest\\ndistance of one indirect citation is dened by the sum of the\\nweights of the edges along the shortest path between the two\\npapers.\\nIn Denition 1, multi-edges means that the edge number\\nof the shortest path is more than 1. If the number is equal\\nto 1, it is the direct citation. A solution to the shortest path\\nproblem is sometimes called a pathing algorithm [6]. The\\nmost important algorithms for solving this problem include', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='Dijkstras algorithm, Floyd-Warshall algorithm, and others.\\nDijkstras algorithm solves the single source problem if all\\nedge weights are greater than or equal to zero. Without\\nworsening the run time, this algorithm can in fact compute\\nthe shortest paths from a given start node to all other nodes.\\nIn our implementation, we choose Dijkstras algorithm for\\ncomputing the indirect citation relationship between papers.\\nWe denote the distance matrix computed from the adjacent\\nmatrix Gusing Dijkstras algorithm by D= Dijkstra( G).\\nTherefore, the nal distance matrix Dis an-by-nmatrix,\\nthat is dijis equal to the the shortest distance between i\\nandjif there is an indirect or direct citation between them;', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='otherwise dij=0. Furthermore, the indirectly cited rela-\\ntionship is also dual to the indirect citation. Dprovides a\\ngood tool for measuring the citation relativity. In order to\\nmeasure the citation relativity, we dene a relativity matrix\\nRwith element rijthat denotes the citation relativity from\\npaper ito paper j. Here, we dene a relativity function for\\nbetween a RandD\\nR=f(D). (3)\\nEach element rijonly depends the shortest distance dijbe-\\ntween the source paper iand the target paper j,s ow ea l s o\\nhave\\nrij=f(dij). (4)\\nHere we only choose a simple function for explaining our\\nprocedure as follows\\nf(x)={1\\nx:x> 0\\n0: otherwise.(5)\\nThen the relativity rijbetween paper iand paper jis\\nrij=f(dij)=\\n\\n1\\ndij:dij>0\\n0: otherwise,', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='rij=f(dij)=\\n\\n1\\ndij:dij>0\\n0: otherwise,\\nWe can also apply the computed distance matrix for re-\\ntrieving the indirect co-citation and indirect co-reference\\nwhich are missed by the authority and hub matrices.Indirect co-citation and indirect co-reference\\nTo overcome the weakness of HITS, we use RTRinstead\\nofGTGfor computing the co-citation. Let R1=( R1ij)\\ndenote the relativity matrix of the indirect co-citation. Then\\nthe indirect co-citation between paper iand paper jcan be\\ncalculated as: R1ij=n\\nk=1rkirkj=(RTR)ij. Here,\\nwe use two norm of two vectors for computing the indirect\\nco-citation relativity\\nR1ij=rirj,\\nwhere ri=(r1i,r2i, ..., r ni)Tand rj=(r1j,r2j, ..., r nj)T\\nare the co-citation vectors for paper iand paper j, respec-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='tively. Other vector norms can also be used for our method.\\nThe self-citation R1iiis not dened and is usually set to\\nR1ii=0 . In addition, R1is a symmetric matrix, also\\nR1ij=R1ji. Thus, the indirect co-citation matrix updat-\\ning Eq. (1) is dened by\\nR1=RTRI1, (6)\\nwhere, I1the diagonal matrix of RTR, since the self-\\ncitation R1iiis not dened and set to 0. Similar to Eq. (6),\\nthe indirect co-reference matrix is dened by\\nR2=RRTI2. (7)\\nwhere, I2the diagonal matrix of RRT, since the self-\\nreference R2iiis not dened and set to 0.\\n2.2. Association matrix\\nNow we build an association matrix based on the relativ-\\nity matrix R.L e t Bbe the association matrix with element', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='bijmeasuring the relativity of associating direct and indirect\\nrelationships between paper iand paper j. Since the direct\\ncitation matrix Ghas been implied into the distance matrix\\nD, we only use the relativity matrix Rinstead of the direct\\nand indirect citation relationships. Similarly, the cited rela-\\ntionship can be represented by RTdue to its dual property.\\nFurthermore, the co-citation and co-reference relationships\\nare represented by R1in Eq. (1) and R2in Eq. (6), respec-\\ntively. They also imply the indirect co-citation and indirect\\nco-reference relationships. We assumed that Bis a linear\\ncombination of all relationships as follows\\nB=w1R1+w2R2+w3R+w4RT, (8)\\nwhere wi(i=1,2,3,4)denote four weights with the con-\\nstraint4\\ni=1wi=1.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='straint4\\ni=1wi=1.\\nThe Markov process represents the web directed graph as\\na square transition probability matrix A[13, 15]. Element\\naijofAis the probability of moving from state ito state jin\\none step (click). An important result in matrix theory known\\n284\\n279\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:26 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 2}), Document(page_content='as the Perron-Frobenius theorem applies to such matrices.\\nIt concludes that a nonzero solution of the equation\\nx=Ax (9)\\nexists and is unique to within a scaling factor. If this scaling\\nfactor is chosen so that\\nixi=1, then xis the state vector\\nof the Markov chain. The elements of xare all positive and\\nless than 1. Our strategy computing Ais similar to PageR-\\nank. Let pbe the probability that the random walk follows\\na relativity if existing relativity from paper ito paper j(i.e.\\nbij>0). Then (1p)is the probability that some arbitrary\\npapers is chosen and (1p)/nis the probability that a par-\\nticular random paper is chosen. Next, we compute Awhose\\nelements are\\naji=\\n\\npbji\\nrj+1p\\nn:rj=0\\n1/n :rj=0,(10)', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='aji=\\n\\npbji\\nrj+1p\\nn:rj=0\\n1/n :rj=0,(10)\\nwhere rjis the jth row sum of B. Finally, we solve the state\\nvector xof the Markov chain based on x=Ax. Finally, x\\nis normalized as the ranking score of papers. In summary,\\nthe PaperRank algorithm are given:\\n1. Calculate the relativity matrix Rbased on the given\\nadjacent matrix G.\\n2. Compute the co-citation matrix R1and the co-\\nreference matrix R2based on the matrix R.\\n3. Construct the association matrix Bin Eq. (8).\\n4. Compute the transition probability matrix A.\\n5. Compute the ranking scores by solving Eq. (9).\\n3 Experimental results\\nWe test our algorithm with two data sets, Google Scholar\\n[2] and CiteSeer [1], to evaluate the PaperRank model. The', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='rst data set contains more than 300,000 papers (excluding\\nbooks) in biology collected from Google Scholar [2] be-\\ntween 10/15/2006 and 1/19/2007. A seed paper s=[20]\\nis used to start the collecting process. All papers that cite\\npaper s, and the papers that cite the papers in the reference\\nofs, and papers that go deeper levels, were gradually added\\nto the data set. Due to the collecting process, this data set is\\nlarge but by no means of complete.\\nExample 2 Consider again the paper in the Example 1. It is\\nranked 426 and 473 among the 300,000 papers by citation\\nnumber and HITS model respectively. This ranking looks\\nnot very poor. However if a search engine shows 10 papers\\non each p age, this paper will be shown o n the 40th page. So', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='this paper is not really visible in le-management system or\\nin the application of digital library. In contrast, this paper\\nis ranked is top 1 by the PaperRank!Example 3 CiteSeer is a scientic literature digital library\\nand search engine that focuses primarily on the literature\\nin computer and information science [1]. We test our al-\\ngorithm by extracting the adjacency matrix from the source\\ncode of CiteSeer. Currently, there are 716,800 papers in\\nthe source code of CiteSeer. To test the co-citation rela-\\ntionships, we choose a subgraph including 20,011 papers\\nfor comparing HITS and our algorithm. The total num-\\nber of citations, i.e. the number of nonzero in G, is 7,706.\\nThis means that each paper has an average direct citation', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='equal to 0.39. The relativity matrix RofGcontains nonzero\\n13,188, that means that each paper has an average indirect\\ncitation equal to 0.27. This average indirect citation is al-\\nmost equal to the average direct citation. Thus, we can not\\nsimply neglect the indirect citation for this example. Similar\\nto the above discussion, there are only 6,760 nonzero for the\\nco-citation matrix. This means that each paper has an av-\\nerage co-citation equal to 0.34. Contrastively, we nd that\\nthere are 20,442 nonzero for the indirect co-citation. This\\nmeans there is an average indirect co-citation equal to 0.68\\nin this example. This average indirect co-citation is twice\\nas large as the co-citation.\\nSome typical papers chosen in the ranking results are', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='listed in Table 1. In this table, O and I are the out-\\ndegree and in-degree number; H, R, and P denotes\\nthe orders using HITS, our Relativity PaperRank algorithm,\\nand PageRank, respectively. We list the highest 5 papers\\nusing HITS and our algorithm. We nd that there are two\\nsame papers (i.e. 18858 and 15205) are in the highest ve\\npapers between HITS and our results. However, the more\\nold papers are given the high ranking orders in our rank-\\ning than HITS, where all ve papers in our ranking are be-\\nfore 1990. There are the smaller differences for the ranking\\norders between our algorithm and PageRank than our and\\nHITS. This simple comparison also shows partially that our\\nalgorithm wins the more favor of time than HITS. Be-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='ing differ to web pages, time is very valuable relativity\\nbetween papers, since a new paper may be evaluated after\\nseveral or more years.\\n4 Conclusions and discussions\\nIn this paper, we present a novel and simple model,\\ncalled PaperRank, for citation ranking and selection of sci-\\nentic publications by using relativity measurements. Com-\\npared with PageRank and HITS, the proposed model and al-\\ngorithm can nd some indirect relationships. The key idea\\nin our algorithm is to measure the relativity between papers.\\nIn some sense, PageRank and/or HITS model for citation\\nanalysis can be partially regarded as the special case of our\\nalgorithm as a special function is adopted. We believe that', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='our PaperRank model can be a good help to many informa-\\ntion retrieval techniques by combining keyword and text.\\n285\\n280\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:26 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 3}), Document(page_content='Table 1. Ranking orders of papers for CiteSeer.\\nID Year Title O I H R P\\n15205 1988 Congestion Avoidance and Control. ACM SIGCOMM88 2 48 1 4 2\\n18858 1990 PVM: A Framework for Parallel Distributed Computing. Concurrency,\\nPractice and Experience05 2 2 2 4\\n19249 1995 A Reliable Multicast Framework for Light-weight Sessions and Applica-\\ntion Level Framing. IEEE/ACM Transactions on Networking4 3 031 1 1 7\\n4526 1993 Random Early Detection Gateways for Congestion Avoidance. IEEE/ACM\\nTransactions on Networking3 1 542 6 9 5\\n6008 1996 Receiver-driven Layered Multicast. ACM SIGCOMM 3 14 5 22 58\\n8919 1988 An Evaluation of Directory Schemes for Cache Coherence. 25 Years ISCA:\\nRetrospectives and Reprints02 33 5 1 3', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 4}), Document(page_content='Retrospectives and Reprints02 33 5 1 3\\n18858 1990 PVM: A Framework for Parallel Distributed Computing. Concurrency,\\nPractice and Experience05 2 2 2 4\\n16423 1988 Caching in the Sprite Network File System. ACM Transactions on Com-\\nputer Systems0 2 87 32 1\\n15205 1988 Congestion Avoidance and Control. ACM SIGCOMM88 2 48 1 4 2\\n921 1990 Weak Ordering A New Denition. Proc. of the 17th Annual Intl Symp. on\\nComputer Architecture (ISCA90)12 21 6 5 6\\nReferences\\n[1] Citeseer: Scientic literature digital library. http://\\nciteseer.ist.psu.edu/ .\\n[2] Google scholar. http://scholar.google.com .\\n[3] Google. http://www.google.com .\\n[4] K. Altmann and G. Gorman. Usage, citation analysis and\\ncosts as indicators for journal deselection and cancellation:', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 4}), Document(page_content='a selective literature review. Australian Library Review ,\\n13(4):379392, 1996.\\n[5] P. Berkhin. A survey on pagerank computing. Internet Math-\\nematics , 2(1):73120, 2005.\\n[6] T. Cormen, C. Leiserson, R. Rivest, and C. Stein. Introduc-\\ntion to algorithms. pages 580642. MIT Press and McGraw-\\nHill, 2001.\\n[7] C. Ding, H. Zha, X. He, P. Husbands, and H. Simon. Link\\nanalysis: Hubs and authorities on the world wide web. SIAM\\nReview , 46(2):256268.\\n[8] E. Gareld. Citation indexing for studying science. Nature ,\\n227:669671, 1970.\\n[9] E. Gareld. Citation analysis as a tool in journal evaluation.\\nScience , 178:471479, 1972.\\n[10] E. Gareld. New international professional society signals', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 4}), Document(page_content='the maturing of scientometrics and informetrics. The Scien-\\ntist, 9(16):11, 1995.\\n[11] J. Kleinberg. Authoritative sources in a hyperlinked envi-\\nronment. In the Nineth Annual ACM-SIAM Symposium on\\nDiscrete Algorithms , 1998.\\n[12] A. Langville and C. Meyer. Deeper inside pagerank. Internet\\nMathematics , 1(3):335380, 2004.[13] A. Langville and C. Meyer. A survey of eigenvector methods\\nfor web information retrieval. SIAM Review , 47(1):135161,\\n2005.\\n[14] R. Lempel and S. Moran. The stochastic approach for link-\\nstructure analysis (salsa) and the tkc effect. In the Ninth\\nInternational WWW Conference , May 2000.\\n[15] C. Moler. Numerical computing with MATLAB . SIAM.\\n[16] J. Morrison, R. Breitling, D. Higham, and D. Gilbert. Gen-', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 4}), Document(page_content='erank: using search engine technology for the analysis of\\nmicroarray experiments. BMC Bioinformatics , 6:233, 2005.\\n[17] L. Page and S. Brin. The anatomy of a large-scale hyper-\\ntextual web search engine. In the Seventh International Web\\nConference (WWW 98) , 1998.\\n[18] L. Page, S. Brin, R. Motwani, and T. Winograd. The pager-\\nank citation ranking: bringing order to the web. Technical\\nreport, Stanford University, 1998.\\n[19] A. Sidiropoulos and Y . Manolopoulos. A citation-based\\nsystem to assist prize awarding. ACM SIGMOD Record ,\\n34(4):5460, 2005.\\n[20] E. Sutherland. Studies on the mechanism of hormone action.\\nScience , page 149, 1972.\\n[21] W. Xing and A. Ghorbani. Weighted pagerank algorithm. In', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 4}), Document(page_content='the Second Annual Conference on Communication Networks\\nand Services Research , pages 305314, 2004.\\n286\\n281\\nAuthorized licensed use limited to: Tsinghua University. Downloaded on April 09,2024 at 13:24:26 UTC from IEEE Xplore.  Restrictions apply.', metadata={'source': '/share/lab4/ych/papers/paper8.pdf', 'page': 4})]\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use System8 to answer this question.\n",
      "Action: System8\n",
      "Action Input: final conclusions\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m The final conclusions of this context are that the relationships between papers can be represented by various types of relationships, such as direct and indirect citation, co-citation, and co-reference. These relationships can be combined using weights to create a relativity matrix, which can be used to measure the associations between papers. The direct citation matrix is implied into the distance matrix, and the relativity matrix is used instead of the direct and indirect citation relationships. The final constraint is that the sum of the weights must equal 1.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The final conclusions reached by the eighth paper are that relationships between papers can be represented by various types of relationships, such as direct and indirect citation, co-citation, and co-reference. These relationships can be combined using weights to create a relativity matrix, which can be used to measure the associations between papers. The direct citation matrix is implied into the distance matrix, and the relativity matrix is used instead of the direct and indirect citation relationships. The final constraint is that the sum of the weights must equal 1.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final conclusions reached by the eighth paper are that relationships between papers can be represented by various types of relationships, such as direct and indirect citation, co-citation, and co-reference. These relationships can be combined using weights to create a relativity matrix, which can be used to measure the associations between papers. The direct citation matrix is implied into the distance matrix, and the relativity matrix is used instead of the direct and indirect citation relationships. The final constraint is that the sum of the weights must equal 1.'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "\n",
    "# This is a major task that requires some thinking and time. \n",
    "\n",
    "# Build a conversation system from a collection of research papers of your choice. \n",
    "# You can ask specific questions of a method about these papers, and the agent returns a brief answer to you (with no more than 100 words). \n",
    "# Save your data and ChromaDB in the /share directory so other people can use it. \n",
    "# Provide at least three query examples so the TAs can review your work. \n",
    "\n",
    "# You may use any tool from the past four labs or from the langchain docs, or any open source project. \n",
    "\n",
    "# write a summary (a Markdown cell) at the end of the notebook summarizing what works and what does not. \n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import AgentType, Tool\n",
    "from langchain.agents import initialize_agent\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "data = []\n",
    "docsearch=[]\n",
    "docsearch_reloaded = []\n",
    "chain = []\n",
    "\n",
    "for i in range(1, 9):\n",
    "    loaded_data = PyPDFLoader(f\"/share/lab4/ych/papers/paper{i}.pdf\").load()\n",
    "    data.append(loaded_data)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=750, chunk_overlap=50)\n",
    "    texts = text_splitter.split_documents(loaded_data)\n",
    "    print(texts)\n",
    "    \n",
    "    docsearch.append(Chroma.from_documents(texts, \n",
    "                                   minilm_embedding, \n",
    "                                   collection_name=f\"data{i}\", \n",
    "                                   persist_directory=\"/share/lab4/ych/chroma\"))\n",
    "    docsearch[i-1].persist()\n",
    "    docsearch_reloaded.append(Chroma(persist_directory = \"/share/lab4/ych/chroma\",\n",
    "                                   collection_name = f\"data{i}\", \n",
    "                                   embedding_function = minilm_embedding))\n",
    "\n",
    "for i in range(0, 8):\n",
    "    chain.append(RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch_reloaded[i].as_retriever()))\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"System1\",\n",
    "        func=chain[0].run,\n",
    "        description=\"It is used to answer the question about the first paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System2\",\n",
    "        func=chain[1].run,\n",
    "        description=\"It is used to answer the question about the second paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System3\",\n",
    "        func=chain[2].run,\n",
    "        description=\"It is used to answer the question about the third paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System4\",\n",
    "        func=chain[3].run,\n",
    "        description=\"It is used to answer the question about the fourth paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System5\",\n",
    "        func=chain[4].run,\n",
    "        description=\"It is used to answer the question about the fifth paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System6\",\n",
    "        func=chain[5].run,\n",
    "        description=\"It is used to answer the question about the sixth paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System7\",\n",
    "        func=chain[6].run,\n",
    "        description=\"It is used to answer the question about the seventh paper.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"System8\",\n",
    "        func=chain[7].run,\n",
    "        description=\"It is used to answer the question about the eighth paper.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "\n",
    "#query = \"What is the Contributions of the fifth paper?\"\n",
    "query = \"What is the final conclusions reached by the eighth paper?\"\n",
    "#query = \"What is the research problem of the first paper?\"\n",
    "\n",
    "agent.run(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43fd857",
   "metadata": {},
   "source": [
    "This agent can summarize the paper stored in the memory and gives some detailed information, such as, the conclusion, of the papers.\n",
    "But it fails to combine the papers' contents together and may be confused when asked the information which don't explicitly appear in the papers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
