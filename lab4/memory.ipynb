{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7731fa-1ab4-48cf-996c-a1a1fb6b2315",
   "metadata": {},
   "source": [
    "# Lec4. Adding Memory and Storage to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b0c75-2dd7-4662-b2ce-4e6b9208926c",
   "metadata": {},
   "source": [
    "Last week, we learned the basic elements of the framework LangChain. In this lecture, we are going to construct a vector store QA application from scratch.\n",
    "\n",
    ">Reference:\n",
    "> 1. [Ask A Book Questions](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Ask%20A%20Book%20Questions.ipynb)\n",
    "> 2. [Agent Vectorstore](https://python.langchain.com/docs/modules/agents/how_to/agent_vectorstore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a649ab-bb72-4894-b526-c97a7aa1fd81",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411a5b-ad45-4bf0-bf8e-91f71b256337",
   "metadata": {},
   "source": [
    "1. Install the requirements.  (Already installed in your image.)\n",
    "    ```\n",
    "    pip install -r requirements.txt\n",
    "    ```\n",
    "2. Get your OpenAI API; to get your Serpapi key, please sign up for a free account at the [Serpapi website](https://serpapi.com/); to get your Pinecone key, first regiter on the [Pinecone website](https://www.pinecone.io/), **Create API Key** and **Create Index**. Note that in this notebook the index's dimension should be 1536.\n",
    "\n",
    "3. Store your keys in a file named **.env** and place it in the current path or in a location that can be accessed.\n",
    "    ```\n",
    "    OPENAI_API_KEY='YOUR-OPENAI-API-KEY'\n",
    "    SERPAPI_API_KEY=\"YOUR-SERPAPI-API-KEY\"\n",
    "    PINECONE_API_KEY=\"YOUR-PINECONE-API-KEY\"\n",
    "    PINECONE_API_ENV=\"PINECONE-API-ENV\" # Should be something like \"gcp-starter\"\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defc9a3a-9f4c-49ff-8546-5799ff78b457",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb49c80a-4c12-4829-bef9-91076a4af689",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159215cd-4035-4f12-9904-e0ad32929b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5009a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function\n",
    "\n",
    "from pprint import pprint\n",
    "def print_with_type(res):\n",
    "    pprint(f\"%s:\" % type(res))\n",
    "    pprint(res)\n",
    "\n",
    "    #pprint(f\"%s : %s\" % (type(res), res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d6985-1b36-4142-90b1-ad6386eb4335",
   "metadata": {},
   "source": [
    "## 1. Adding memory to remember the context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6809691-6aa5-4062-8d9e-1c620f9c6d2f",
   "metadata": {},
   "source": [
    "### 1.1 Use Conversation Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e8c81",
   "metadata": {},
   "source": [
    "#### Basic Use of ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3b8fbfe-6cd7-4c4e-843f-92b0f4755d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'history': \"Human: hi\\nAI: what's up\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Creating a memory and write to it.\n",
    "memory = ConversationBufferMemory()  # stores all histories as a single string\n",
    "memory.save_context({\"input\": \"hi\"}, \n",
    "                    {\"output\": \"what's up\"})\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c34234",
   "metadata": {},
   "source": [
    "We can also get the history as a list of messages (this is useful if you are using this with a chat model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2794154-3b85-4012-b28f-2470cfeaa13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'history': [HumanMessage(content='hi'), AIMessage(content=\"what's up\")]}\n"
     ]
    }
   ],
   "source": [
    "# get the history as a list of messages\n",
    "memory = ConversationBufferMemory(return_messages=True)  # stores messages as a list\n",
    "memory.save_context({\"input\": \"hi\"}, \n",
    "                    {\"output\": \"what's up\"})\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7eafa",
   "metadata": {},
   "source": [
    "#### Managing Conversation Memory automatically in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e349aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edfe2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content = \"\"\"You are a chatbot having a conversation with a human. \n",
    "            Your name is Tom Marvolo Riddle. \n",
    "            You need to tell your name to that human if he doesn't know.\"\"\"\n",
    "        ),  # The persistent system prompt\n",
    "        MessagesPlaceholder(\n",
    "            variable_name = \"chat_history\"\n",
    "        ),  # This is where the memory will be stored.\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),  # This is where the human input will be injected\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", \n",
    "                                  return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2d0587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set verbose as True to see more details\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "chat_llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory,   # Look at this line\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db79f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there, Harry Potter. I am Tom Marvolo Riddle. It's nice to meet you. It sounds like you've made some great friends at Hogwarts in Ron Weasley and Hermione Granger. How are you finding your time at Hogwarts so far?\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12e8428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.'),\n",
       "  AIMessage(content=\"Hello there, Harry Potter. I am Tom Marvolo Riddle. It's nice to meet you. It sounds like you've made some great friends at Hogwarts in Ron Weasley and Hermione Granger. How are you finding your time at Hogwarts so far?\")]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0cf684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Your best friends' names are Ron Weasley and Hermione Granger. They are loyal and brave companions who have stood by you through thick and thin.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm_chain.predict(human_input=\"What are my best friends' names? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ace5b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.'),\n",
       "  AIMessage(content=\"Hello there, Harry Potter. I am Tom Marvolo Riddle. It's nice to meet you. It sounds like you've made some great friends at Hogwarts in Ron Weasley and Hermione Granger. How are you finding your time at Hogwarts so far?\"),\n",
       "  HumanMessage(content=\"What are my best friends' names? \"),\n",
       "  AIMessage(content=\"Your best friends' names are Ron Weasley and Hermione Granger. They are loyal and brave companions who have stood by you through thick and thin.\")]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5184cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! My name is Tom Marvolo Riddle. How can I assist you today?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.clear()\n",
    "memory.load_memory_variables({})\n",
    "chat_llm_chain.predict(human_input=\"What are my best friends' names? \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451b9db-5213-463c-9867-5ecb67bd6d01",
   "metadata": {},
   "source": [
    "#### (Optional) Manipulate the memory by yourself in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "453b9ad2-45b7-4899-b28a-be80166d71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI()\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful chatbot\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f429977-c439-4f56-bf42-191c14d6daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add memory to an arbitrary chain\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\")\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c28ebc5-9720-40e8-b8f6-497b14092367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'langchain_core.messages.ai.AIMessage'>:\"\n",
      "AIMessage(content='Hello Harry! How can I assist you today?')\n",
      "\"<class 'dict'>:\"\n",
      "{'history': []}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"input\": \"Hi, I am Harry!\"}\n",
    "response = chain.invoke(inputs)\n",
    "print_with_type(response)\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "205e3b28-4fd5-426a-87fd-4e88604762a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'history': [HumanMessage(content='Hi, I am Harry!'),\n",
      "             AIMessage(content='Hello Harry! How can I assist you today?')]}\n"
     ]
    }
   ],
   "source": [
    "# You need to save the context yourself\n",
    "memory.save_context(inputs, \n",
    "                    {\"output\": response.content})\n",
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12b115f9-c389-43a6-815a-351dfaea009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'langchain_core.messages.ai.AIMessage'>:\"\n",
      "AIMessage(content='Your name is Harry. How can I assist you today, Harry?')\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What's my name?\"})\n",
    "print_with_type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cc6973-7992-4e37-bda1-505c0e670df8",
   "metadata": {},
   "source": [
    "### 1.2 Using Entity memory\n",
    "\n",
    "#### Basic Use of ConversationEntityMemory\n",
    "\n",
    "Entity memory remembers given facts about specific entities in a conversation. It extracts information on entities (using an LLM) and builds up its knowledge about that entity over time (also using an LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ae8f4b-067e-4a39-9802-8989513480cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d147e6-bc48-4235-ba83-d40c83be86b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Harry & Ron are going to rescue a baby dragon in London.'),\n",
       "  AIMessage(content='That sounds like a great mission! What kind of mission are they working on?')],\n",
       " 'entities': {'Harry': 'Harry is going to rescue a baby dragon in London.',\n",
       "  'Ron': 'Ron is going to rescue a baby dragon in London with Harry.',\n",
       "  'Wei': '',\n",
       "  'London': 'London is the location where Harry and Ron are going to rescue a baby dragon.'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationEntityMemory(llm=llm, return_messages=True)\n",
    "inputs = {\"input\": \"Harry & Ron are going to rescue a baby dragon in London.\"}\n",
    "memory.load_memory_variables(inputs)\n",
    "memory.save_context(\n",
    "    inputs,\n",
    "    {\"output\": \"That sounds like a great mission! What kind of mission are they working on?\"}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({\"input\": \"Harry and Ron and Wei and London?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aaf35a-8bbe-4274-9ed0-43d983e35e01",
   "metadata": {},
   "source": [
    "#### Using Entity in a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3128de",
   "metadata": {},
   "source": [
    "Here we use ConversationChain.  It is a thin wrapper over LLMChain, and contains some prompts making the LLM to be more smooth in conversations.  See its source code for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ac27a8-bfce-4066-b038-a75265036c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef6b28b9-4c78-4c7c-9164-89a60d980329",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5defa301-db7f-4bae-8b43-af49cee92f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Harry & Ron are going to rescue a baby dragon.',\n",
       " 'history': '',\n",
       " 'entities': {'Harry': '', 'Ron': ''},\n",
       " 'response': \" That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be quite dangerous, but I'm sure Harry and Ron are up for the challenge. Do you know where they are planning to rescue the dragon from?\"}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Harry & Ron are going to rescue a baby dragon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e492536-d6ee-4094-8bf5-4a17dd48348e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Harry': 'Harry is going on an adventure with Ron to rescue a baby dragon.',\n",
       " 'Ron': 'Ron is going on an adventure with Harry to rescue a baby dragon.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.memory.entity_store.store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97567380-84a5-4517-be2f-5aef57b0f052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\",\n",
       " 'history': \"Human: Harry & Ron are going to rescue a baby dragon.\\nAI:  That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be quite dangerous, but I'm sure Harry and Ron are up for the challenge. Do you know where they are planning to rescue the dragon from?\",\n",
       " 'entities': {'Romania': ''},\n",
       " 'response': \" That's a great idea! Romania is known for its dragon reserves and I'm sure the baby dragon will be well taken care of there. I hope Harry and Ron are able to successfully deliver the dragon to Charlie's friends and ensure its safety.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62f5f13a-ff9f-407a-ae5f-1004ff8c0cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\",\n",
       " 'history': \"Human: Harry & Ron are going to rescue a baby dragon.\\nAI:  That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be quite dangerous, but I'm sure Harry and Ron are up for the challenge. Do you know where they are planning to rescue the dragon from?\\nHuman: They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\\nAI:  That's a great idea! Romania is known for its dragon reserves and I'm sure the baby dragon will be well taken care of there. I hope Harry and Ron are able to successfully deliver the dragon to Charlie's friends and ensure its safety.\",\n",
       " 'entities': {'Harry': 'Harry is going on an adventure with Ron to rescue a baby dragon.',\n",
       "  'Ron': 'Ron is going on an adventure with Harry to rescue a baby dragon.',\n",
       "  'Hogwarts': '',\n",
       "  \"Harry's Invisibility cloak\": ''},\n",
       " 'response': \" That's a clever plan! Harry's Invisibility cloak will definitely come in handy for this mission. I'm sure they will be able to successfully transfer the baby dragon without anyone noticing. Hogwarts is a big place, so finding the highest point might be a challenge, but I have faith in Harry and Ron's abilities.\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e27e48a2-862d-418b-9cdb-8fec5278d77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What do you know about Harry & Ron?',\n",
       " 'history': \"Human: Harry & Ron are going to rescue a baby dragon.\\nAI:  That sounds like quite an adventure! I hope they have a plan in place to safely rescue the dragon and return it to its natural habitat. Dragons can be quite dangerous, but I'm sure Harry and Ron are up for the challenge. Do you know where they are planning to rescue the dragon from?\\nHuman: They are trying to give the baby dragon to Ron's elder brother Charlie's friends and let them take the baby dragon to Romania.\\nAI:  That's a great idea! Romania is known for its dragon reserves and I'm sure the baby dragon will be well taken care of there. I hope Harry and Ron are able to successfully deliver the dragon to Charlie's friends and ensure its safety.\\nHuman: Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\\nAI:  That's a clever plan! Harry's Invisibility cloak will definitely come in handy for this mission. I'm sure they will be able to successfully transfer the baby dragon without anyone noticing. Hogwarts is a big place, so finding the highest point might be a challenge, but I have faith in Harry and Ron's abilities.\",\n",
       " 'entities': {'Harry': 'Harry is using his Invisibility cloak to help transfer the baby dragon to the highest point in Hogwarts without being seen.',\n",
       "  'Ron': \"Ron is helping Harry transfer the baby dragon to the highest place in Hogwarts using Harry's Invisibility cloak.\"},\n",
       " 'response': \" Harry and Ron are two brave and resourceful students at Hogwarts. They are currently on a mission to rescue a baby dragon and transfer it to Romania. They are using Harry's Invisibility cloak to secretly transport the dragon to the highest point in Hogwarts without being seen. They are determined to complete their mission and ensure the safety of the dragon.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"What do you know about Harry & Ron?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66085a34-f6fd-4bb0-a91f-3b9aa96b278c",
   "metadata": {},
   "source": [
    "Now Let's inspect the entities that are extracted from the conversation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c36d9ec-2840-48db-b6a9-809229a53a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'Harry': 'Harry and Ron are two brave and resourceful students at Hogwarts. '\n",
      "          'They are currently on a mission to rescue a baby dragon and '\n",
      "          \"transfer it to Romania. They are using Harry's Invisibility cloak \"\n",
      "          'to secretly transport the dragon to the highest point in Hogwarts '\n",
      "          'without being seen. They are determined to complete their mission '\n",
      "          'and ensure the safety of the dragon.',\n",
      " \"Harry's Invisibility cloak\": 'Harry will use his Invisibility cloak to '\n",
      "                               'secretly transfer the baby dragon to the '\n",
      "                               'highest place in Hogwarts without being seen.',\n",
      " 'Hogwarts': 'Hogwarts is the location where Harry and Ron plan to secretly '\n",
      "             \"transfer the baby dragon using Harry's Invisibility cloak.\",\n",
      " 'Romania': 'Romania is known for its dragon reserves and is the planned '\n",
      "            \"destination for the baby dragon to be safely delivered to Ron's \"\n",
      "            \"elder brother Charlie's friends.\",\n",
      " 'Ron': 'Ron is a brave and resourceful student at Hogwarts who is currently '\n",
      "        'on a mission with Harry to rescue a baby dragon and transfer it to '\n",
      "        \"Romania. He is using Harry's Invisibility cloak to secretly transport \"\n",
      "        'the dragon to the highest point in Hogwarts without being seen.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ad77c",
   "metadata": {},
   "source": [
    "Let's do more conversations and see what we can learn more about each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4821793a-fe46-4693-a940-18833f1b9a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Yes, Harry is definitely a brave and clever boy. He has proven himself time and time again, whether it's facing dangerous challenges or coming up with clever solutions to difficult problems. He is a true hero and a valuable friend to have.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Harry is a brave and clever boy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b340df6-b5c8-4731-8936-c8587eb1d527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'Harry': 'Harry is a brave and clever boy who has proven himself time and '\n",
      "          \"time again, whether it's facing dangerous challenges or coming up \"\n",
      "          'with clever solutions to difficult problems. He is a true hero and '\n",
      "          'a valuable friend to have.',\n",
      " \"Harry's Invisibility cloak\": 'Harry will use his Invisibility cloak to '\n",
      "                               'secretly transfer the baby dragon to the '\n",
      "                               'highest place in Hogwarts without being seen.',\n",
      " 'Hogwarts': 'Hogwarts is the location where Harry and Ron plan to secretly '\n",
      "             \"transfer the baby dragon using Harry's Invisibility cloak.\",\n",
      " 'Romania': 'Romania is known for its dragon reserves and is the planned '\n",
      "            \"destination for the baby dragon to be safely delivered to Ron's \"\n",
      "            \"elder brother Charlie's friends.\",\n",
      " 'Ron': 'Ron is a brave and resourceful student at Hogwarts who is currently '\n",
      "        'on a mission with Harry to rescue a baby dragon and transfer it to '\n",
      "        \"Romania. He is using Harry's Invisibility cloak to secretly transport \"\n",
      "        'the dragon to the highest point in Hogwarts without being seen.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "718775f3-8188-4199-a663-72bd4b96eac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What do you know about Harry?',\n",
       " 'history': \"Human: Harry & Ron need to secretly transfer the baby dragon to the highest place in Hogwarts without let anyone see them. So they are going to use Harry's Invisibility cloak.\\nAI:  That's a clever plan! Harry's Invisibility cloak will definitely come in handy for this mission. I'm sure they will be able to successfully transfer the baby dragon without anyone noticing. Hogwarts is a big place, so finding the highest point might be a challenge, but I have faith in Harry and Ron's abilities.\\nHuman: What do you know about Harry & Ron?\\nAI:  Harry and Ron are two brave and resourceful students at Hogwarts. They are currently on a mission to rescue a baby dragon and transfer it to Romania. They are using Harry's Invisibility cloak to secretly transport the dragon to the highest point in Hogwarts without being seen. They are determined to complete their mission and ensure the safety of the dragon.\\nHuman: Harry is a brave and clever boy.\\nAI:  Yes, Harry is definitely a brave and clever boy. He has proven himself time and time again, whether it's facing dangerous challenges or coming up with clever solutions to difficult problems. He is a true hero and a valuable friend to have.\",\n",
       " 'entities': {'Harry': \"Harry is a brave and clever boy who has proven himself time and time again, whether it's facing dangerous challenges or coming up with clever solutions to difficult problems. He is a true hero and a valuable friend to have.\"},\n",
       " 'response': \" As an AI, I have access to a lot of information about Harry. I know that he is a brave and clever boy who has proven himself time and time again, whether it's facing dangerous challenges or coming up with clever solutions to difficult problems. He is a true hero and a valuable friend to have.\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(input=\"What do you know about Harry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2467bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'Harry': 'As an AI, I have access to a lot of information about Harry. I know '\n",
      "          'that he is a brave and clever boy who has proven himself time and '\n",
      "          \"time again, whether it's facing dangerous challenges or coming up \"\n",
      "          'with clever solutions to difficult problems. He is a true hero and '\n",
      "          'a valuable friend to have.',\n",
      " \"Harry's Invisibility cloak\": 'Harry will use his Invisibility cloak to '\n",
      "                               'secretly transfer the baby dragon to the '\n",
      "                               'highest place in Hogwarts without being seen.',\n",
      " 'Hogwarts': 'Hogwarts is the location where Harry and Ron plan to secretly '\n",
      "             \"transfer the baby dragon using Harry's Invisibility cloak.\",\n",
      " 'Romania': 'Romania is known for its dragon reserves and is the planned '\n",
      "            \"destination for the baby dragon to be safely delivered to Ron's \"\n",
      "            \"elder brother Charlie's friends.\",\n",
      " 'Ron': 'Ron is a brave and resourceful student at Hogwarts who is currently '\n",
      "        'on a mission with Harry to rescue a baby dragon and transfer it to '\n",
      "        \"Romania. He is using Harry's Invisibility cloak to secretly transport \"\n",
      "        'the dragon to the highest point in Hogwarts without being seen.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(conversation.memory.entity_store.store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab1e54-6c47-43ea-9750-af8840c1494d",
   "metadata": {},
   "source": [
    "### 1.3 Adding Memory to Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8bf04-34d1-4a86-82f8-de39be61b836",
   "metadata": {},
   "source": [
    "In this section, we will first ask the agent a question, and then without mention the context information ourselves ask another related question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edba9d7b-5baa-4769-9c2a-d11164941fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9088da52-e54b-468e-a158-9220360ea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ee6d6dd-39eb-425f-bdda-8d5dc07e3038",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=\"\"\"Have a conversation with a human, answering the following questions as best you can.  You have access to the following tools:\"\"\",\n",
    "    suffix=\"\"\"Begin!  \n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\",\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0a5b87b-2c41-4b4a-b14a-cb30838c561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.mrkl.base.ZeroShotAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use create_react_agent instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=OpenAI(temperature=0), prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed18da6e-6754-4b8b-8951-4bf916e3d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use the Search tool to find the most recent data on China's population.\n",
      "Action: Search\n",
      "Action Input: \"China population 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1,425,178,782\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is the estimated population for 2024, but it may change in the future.\n",
      "Action: Search\n",
      "Action Input: \"China population forecast 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mChina Population Projections The current population of China is 1,425,354,512 based on projections of the latest United Nations data. The UN estimates the July 1, 2024 population at 1,425,178,782.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is a more accurate estimate, but it is still a projection and may change.\n",
      "Action: Search\n",
      "Action Input: \"China population growth rate\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'China', 'population': '0.1% annual change', 'year': '2021'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This shows that China's population is growing at a slower rate compared to previous years.\n",
      "Final Answer: The estimated population of China in 2024 is 1,425,178,782, with a projected growth rate of 0.1% annually. However, this is subject to change in the future.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the population of China in 2024?',\n",
       " 'chat_history': '',\n",
       " 'output': 'The estimated population of China in 2024 is 1,425,178,782, with a projected growth rate of 0.1% annually. However, this is subject to change in the future.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"What is the population of China in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd9a011d-c1cc-4c1c-bf43-7b505eb97c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: What is the population of China in 2024?\\nAI: The estimated population of China in 2024 is 1,425,178,782, with a projected growth rate of 0.1% annually. However, this is subject to change in the future.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4dc74f05-4c59-4df3-800b-c2421e1d1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use the search tool to find the current population of India.\n",
      "Action: Search\n",
      "Action Input: \"Population of India\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'population_result', 'place': 'India', 'population': '1.408 billion', 'year': '2021'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m Now I have the current population of India, I can compare it to the projected population of China in 2024.\n",
      "Action: Compare\n",
      "Action Input: 1.408 billion vs 1,425,178,782\u001b[0m\n",
      "Observation: Compare is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to compare the two populations.\n",
      "Action: Use calculator\n",
      "Action Input: 1.408 billion vs 1,425,178,782\u001b[0m\n",
      "Observation: Use calculator is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a search engine to find a website that can compare the two populations.\n",
      "Action: Search\n",
      "Action Input: \"Compare population of China and India\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mChina and India are the two most populous countries in the world, with India home to about 1.44 billion people and China home to 1.43 billion in 2024. China and India together account for about 35.31 % of total world population and 60% of Asia population.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: In 2024, the population of China is projected to be slightly less than the population of India.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Is it more or less than India?',\n",
       " 'chat_history': 'Human: What is the population of China in 2024?\\nAI: The estimated population of China in 2024 is 1,425,178,782, with a projected growth rate of 0.1% annually. However, this is subject to change in the future.',\n",
       " 'output': 'In 2024, the population of China is projected to be slightly less than the population of India.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"Is it more or less than India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6539886a-230d-497e-bcf3-1f60fc6d607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'chat_history': 'Human: What is the population of China in 2024?\\n'\n",
      "                 'AI: The estimated population of China in 2024 is '\n",
      "                 '1,425,178,782, with a projected growth rate of 0.1% '\n",
      "                 'annually. However, this is subject to change in the future.\\n'\n",
      "                 'Human: Is it more or less than India?\\n'\n",
      "                 'AI: In 2024, the population of China is projected to be '\n",
      "                 'slightly less than the population of India.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff3ddfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use the search tool to find the most accurate and up-to-date information.\n",
      "Action: Search\n",
      "Action Input: \"Population of China 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1.43 billion\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is the same as the previous estimate, so it seems to be a reliable source.\n",
      "Action: Search\n",
      "Action Input: \"Population of India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1,441,719,852\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m This is slightly higher than the previous estimate for India's population in 2024.\n",
      "Action: None needed\n",
      "Final Answer: The population of China in 2024 is slightly less than the population of India.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the population in Chima?',\n",
       " 'chat_history': 'Human: What is the population of China in 2024?\\nAI: The estimated population of China in 2024 is 1,425,178,782, with a projected growth rate of 0.1% annually. However, this is subject to change in the future.\\nHuman: Is it more or less than India?\\nAI: In 2024, the population of China is projected to be slightly less than the population of India.',\n",
       " 'output': 'The population of China in 2024 is slightly less than the population of India.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"what is the population in Chima?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e01167-55ca-4ba1-836d-c00e648e4634",
   "metadata": {},
   "source": [
    "## 2. Long term memory with vector storage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c1f37-7026-4d59-bf87-70c94eed7afa",
   "metadata": {},
   "source": [
    "In this section, we are going to embed the famous Harry Potter book's first chapter into a vectorstore and try some similarity searches. We have some extra examples commented, you can uncomment and try them one-by-one. If you observe the results carefully, you may find the characteristics of similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc75f3-1fd9-4076-8a3f-d809b7dbf572",
   "metadata": {},
   "source": [
    "### 2.1 Loaders and Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d598ad",
   "metadata": {},
   "source": [
    "#### PDF Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cac64c7-69dc-4450-b2fa-ffd05740411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "data = PyPDFLoader(\"/share/lab4/harry-potter-chap-1.pdf\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43a7e514-29b0-44ad-afbd-529f67296153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 16 document(s) in your data\n",
      "There are 1848 characters in doc 0\n",
      "There are 2101 characters in doc 1\n",
      "There are 2093 characters in doc 2\n",
      "There are 1898 characters in doc 3\n",
      "There are 1892 characters in doc 4\n",
      "There are 1300 characters in doc 5\n",
      "There are 1867 characters in doc 6\n",
      "There are 1806 characters in doc 7\n",
      "There are 1548 characters in doc 8\n",
      "There are 1573 characters in doc 9\n",
      "There are 1635 characters in doc 10\n",
      "There are 1792 characters in doc 11\n",
      "There are 1542 characters in doc 12\n",
      "There are 1399 characters in doc 13\n",
      "There are 1882 characters in doc 14\n",
      "There are 1921 characters in doc 15\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "i = 0\n",
    "for d in data:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2396be0",
   "metadata": {},
   "source": [
    "#### Text file loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c50f2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "union = TextLoader(\"/share/lab4/state_of_the_union.txt\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caf81f",
   "metadata": {},
   "source": [
    "#### Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce5a0a",
   "metadata": {},
   "source": [
    "From Langchain documents: \n",
    "\n",
    "RecursiveCharacterTextSplitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e29fd56-3275-4041-ad1c-63f71a9d0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have some trials with different chunk_size and chunk_overlap.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1a8d1fe-d24c-443d-bf68-43bdb0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 70 documents\n",
      "CHAPTER ONE  \n",
      " \n",
      "THE BOY WHO LIVED  \n",
      " \n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud\n",
      "=========\n",
      "have a very large mustac he. Mrs. Dursley was thin and blonde and had  \n",
      "nearly twice the usual amoun\n",
      "=========\n",
      "think they could bear it if anyone found out about the Potters. Mrs.  \n",
      "Potter was Mrs. Dursley's sis\n",
      "=========\n",
      "Potters had a small son, too, but they had never even seen him. This boy  \n",
      "was another good reason f\n",
      "=========\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "screaming  \n",
      "Dudley into his high cha\n",
      "=========\n",
      "into his car and backed out of number four's drive.  \n",
      " \n",
      "It was on the corner of the street that he n\n",
      "=========\n",
      "stared at the cat. It stared  back. As Mr. Dursley drove around the  \n",
      "corner and up the road, he wat\n",
      "=========\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the us\n",
      "=========\n",
      "wheel and his eyes fell on a huddle of these weirdos standing quite  \n",
      "close by. They were whispering\n",
      "=========\n",
      "nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "silly stunt -- these peop\n",
      "=========\n",
      "on drills that morning. He didn't see the owls swoop ing past in broad  \n",
      "daylight, though people dow\n",
      "=========\n",
      "very good mood until lunchtime, when he thought he'd stretch his legs  \n",
      "and wal k across the road to\n",
      "=========\n",
      "caught a few words of what they were saying.  \n",
      " \n",
      "\"The Potters, that's right, that's what I heard yes\n",
      "=========\n",
      "receiver back down and stroked his mustache, thinking... no, he was  \n",
      "being stupid. Potter wasn't su\n",
      "=========\n",
      "of it, he wasn't even sure his nephew was called Harry. He'd never even  \n",
      "seen the boy. It might hav\n",
      "=========\n",
      "he walked straight into someone just outside the door.  \n",
      " \n",
      "\"Sorry,\" he grunted, as the tiny old man \n",
      "=========\n",
      "for nothing could upset me today! Rejo ice, for You -Know -Who has gone \n",
      "at \n",
      "last! Even Muggles like\n",
      "=========\n",
      "he was imagining things, which he had never hoped before, because he  \n",
      "didn't approve of imagination\n",
      "=========\n",
      "stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
      "=========\n",
      "to pull himself together, he let himself into the house. He was still  \n",
      "determined not to mention  a\n",
      "=========\n",
      "catch the last report on the evening news:  \n",
      " \n",
      "\"And finally, bird -watchers everywhere have reported\n",
      "=========\n",
      "\"Most mysterious. And now, over to Jim McGuffin with the weather. \n",
      "Going  \n",
      "to be any more showers of\n",
      "=========\n",
      "not until next wee k, folks! But I can promise a wet night tonight.\"  \n",
      " \n",
      "Mr. Dursley sat frozen in h\n",
      "=========\n",
      "lately, have you?\"\n",
      "=========\n",
      "As he had expected, Mrs. Durs ley looked shocked and angry. After all,  \n",
      "they normally pretended she\n",
      "=========\n",
      "know... her crowd.\"  \n",
      " \n",
      "Mrs. Dursley sipped her tea through pursed lips. Mr. Dursley wondered  \n",
      "whet\n",
      "=========\n",
      "\"Harry. Nasty, commo n name, if you ask me.\"  \n",
      " \n",
      "\"Oh, yes,\" said Mr. Dursley, his heart sinking horr\n",
      "=========\n",
      "something.  \n",
      " \n",
      "Was he imagining things? Could all this have anything to do with the\n",
      "=========\n",
      "Potters? If it did... if it got out  that they were related to a pair of  \n",
      "-- well, he didn't think \n",
      "=========\n",
      "them and their kind.... He couldn't see how he and Petunia could get  \n",
      "mixed up in a nything that mi\n",
      "=========\n",
      "Privet Drive. It didn't so much as quiver when a car door slammed on the  \n",
      "next street, nor when two\n",
      "=========\n",
      "thin, and very old, judging by the silver of his hair and beard, which  \n",
      "were both long enough to tu\n",
      "=========\n",
      "Albus Dumbledore didn't seem to realize that he had just arrived in  a\n",
      "=========\n",
      "street where everything from his name to his boots was unwelcome. He \n",
      "was \n",
      "busy rummaging in his clo\n",
      "=========\n",
      "silver cigarette lighter. He flicked it open, held it up in the air, and  \n",
      "clicked it. The nearest s\n",
      "=========\n",
      "eyed  \n",
      "Mrs. Dursley, they wouldn't be able to see anything that was happening  \n",
      "down on the pavement\n",
      "=========\n",
      "at a rather severe -looking woman who was wearing square glasses exactly  \n",
      "the shape of the markings\n",
      "=========\n",
      "Professor McGona gall. \n",
      " \n",
      "\"All day? When you could have been celebrating? I must have passed a  \n",
      "doz\n",
      "=========\n",
      "of owls... shooting stars.... Well, they're not completely st upid. They  \n",
      "were bound to notice some\n",
      "=========\n",
      "the streets in broad daylight, not even dressed in Muggle clothes,  \n",
      "swapping rumors.\"  \n",
      " \n",
      "She threw\n",
      "=========\n",
      "for. Would you care for a lemon drop?\"  \n",
      " \n",
      "\"A what?\"  \n",
      " \n",
      "\"A lemon drop. They're a kind of Muggle swe\n",
      "=========\n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment \n",
      "=========\n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You\n",
      "=========\n",
      "never have.\"  \n",
      " \n",
      "\"Only because you're too -- well -- noble to use them.\"  \n",
      " \n",
      "\"It's lucky it's dark. \n",
      "=========\n",
      "anxious to discuss, the real reason she had been waiting on a cold, hard  \n",
      "wall all day, for neither\n",
      "=========\n",
      "Dumbledore with such a piercin g stare as she did now. It was plain that  \n",
      "whatever \"everyone\" was s\n",
      "=========\n",
      "Dumbledore bowed his head. Professor McGonagall gasped.  \n",
      " \n",
      "\"Lily and James...  I can't believe it..\n",
      "=========\n",
      "but they're saying that when he couldn't kill Harry Potter, Voldemort's  \n",
      "power somehow broke -- and\n",
      "=========\n",
      "Professor McGonagall pulled out a lace handkerchief and dabbed at her  \n",
      "eyes beneath her spectacles.\n",
      "=========\n",
      "It had twelve hands but no numbers; instead, little planets were moving  \n",
      "around the edge. It must h\n",
      "=========\n",
      "he has left now.\"  \n",
      " \n",
      "\"You don't mean -- you can't mean the people who live here?\" cried  \n",
      "Professor\n",
      "=========\n",
      "uncle will be able to explain everything to him when he's older. I've  \n",
      "written them a letter.\"  \n",
      " \n",
      "\n",
      "=========\n",
      "in our world will know his name!\"  \n",
      " \n",
      "\"Exactly,\" said Dumbledore, looking very seriously over the  t\n",
      "=========\n",
      "Professor McGonagall opened her mouth, changed her mind, swallowed, \n",
      "and \n",
      "then said, \"Yes -- yes, yo\n",
      "=========\n",
      "\"I'm not saying his heart isn't in the right place,\" said Professor  \n",
      "McG onagall grudgingly, \"but y\n",
      "=========\n",
      "them.  \n",
      " \n",
      "If the motorcycle was huge, it was nothing to the man sitting astride  \n",
      "it. He was almost \n",
      "=========\n",
      "of blankets.  \n",
      " \n",
      "\"Hagrid,\" said Dumbledore, sounding relieved. \"At last. And where did  \n",
      "you get tha\n",
      "=========\n",
      "carefully off  the motorcycle as he spoke. \"Young Sirius Black lent it to  \n",
      "me. I've got him, sir.\" \n",
      "=========\n",
      "tuft of jet -black hair over his forehead they could see a curiously  \n",
      "shaped cut, like a bol t of l\n",
      "=========\n",
      "Dumbledore took Harry in his arms and turned toward the Dursleys' \n",
      "house.  \n",
      " \n",
      "\"Could I -- could I sa\n",
      "=========\n",
      "burying his face in it. \"But I c -c-can't stand it -- Lily an' James dead  \n",
      "-- an' poor little Harry\n",
      "=========\n",
      "of his cloak,  tucked it inside Harry's blankets, and then came back to  \n",
      "the other two. For a full \n",
      "=========\n",
      "\"Yeah,\" said Hagrid in a very muffled voice, \"I'll be takin' Sirius his  \n",
      "bike back. G'night, Profes\n",
      "=========\n",
      "Dumbledore turned and walked back down the street. On the corner he  \n",
      "stopped and took out the silve\n",
      "=========\n",
      "of his cloak, he was gone.\n",
      "=========\n",
      "A breeze ruffled the neat hedges of Privet Drive, which lay silent and  \n",
      "tidy under the inky sky, th\n",
      "=========\n",
      "bottles, nor that he would spend the next few weeks being prodded and  \n",
      "pinched by his cousin Dudley\n",
      "=========\n",
      "all. The sun rose on the same tidy front gardens and lit up the brass  \n",
      "number four on the Dursleys'\n",
      "=========\n",
      "large pink beac h ball wearing different -colored bonnets -- but Dudley  \n",
      "Dursley was no longer a ba\n",
      "=========\n",
      "long. His Aunt Petunia was awake and it was her shrill voice that made\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')\n",
    "\n",
    "for t in texts:\n",
    "    print(t.page_content[:100])\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515d70a",
   "metadata": {},
   "source": [
    "There are different kinds of splitters.  \n",
    "\n",
    "https://chunkviz.up.railway.app/ \n",
    "\n",
    "provides a great tool to see the splitter differences with different chunk_size and chunk_overlap settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a6a49db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your TASK ####\n",
    "# Try different PDF Loaders.  Which one works the best for this file /share/lab4/hp-book1.pdf ,\n",
    "# which contains the full book of Harry Potter Book 1, with all the illustratons.\n",
    "\n",
    "## Langchain provides many other options for loaders, read the documents to find out the differences\n",
    "# See page https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf\n",
    "# loader = UnstructuredPDFLoader(\"./data/field-guide-to-data-science.pdf\")\n",
    "# loader = PyPDFLoader(\"example_data/layout-parser-paper.pdf\")\n",
    "# loader = PDFMinerLoader(\"example_data/layout-parser-paper.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c23cf-0d0a-4f79-9718-42d093fc4dd0",
   "metadata": {},
   "source": [
    "### 2.2 Create embeddings of your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1bbf6",
   "metadata": {},
   "source": [
    "Embedding is a model that turns a sentence into vectors, so that we can \"semantically search\" for related splits of a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd92c90b-7f21-4c8b-9586-41abf20b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI embedding: slow and expensive, we do not use them here.  \n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# openai_embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08ee572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Let's use the local ones.\n",
    "# We have downloaded a number of popular embedding models for you, in the /share/embedding directory, including\n",
    "# LaBSE\n",
    "# all-MiniLM-L12-v2\n",
    "# all-MiniLM-L6-v2\n",
    "# paraphrase-multilingual-MiniLM-L12-v2\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "minilm_embedding = SentenceTransformerEmbeddings(model_name=\"/share/embedding/all-MiniLM-L6-v2/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b805c79-c5b1-4812-9b85-671820ff0a69",
   "metadata": {},
   "source": [
    "### 2.4  Store and retrieve the embeddings in ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0c49f-541a-44da-8f5b-1e6059b478a6",
   "metadata": {},
   "source": [
    "You can search documents stored in \"Vector DBs\" by their semantic similarity.  Vector DBs uses an algorithm called \"KNN (k-nearest neighbors)\" to find documents whose embedding is the closest to the query. \n",
    "\n",
    "We first introduce ChromaDB becauase it runs locally, easy-to-set-up, and best of all, free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2af187c9-e90d-40be-a74f-db620af2bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings and save the embeddings into ChromaDB\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "chroma_dir = \"/scratch2/chroma_db\"\n",
    "docsearch_chroma = Chroma.from_documents(texts, \n",
    "                                         minilm_embedding, \n",
    "                                         collection_name='harry-potter', \n",
    "                                         persist_directory=chroma_dir,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51465f59-49ed-45a5-832a-1f03b9560c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions from https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Books/Philosopher%27s_Stone/Chapter_1\n",
    "# you can try yourself\n",
    "\n",
    "# query = 'Why would the Dursleys consider being related to the Potters a \"shameful secret\"?'\n",
    "# query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "# query = 'What might a \"Muggle\" be?'\n",
    "# query = 'What exactly is the cat on Privet Drive?'\n",
    "query = '''Who might \"You-Know-Who\" be? Why isn't this person referred to by a given name?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34cf7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A utiity function ...\n",
    "def print_search_results(docs):\n",
    "    print(f\"search returned %d results. \" % len(docs))\n",
    "    for doc in docs:\n",
    "        print(doc.page_content)\n",
    "        print(\"=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c24069d5-19d6-477b-a3ba-c79b6cd39d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment for lemon drops. \"As I say, even if  \n",
      "You-Know -Who has gone -\" \n",
      " \n",
      "\"My dear Professor, surely a sensible person like yourself can call him  \n",
      "by his name? All this 'You - Know -Who' nonsense -- for eleven years I  \n",
      "have been trying to persuade people to call him by his proper name:  \n",
      "Voldemort.\" Professor McGonagall flinched, but Dumbledore, who was  \n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You -Know -Who.' I have never seen any \n",
      "reason  \n",
      "to be frightened of saying Voldemort's name.  \n",
      " \n",
      "\"I know you haven 't, said Professor McGonagall, sounding half  \n",
      "exasperated, half admiring. \"But you're different. Everyone knows you're  \n",
      "the only one You -Know - oh, al l right, Voldemort, was frightened of.\"  \n",
      " \n",
      "\"You flatter me,\" said Dumbledore calmly. \"Voldemort had powers I will  \n",
      "never have.\"  \n",
      " \n",
      "\"Only because you're too -- well -- noble to use them.\"  \n",
      " \n",
      "\"It's lucky it's dark. I haven't blushed so much since Madam Pomfr ey \n",
      "told me she liked my new earmuffs.\"  \n",
      " \n",
      "Professor McGonagall shot a sharp look at Dumbledore and said, \"The \n",
      "owls  \n",
      "are nothing next to the rumors that are flying around. You know what  \n",
      "everyone's saying? About why he's disappeared? About what finally  \n",
      "stopped him?\"  \n",
      " \n",
      "It seemed that Professor McGonagall had reached the point she was most  \n",
      "anxious to discuss, the real reason she had been waiting on a cold, hard  \n",
      "wall all day, for neither as a cat nor as a woman had she fixed\n",
      "=============\n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment for lemon drops. \"As I say, even if  \n",
      "You-Know -Who has gone -\" \n",
      " \n",
      "\"My dear Professor, surely a sensible person like yourself can call him  \n",
      "by his name? All this 'You - Know -Who' nonsense -- for eleven years I  \n",
      "have been trying to persuade people to call him by his proper name:  \n",
      "Voldemort.\" Professor McGonagall flinched, but Dumbledore, who was  \n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You -Know -Who.' I have never seen any \n",
      "reason  \n",
      "to be frightened of saying Voldemort's name.  \n",
      " \n",
      "\"I know you haven 't, said Professor McGonagall, sounding half  \n",
      "exasperated, half admiring. \"But you're different. Everyone knows you're  \n",
      "the only one You -Know - oh, al l right, Voldemort, was frightened of.\"  \n",
      " \n",
      "\"You flatter me,\" said Dumbledore calmly. \"Voldemort had powers I will  \n",
      "never have.\"  \n",
      " \n",
      "\"Only because you're too -- well -- noble to use them.\"  \n",
      " \n",
      "\"It's lucky it's dark. I haven't blushed so much since Madam Pomfr ey \n",
      "told me she liked my new earmuffs.\"  \n",
      " \n",
      "Professor McGonagall shot a sharp look at Dumbledore and said, \"The \n",
      "owls  \n",
      "are nothing next to the rumors that are flying around. You know what  \n",
      "everyone's saying? About why he's disappeared? About what finally  \n",
      "stopped him?\"  \n",
      " \n",
      "It seemed that Professor McGonagall had reached the point she was most  \n",
      "anxious to discuss, the real reason she had been waiting on a cold, hard  \n",
      "wall all day, for neither as a cat nor as a woman had she fixed\n",
      "=============\n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You -Know -Who.' I have never seen any \n",
      "reason  \n",
      "to be frightened of saying Voldemort's name.\n",
      "=============\n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You -Know -Who.' I have never seen any \n",
      "reason  \n",
      "to be frightened of saying Voldemort's name.\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# semantic similarity search\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a21737",
   "metadata": {},
   "source": [
    "#### Saving and Loading your ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "56bd7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local disk\n",
    "docsearch_chroma.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd053d53-d5a0-4e1f-8d56-69acb51d6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from disk\n",
    "docsearch_chroma_reloaded = Chroma(persist_directory = chroma_dir,\n",
    "                                   collection_name = 'harry-potter', \n",
    "                                   embedding_function = minilm_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ff1f853-d04e-4bae-8bf2-bddec2d4326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in\n",
      "=============\n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in\n",
      "=============\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help  \n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getups you saw on young people! He supposed this  \n",
      "was some stupi d new fashion. He drummed his fingers on the steering\n",
      "=============\n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help  \n",
      "noticing that there seemed to be a lot of strangely dressed people  \n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getups you saw on young people! He supposed this  \n",
      "was some stupi d new fashion. He drummed his fingers on the steering\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# you can test with the previous or another query\n",
    "\n",
    "query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd8cdb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your TASK ####\n",
    "# With the chosen PDF loaders, test different splitters and chunk size until you feel that the chucking makes sense. \n",
    "# You can also try different embeddings\n",
    "# Then embed the entire book 1 into ChormaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa211d6-014a-4b99-8c79-1699557e0fe1",
   "metadata": {},
   "source": [
    "### 2.5 Query those docs with a QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4050ea43-6af4-4617-8c2e-c3b550336fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f035d818-b8cf-4d49-9a6f-ba233e204188",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9db75a21-9f02-4e09-98ef-81c40d6e04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How did Harry's parents die?\"\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98270f41-fddd-4be0-909d-c80345e98470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "tell me why you're here, of all places?\"  \n",
      " \n",
      "\"I've come to bring Harry to his aunt and uncle. They're the only family  \n",
      "he has left now.\"\n",
      "\n",
      "tell me why you're here, of all places?\"  \n",
      " \n",
      "\"I've come to bring Harry to his aunt and uncle. They're the only family  \n",
      "he has left now.\"\n",
      "\n",
      "his way back past them, clutching a large doughnut in a bag, that he  \n",
      "caught a few words of what they were saying.  \n",
      " \n",
      "\"The Potters, that's right, that's what I heard yes, their son, Harry\"\n",
      "\n",
      "his way back past them, clutching a large doughnut in a bag, that he  \n",
      "caught a few words of what they were saying.  \n",
      " \n",
      "\"The Potters, that's right, that's what I heard yes, their son, Harry\"\n",
      "\n",
      "Question: How did Harry's parents die?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Harry's parents died and he is now being taken to live with his aunt and uncle, as they are the only family he has left.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "43d0d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task ####\n",
    "\n",
    "# Rebuild the chain from the whole book ChromaDB.  Test with one of the following questions (of your choice).\n",
    "\n",
    "#query = 'Why does Dumbledore believe the celebrations may be premature?'\n",
    "#query = 'Why is Harry left with the Dursleys rather than a Wizard family?'\n",
    "#query = 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4599ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task ####\n",
    "\n",
    "# Using langchain documentation, find out about the map reduce QA chain.  \n",
    "# answer the following questions using the chain\n",
    "#chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "# answer one of the following questions of your choice. \n",
    "\n",
    "# query = What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
    "# query = Tell me about Harry Potter and Quidditch during the first year\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0d396",
   "metadata": {},
   "source": [
    "### 2.6 Using Pinecone, an online vector DB\n",
    "\n",
    "You have many reasons to store your DB online in a SaaS / PaaS service.  For example, \n",
    "- you want to scale the queries to many concurrent users\n",
    "- you want more data reliability without having to worry about DB management\n",
    "- you want to share the DB but without owning any servers\n",
    "\n",
    "If you want to store your embeddings online, try pinecone with the code below. You must go to [Pinecone.io](https://www.pinecone.io/) and set up an account. Then you need to generate an api-key and create an \"index\", this can be done by navigating through the homepage once you've logged in to Pinecone, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b75f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "# initialize pinecone, depends on two environment variables, os.environ['PINECONE_API_KEY'] and os.environ['PINECONE_API_ENV']\n",
    "pinecone.Pinecone()\n",
    "\n",
    "# You should create an index for your vector db.  \n",
    "# The \"dimension\" setting when you create the DB online, should be 1536 for openAI embedding, or 384 for minilm. \n",
    "index_name = \"test001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f04c5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch_pinecone = Pinecone.from_texts(\n",
    "                                [ t.page_content for t in texts ], \n",
    "                                minilm_embedding, \n",
    "                                index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba00d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "large pink beac h ball wearing different -colored bonnets -- but Dudley  \n",
      "Dursley was no longer a baby, and now the photographs showed a large  \n",
      "blond boy riding his first bicycle, on a carousel at the fair, playing a  \n",
      "computer game with his father, being hugged and kissed b y his mother.  \n",
      "The room held no sign at all that another boy lived in the house, too.  \n",
      " \n",
      "Yet Harry Potter was still there, asleep at the moment, but not for\n",
      "\n",
      "caught a few words of what they were saying.  \n",
      " \n",
      "\"The Potters, that's right, that's what I heard yes, their son, Harry\"  \n",
      " \n",
      "Mr. Dursley stopped dead. Fear flooded him. He looked back at the  \n",
      "whisperers as if he wanted to say something to them, but thought better  \n",
      "of it.  \n",
      " \n",
      "He dashed back across the road, hurried up to his office, snapped at his  \n",
      "secretary n ot to disturb him, seized his telephone, and had almost  \n",
      "finished dialing his home number when he changed his mind. He put the\n",
      "\n",
      "of it, he wasn't even sure his nephew was called Harry. He'd never even  \n",
      "seen the boy. It might have been Harvey. Or Harold. There was no point  \n",
      "in worrying Mrs. Dursley ; she always got so upset at any mention of her  \n",
      "sister. He didn't blame her -- if he'd had a sister like that... but all  \n",
      "the same, those people in cloaks...  \n",
      " \n",
      "He found it a lot harder to concentrate on drills that afternoon and  \n",
      "when he left the buildin g at five o'clock, he was still so worried that\n",
      "\n",
      "Dumbledore bowed his head. Professor McGonagall gasped.  \n",
      " \n",
      "\"Lily and James...  I can't believe it... I didn't want to believe it...  \n",
      "Oh, Albus...\"  \n",
      " \n",
      "Dumbledore reached out and patted her on the shoulder. \"I know... I  \n",
      "know...\" he said heavily.  \n",
      " \n",
      "Professor McGonagall's voice trembled as she went on. \"That's not all.  \n",
      "They're saying  he tried to kill the Potter's son, Harry. But -- he \n",
      "couldn't. He couldn't kill that little boy. No one knows why, or how,\n",
      "\n",
      "Question: How did Harry's parents die?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Harry's parents, Lily and James Potter, were killed by the dark wizard, Lord Voldemort, who also attempted to kill their son, Harry, but was unable to do so.\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", verbose=True)\n",
    "query = \"How did Harry's parents die?\"\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)\n",
    "\n",
    "# we can use the full-book to test 'map-reduce'\n",
    "#chain = load_qa_chain(llm, chain_type=\"map_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7453fd84-ba39-4f2b-ab23-23b94d45d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privet Drive. It didn't so much as quiver when a car door slammed on the  \n",
      "next street, nor when two owls swooped overhead. In fact, it was nearly  \n",
      "midnight before the cat moved  at all.  \n",
      " \n",
      "A man appeared on the corner the cat had been watching, appeared so  \n",
      "suddenly and silently you'd have thought he'd just popped out of the  \n",
      "ground. The cat's tail twitched and its eyes narrowed.  \n",
      " \n",
      "Nothing like this man had ever been seen on Pri vet Drive. He was tall,\n"
     ]
    }
   ],
   "source": [
    "# query with pinecone\n",
    "query = 'What exactly is the cat on Privet Drive?'\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "print(docs[0].page_content[:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task ####\n",
    "# modify the QA chain in Section 2.5 (Chapter 1 only) to use pinecone instead of ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc6131-6a1a-40f5-8af0-afc5c723e49e",
   "metadata": {},
   "source": [
    "### 2.7 Use vector store in Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "source": [
    "In this section, we are going to create a simple QA agent that can decide by itself which of the two vectorstores it should switch to for questions of differnent fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "#### Preparing the tools for the agent.\n",
    "\n",
    "We will use our chroma_based Harry Potter vectorDB, and let's create another one containing President Biden's State of the Union speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "949662aa-5044-4899-ba50-5e06ac7df371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "documents = TextLoader('/share/lab4/state_of_the_union.txt').load()\n",
    "texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(documents)\n",
    "docsearch3 = Chroma.from_documents(texts, \n",
    "                                   minilm_embedding, \n",
    "                                   collection_name=\"state-of-union\", \n",
    "                                   persist_directory=\"/scratch2/chroma_db\")\n",
    "docsearch3.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "To allow the agent query these databases, we need to define two RetrievalQA chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ccd41e19-fcff-4358-9374-2b36b29d1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "harry_potter = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch_chroma_reloaded.as_retriever())\n",
    "state_of_union = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                             chain_type=\"stuff\", \n",
    "                                             retriever=docsearch3.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'query': 'Why does McGonagall seem concerned about Harry being raised by the '\n",
      "          'Dursleys?',\n",
      " 'result': ' McGonagall may be concerned because she knows that the Dursleys '\n",
      "           'do not like magic and may not treat Harry well because of his '\n",
      "           \"magical abilities. She also may be worried about Harry's safety \"\n",
      "           'and well-being in their care.'}\n",
      "\"<class 'dict'>:\"\n",
      "{'query': 'what is the GDP increase last year?',\n",
      " 'result': ' The GDP increase last year was 5.7%.'}\n"
     ]
    }
   ],
   "source": [
    "# Now try both chains\n",
    "\n",
    "print_with_type(harry_potter.invoke('Why does McGonagall seem concerned about Harry being raised by the Dursleys?'))\n",
    "print_with_type(state_of_union.invoke(\"what is the GDP increase last year?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73957e1e-f3e2-48e6-91db-d669d5cbe3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Harry Potter QA System\",\n",
    "        func=harry_potter.run,\n",
    "        description=\"useful for when you need to answer questions about Harry Potter. Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "source": [
    "Now we can create the Agent giving both chains as tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11b068ff-d822-44ec-ba63-c47f49b492e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "\n",
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b85245e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use the State of Union QA System to find the answer\n",
      "Action: State of Union QA System\n",
      "Action Input: What did biden say about ketanji brown jackson?\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m Biden nominated Ketanji Brown Jackson for the United States Supreme Court.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Biden nominated Ketanji Brown Jackson for the United States Supreme Court.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Biden nominated Ketanji Brown Jackson for the United States Supreme Court.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"What did biden say about ketanji brown jackson?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "497fde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m You should always think about what to do\n",
      "Action: Harry Potter QA System\n",
      "Action Input: 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m McGonagall is concerned about Harry being raised by the Dursleys because she knows that they have a negative opinion of magic and the wizarding world. She worries that Harry may not be treated well or may not be taught about his magical abilities.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m You should always think about what to do\n",
      "Action: Harry Potter QA System\n",
      "Action Input: 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m McGonagall is concerned about Harry being raised by the Dursleys because she knows that they have a negative opinion of magic and the wizarding world. She worries that Harry may not be treated well or may not be taught about his magical abilities.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: McGonagall is concerned about Harry being raised by the Dursleys because she knows that they have a negative opinion of magic and the wizarding world. She worries that Harry may not be treated well or may not be taught about his magical abilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'McGonagall is concerned about Harry being raised by the Dursleys because she knows that they have a negative opinion of magic and the wizarding world. She worries that Harry may not be treated well or may not be taught about his magical abilities.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\n",
    "    \"'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85245e2",
   "metadata": {},
   "source": [
    "We can see that the agent can \"smartly\" choose which QA system to use given a specific question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fde49",
   "metadata": {},
   "source": [
    "## 3 Your Task: putting it all together: OpenAI and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "09e6d104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task ####\n",
    "\n",
    "# This is a major task that requires some thinking and time. \n",
    "\n",
    "# Build a conversation system from a collection of research papers of your choice. \n",
    "# You can ask specific questions of a method about these papers, and the agent returns a brief answer to you (with no more than 100 words). \n",
    "# Save your data and ChromaDB in the /share directory so other people can use it. \n",
    "# Provide at least three query examples so the TAs can review your work. \n",
    "\n",
    "# You may use any tool from the past four labs or from the langchain docs, or any open source project. \n",
    "\n",
    "# write a summary (a Markdown cell) at the end of the notebook summarizing what works and what does not. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
